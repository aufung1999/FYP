{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guest1\\anaconda3\\envs\\backup_20220216_20220322\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Activation, Dense, Dropout, Conv2D, \\\n",
    "                         Flatten, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import TensorBoard\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold\n",
    "from os import path\n",
    "from pydub import AudioSegment\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice_file_name</th>\n",
       "      <th>fsID</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>salience</th>\n",
       "      <th>fold</th>\n",
       "      <th>classID</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100032-3-0-0.wav</td>\n",
       "      <td>100032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.317551</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100263-2-0-117.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>58.5</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100263-2-0-121.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>60.5</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100263-2-0-126.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>63.0</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100263-2-0-137.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>68.5</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      slice_file_name    fsID  start        end  salience  fold  classID  \\\n",
       "0    100032-3-0-0.wav  100032    0.0   0.317551         1     5        3   \n",
       "1  100263-2-0-117.wav  100263   58.5  62.500000         1     5        2   \n",
       "2  100263-2-0-121.wav  100263   60.5  64.500000         1     5        2   \n",
       "3  100263-2-0-126.wav  100263   63.0  67.000000         1     5        2   \n",
       "4  100263-2-0-137.wav  100263   68.5  72.500000         1     5        2   \n",
       "\n",
       "              class  \n",
       "0          dog_bark  \n",
       "1  children_playing  \n",
       "2  children_playing  \n",
       "3  children_playing  \n",
       "4  children_playing  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Data\n",
    "data = pd.read_csv('UrbanSounds8K/metadata/UrbanSound8K.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8732, 8)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7468, 4)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get data over 3 seconds long\n",
    "\n",
    "valid_data = data[['slice_file_name', 'fold' ,'classID', 'class']][ data['end']-data['start'] >= 3 ]\n",
    "valid_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x27cd5677b88>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y, sr = librosa.load('UrbanSounds8K/audio/fold9/13579-2-0-16.wav', duration=2.97)\n",
    "ps = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "ps.shape\n",
    "\n",
    "mel_sgram = librosa.amplitude_to_db(ps, ref=np.min)\n",
    "\n",
    "librosa.display.specshow(ps , y_axis='mel', x_axis='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data['path'] = 'fold' + valid_data['fold'].astype('str') + '/' + valid_data['slice_file_name'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use it to create data ######################################################################\n",
    "def creates_train_data():\n",
    "    D = [] # Dataset\n",
    "\n",
    "    for row in valid_data.itertuples():\n",
    "        y, sr = librosa.load('UrbanSounds8K/augmented/ps2_m25/' + row.path, duration=2.97)  #2.97 = 3*1000 - 3*1000/128  ###############################\n",
    "        ps = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "        if ps.shape != (128, 128): continue\n",
    "        D.append( (ps, row.classID) )\n",
    "    np.save('train_data_augmented_ps2_m25.npy', D) ###############################\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.load.__defaults__=(None, True, True, 'ASCII')\n",
    "a = np.load('train_data.npy')\n",
    "b = np.load('train_data_augmented_speed_81.npy')\n",
    "c = np.load('train_data_augmented_speed_107.npy')\n",
    "d = np.load('train_data_augmented_ps1_2.npy')\n",
    "e = np.load('train_data_augmented_ps2_m25.npy')\n",
    "\n",
    "# np.savez('train.npz',a,b,c,d,e) ############################################################################\n",
    "# r = np.load('train.npz') ############################################################################\n",
    "# locals().update(r) ############################################################################\n",
    "\n",
    "tuple = (a,b,c,d,e)\n",
    "tuplearr = np.vstack(tuple)\n",
    "len(tuplearr)\n",
    "dataset = tuplearr\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To see how many samples are in X-train and y-train\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3731  3732  3733 ... 37300 37301 37302] [   0    1    2 ... 3728 3729 3730]\n",
      "-----------breaking line--------------\n",
      "----------------------------\n",
      "1\n",
      "----------------------------\n",
      "Epoch 1/12\n",
      "  1/263 [..............................] - ETA: 0s - loss: 10.0216 - accuracy: 0.0859WARNING:tensorflow:From C:\\Users\\otsanyin6920\\anaconda3\\envs\\backup_20220216\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "263/263 [==============================] - 115s 436ms/step - loss: 2.1142 - accuracy: 0.2958 - val_loss: 1.4185 - val_accuracy: 0.5240\n",
      "Epoch 2/12\n",
      "263/263 [==============================] - 112s 425ms/step - loss: 1.4791 - accuracy: 0.4727 - val_loss: 1.0045 - val_accuracy: 0.6642\n",
      "Epoch 3/12\n",
      "263/263 [==============================] - 110s 418ms/step - loss: 1.2535 - accuracy: 0.5612 - val_loss: 0.7666 - val_accuracy: 0.7574\n",
      "Epoch 4/12\n",
      "263/263 [==============================] - 109s 415ms/step - loss: 1.0547 - accuracy: 0.6362 - val_loss: 0.6011 - val_accuracy: 0.8094\n",
      "Epoch 5/12\n",
      "263/263 [==============================] - 109s 415ms/step - loss: 0.9325 - accuracy: 0.6875 - val_loss: 0.4836 - val_accuracy: 0.8483\n",
      "Epoch 6/12\n",
      "263/263 [==============================] - 109s 414ms/step - loss: 0.8288 - accuracy: 0.7255 - val_loss: 0.4577 - val_accuracy: 0.8695\n",
      "Epoch 7/12\n",
      "263/263 [==============================] - 109s 415ms/step - loss: 0.7943 - accuracy: 0.7386 - val_loss: 0.3913 - val_accuracy: 0.8797\n",
      "Epoch 8/12\n",
      "263/263 [==============================] - 109s 415ms/step - loss: 0.6879 - accuracy: 0.7748 - val_loss: 0.4101 - val_accuracy: 0.8692\n",
      "Epoch 9/12\n",
      "263/263 [==============================] - 109s 415ms/step - loss: 0.6497 - accuracy: 0.7879 - val_loss: 0.3371 - val_accuracy: 0.8888\n",
      "Epoch 10/12\n",
      "263/263 [==============================] - 109s 413ms/step - loss: 0.6125 - accuracy: 0.8010 - val_loss: 0.2603 - val_accuracy: 0.9140\n",
      "Epoch 11/12\n",
      "263/263 [==============================] - 109s 415ms/step - loss: 0.5532 - accuracy: 0.8201 - val_loss: 0.2346 - val_accuracy: 0.9212\n",
      "Epoch 12/12\n",
      "263/263 [==============================] - 110s 419ms/step - loss: 0.5223 - accuracy: 0.8278 - val_loss: 0.2411 - val_accuracy: 0.9215\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.2411 - accuracy: 0.9215\n",
      "Test loss: 0.24114637076854706\n",
      "Test accuracy: 0.9214687943458557\n",
      "[    0     1     2 ... 37300 37301 37302] [3731 3732 3733 ... 7459 7460 7461]\n",
      "-----------breaking line--------------\n",
      "----------------------------\n",
      "2\n",
      "----------------------------\n",
      "Epoch 1/12\n",
      "263/263 [==============================] - 111s 420ms/step - loss: 2.0632 - accuracy: 0.3043 - val_loss: 1.4358 - val_accuracy: 0.4918\n",
      "Epoch 2/12\n",
      "263/263 [==============================] - 110s 417ms/step - loss: 1.4374 - accuracy: 0.4900 - val_loss: 1.0496 - val_accuracy: 0.6529\n",
      "Epoch 3/12\n",
      "263/263 [==============================] - 109s 414ms/step - loss: 1.1811 - accuracy: 0.5929 - val_loss: 0.8947 - val_accuracy: 0.7014\n",
      "Epoch 4/12\n",
      "263/263 [==============================] - 109s 416ms/step - loss: 1.0120 - accuracy: 0.6586 - val_loss: 0.6888 - val_accuracy: 0.7716\n",
      "Epoch 5/12\n",
      "263/263 [==============================] - 109s 416ms/step - loss: 0.9159 - accuracy: 0.7003 - val_loss: 0.6197 - val_accuracy: 0.8076\n",
      "Epoch 6/12\n",
      "263/263 [==============================] - 109s 416ms/step - loss: 0.8015 - accuracy: 0.7374 - val_loss: 0.5512 - val_accuracy: 0.8218\n",
      "Epoch 7/12\n",
      "263/263 [==============================] - 110s 420ms/step - loss: 0.7247 - accuracy: 0.7642 - val_loss: 0.4675 - val_accuracy: 0.8480\n",
      "Epoch 8/12\n",
      "263/263 [==============================] - 109s 414ms/step - loss: 0.6552 - accuracy: 0.7902 - val_loss: 0.4003 - val_accuracy: 0.8700\n",
      "Epoch 9/12\n",
      "263/263 [==============================] - 108s 411ms/step - loss: 0.6091 - accuracy: 0.8039 - val_loss: 0.3577 - val_accuracy: 0.8839\n",
      "Epoch 10/12\n",
      "263/263 [==============================] - 108s 411ms/step - loss: 0.5408 - accuracy: 0.8251 - val_loss: 0.3125 - val_accuracy: 0.8998\n",
      "Epoch 11/12\n",
      "263/263 [==============================] - 108s 410ms/step - loss: 0.4861 - accuracy: 0.8404 - val_loss: 0.3140 - val_accuracy: 0.8877\n",
      "Epoch 12/12\n",
      "263/263 [==============================] - 108s 411ms/step - loss: 0.4833 - accuracy: 0.8437 - val_loss: 0.3775 - val_accuracy: 0.8912\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.3775 - accuracy: 0.8912\n",
      "Test loss: 0.3775489628314972\n",
      "Test accuracy: 0.891182005405426\n",
      "[    0     1     2 ... 37300 37301 37302] [ 7462  7463  7464 ... 11190 11191 11192]\n",
      "-----------breaking line--------------\n",
      "----------------------------\n",
      "3\n",
      "----------------------------\n",
      "Epoch 1/12\n",
      "  2/263 [..............................] - ETA: 2:20 - loss: 8.3464 - accuracy: 0.0664WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4189s vs `on_train_batch_end` time: 0.6611s). Check your callbacks.\n",
      "263/263 [==============================] - 111s 420ms/step - loss: 2.0494 - accuracy: 0.3038 - val_loss: 1.4526 - val_accuracy: 0.4835\n",
      "Epoch 2/12\n",
      "263/263 [==============================] - 109s 413ms/step - loss: 1.4452 - accuracy: 0.4920 - val_loss: 1.3020 - val_accuracy: 0.5414\n",
      "Epoch 3/12\n",
      "263/263 [==============================] - 109s 413ms/step - loss: 1.2320 - accuracy: 0.5766 - val_loss: 1.0508 - val_accuracy: 0.6593\n",
      "Epoch 4/12\n",
      "263/263 [==============================] - 109s 413ms/step - loss: 1.0463 - accuracy: 0.6491 - val_loss: 0.8155 - val_accuracy: 0.7395\n",
      "Epoch 5/12\n",
      "263/263 [==============================] - 108s 411ms/step - loss: 0.8990 - accuracy: 0.7025 - val_loss: 0.6914 - val_accuracy: 0.7617\n",
      "Epoch 6/12\n",
      "263/263 [==============================] - 108s 412ms/step - loss: 0.8079 - accuracy: 0.7387 - val_loss: 0.6501 - val_accuracy: 0.7794\n",
      "Epoch 7/12\n",
      "263/263 [==============================] - 108s 411ms/step - loss: 0.7099 - accuracy: 0.7685 - val_loss: 0.5508 - val_accuracy: 0.8223\n",
      "Epoch 8/12\n",
      "263/263 [==============================] - 109s 415ms/step - loss: 0.6266 - accuracy: 0.7960 - val_loss: 0.4941 - val_accuracy: 0.8456\n",
      "Epoch 9/12\n",
      "263/263 [==============================] - 109s 415ms/step - loss: 0.6100 - accuracy: 0.8057 - val_loss: 0.5617 - val_accuracy: 0.8172\n",
      "Epoch 10/12\n",
      "263/263 [==============================] - 109s 413ms/step - loss: 0.5582 - accuracy: 0.8204 - val_loss: 0.4876 - val_accuracy: 0.8609\n",
      "Epoch 11/12\n",
      "263/263 [==============================] - 108s 412ms/step - loss: 0.5426 - accuracy: 0.8278 - val_loss: 0.3805 - val_accuracy: 0.8727\n",
      "Epoch 12/12\n",
      "263/263 [==============================] - 109s 414ms/step - loss: 0.4925 - accuracy: 0.8420 - val_loss: 0.3555 - val_accuracy: 0.8813\n",
      "117/117 [==============================] - 4s 37ms/step - loss: 0.3555 - accuracy: 0.8813\n",
      "Test loss: 0.3554815649986267\n",
      "Test accuracy: 0.8812651038169861\n",
      "[    0     1     2 ... 37300 37301 37302] [11193 11194 11195 ... 14920 14921 14922]\n",
      "-----------breaking line--------------\n",
      "----------------------------\n",
      "4\n",
      "----------------------------\n",
      "Epoch 1/12\n",
      "  2/263 [..............................] - ETA: 3:07 - loss: 6.0370 - accuracy: 0.1289WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4462s vs `on_train_batch_end` time: 0.9882s). Check your callbacks.\n",
      "263/263 [==============================] - 113s 430ms/step - loss: 1.9690 - accuracy: 0.3241 - val_loss: 1.4441 - val_accuracy: 0.4761\n",
      "Epoch 2/12\n",
      "263/263 [==============================] - 109s 415ms/step - loss: 1.4299 - accuracy: 0.4983 - val_loss: 1.1218 - val_accuracy: 0.6405\n",
      "Epoch 3/12\n",
      "263/263 [==============================] - 109s 414ms/step - loss: 1.1564 - accuracy: 0.6029 - val_loss: 0.9671 - val_accuracy: 0.6716\n",
      "Epoch 4/12\n",
      "263/263 [==============================] - 109s 414ms/step - loss: 0.9867 - accuracy: 0.6695 - val_loss: 0.8491 - val_accuracy: 0.7228\n",
      "Epoch 5/12\n",
      "263/263 [==============================] - 110s 418ms/step - loss: 0.8910 - accuracy: 0.7086 - val_loss: 0.7573 - val_accuracy: 0.7314\n",
      "Epoch 6/12\n",
      "263/263 [==============================] - 110s 419ms/step - loss: 0.8107 - accuracy: 0.7375 - val_loss: 0.6244 - val_accuracy: 0.7858\n",
      "Epoch 7/12\n",
      "263/263 [==============================] - 110s 420ms/step - loss: 0.7123 - accuracy: 0.7689 - val_loss: 0.5881 - val_accuracy: 0.7954\n",
      "Epoch 8/12\n",
      "263/263 [==============================] - 111s 421ms/step - loss: 0.6456 - accuracy: 0.7894 - val_loss: 0.4773 - val_accuracy: 0.8357\n",
      "Epoch 9/12\n",
      "263/263 [==============================] - 111s 421ms/step - loss: 0.6065 - accuracy: 0.8052 - val_loss: 0.4549 - val_accuracy: 0.8472\n",
      "Epoch 10/12\n",
      "263/263 [==============================] - 111s 420ms/step - loss: 0.5794 - accuracy: 0.8122 - val_loss: 0.5196 - val_accuracy: 0.8314\n",
      "Epoch 11/12\n",
      "263/263 [==============================] - 110s 420ms/step - loss: 0.5720 - accuracy: 0.8146 - val_loss: 0.4431 - val_accuracy: 0.8399\n",
      "Epoch 12/12\n",
      "263/263 [==============================] - 110s 419ms/step - loss: 0.4994 - accuracy: 0.8350 - val_loss: 0.3632 - val_accuracy: 0.8676\n",
      "117/117 [==============================] - 5s 40ms/step - loss: 0.3632 - accuracy: 0.8676\n",
      "Test loss: 0.36324480175971985\n",
      "Test accuracy: 0.8675603270530701\n",
      "[    0     1     2 ... 37300 37301 37302] [14923 14924 14925 ... 18650 18651 18652]\n",
      "-----------breaking line--------------\n",
      "----------------------------\n",
      "5\n",
      "----------------------------\n",
      "Epoch 1/12\n",
      "  2/263 [..............................] - ETA: 2:52 - loss: 6.3670 - accuracy: 0.1211WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4146s vs `on_train_batch_end` time: 0.9077s). Check your callbacks.\n",
      "263/263 [==============================] - 114s 433ms/step - loss: 2.0857 - accuracy: 0.2996 - val_loss: 1.4845 - val_accuracy: 0.4678\n",
      "Epoch 2/12\n",
      "263/263 [==============================] - 111s 421ms/step - loss: 1.4215 - accuracy: 0.5031 - val_loss: 1.1772 - val_accuracy: 0.5914\n",
      "Epoch 3/12\n",
      "263/263 [==============================] - 110s 419ms/step - loss: 1.1448 - accuracy: 0.6132 - val_loss: 0.9889 - val_accuracy: 0.6660\n",
      "Epoch 4/12\n",
      "263/263 [==============================] - 111s 421ms/step - loss: 1.0080 - accuracy: 0.6672 - val_loss: 0.8649 - val_accuracy: 0.7214\n",
      "Epoch 5/12\n",
      "263/263 [==============================] - 111s 421ms/step - loss: 0.8590 - accuracy: 0.7140 - val_loss: 0.7650 - val_accuracy: 0.7574\n",
      "Epoch 6/12\n",
      "263/263 [==============================] - 111s 420ms/step - loss: 0.7990 - accuracy: 0.7406 - val_loss: 0.7015 - val_accuracy: 0.7735\n",
      "Epoch 7/12\n",
      "263/263 [==============================] - 110s 419ms/step - loss: 0.7429 - accuracy: 0.7570 - val_loss: 0.6786 - val_accuracy: 0.7786\n",
      "Epoch 8/12\n",
      "263/263 [==============================] - 110s 419ms/step - loss: 0.6577 - accuracy: 0.7872 - val_loss: 0.5839 - val_accuracy: 0.8064\n",
      "Epoch 9/12\n",
      "263/263 [==============================] - 111s 420ms/step - loss: 0.6058 - accuracy: 0.8008 - val_loss: 0.5574 - val_accuracy: 0.8190\n",
      "Epoch 10/12\n",
      "263/263 [==============================] - 111s 421ms/step - loss: 0.5839 - accuracy: 0.8105 - val_loss: 0.5884 - val_accuracy: 0.8193\n",
      "Epoch 11/12\n",
      "263/263 [==============================] - 110s 420ms/step - loss: 0.5403 - accuracy: 0.8225 - val_loss: 0.4371 - val_accuracy: 0.8523\n",
      "Epoch 12/12\n",
      "263/263 [==============================] - 110s 418ms/step - loss: 0.5106 - accuracy: 0.8362 - val_loss: 0.4390 - val_accuracy: 0.8563\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.4390 - accuracy: 0.8563\n",
      "Test loss: 0.4389909505844116\n",
      "Test accuracy: 0.8563002943992615\n",
      "[    0     1     2 ... 37300 37301 37302] [18653 18654 18655 ... 22380 22381 22382]\n",
      "-----------breaking line--------------\n",
      "----------------------------\n",
      "6\n",
      "----------------------------\n",
      "Epoch 1/12\n",
      "263/263 [==============================] - 112s 425ms/step - loss: 2.0550 - accuracy: 0.3061 - val_loss: 1.5269 - val_accuracy: 0.4571\n",
      "Epoch 2/12\n",
      "263/263 [==============================] - 111s 421ms/step - loss: 1.4765 - accuracy: 0.4861 - val_loss: 1.2627 - val_accuracy: 0.5517\n",
      "Epoch 3/12\n",
      "263/263 [==============================] - 111s 420ms/step - loss: 1.2353 - accuracy: 0.5794 - val_loss: 1.0644 - val_accuracy: 0.6381\n",
      "Epoch 4/12\n",
      "263/263 [==============================] - 111s 421ms/step - loss: 1.0412 - accuracy: 0.6527 - val_loss: 0.8583 - val_accuracy: 0.7021\n",
      "Epoch 5/12\n",
      "263/263 [==============================] - 110s 418ms/step - loss: 0.9316 - accuracy: 0.6931 - val_loss: 0.7937 - val_accuracy: 0.7260\n",
      "Epoch 6/12\n",
      "263/263 [==============================] - 110s 419ms/step - loss: 0.8593 - accuracy: 0.7226 - val_loss: 0.7215 - val_accuracy: 0.7501\n",
      "Epoch 7/12\n",
      "263/263 [==============================] - 111s 423ms/step - loss: 0.7384 - accuracy: 0.7586 - val_loss: 0.5846 - val_accuracy: 0.8064\n",
      "Epoch 8/12\n",
      "263/263 [==============================] - 111s 422ms/step - loss: 0.7570 - accuracy: 0.7598 - val_loss: 0.5657 - val_accuracy: 0.8180\n",
      "Epoch 9/12\n",
      "263/263 [==============================] - 111s 421ms/step - loss: 0.6643 - accuracy: 0.7845 - val_loss: 0.5332 - val_accuracy: 0.8204\n",
      "Epoch 10/12\n",
      "263/263 [==============================] - 111s 420ms/step - loss: 0.5937 - accuracy: 0.8085 - val_loss: 0.4901 - val_accuracy: 0.8440\n",
      "Epoch 11/12\n",
      "263/263 [==============================] - 110s 419ms/step - loss: 0.5513 - accuracy: 0.8216 - val_loss: 0.5042 - val_accuracy: 0.8311\n",
      "Epoch 12/12\n",
      "263/263 [==============================] - 111s 420ms/step - loss: 0.5433 - accuracy: 0.8237 - val_loss: 0.4064 - val_accuracy: 0.8611\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.4064 - accuracy: 0.8611\n",
      "Test loss: 0.4064244031906128\n",
      "Test accuracy: 0.8611260056495667\n",
      "[    0     1     2 ... 37300 37301 37302] [22383 22384 22385 ... 26110 26111 26112]\n",
      "-----------breaking line--------------\n",
      "----------------------------\n",
      "7\n",
      "----------------------------\n",
      "Epoch 1/12\n",
      "  2/263 [..............................] - ETA: 2:16 - loss: 6.1787 - accuracy: 0.1328WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4062s vs `on_train_batch_end` time: 0.6406s). Check your callbacks.\n",
      "263/263 [==============================] - 111s 421ms/step - loss: 1.9846 - accuracy: 0.3212 - val_loss: 1.4269 - val_accuracy: 0.5048\n",
      "Epoch 2/12\n",
      "263/263 [==============================] - 110s 417ms/step - loss: 1.3962 - accuracy: 0.5080 - val_loss: 1.1340 - val_accuracy: 0.6142\n",
      "Epoch 3/12\n",
      "263/263 [==============================] - 110s 417ms/step - loss: 1.1373 - accuracy: 0.6071 - val_loss: 1.0023 - val_accuracy: 0.6472\n",
      "Epoch 4/12\n",
      "263/263 [==============================] - 110s 418ms/step - loss: 0.9660 - accuracy: 0.6760 - val_loss: 0.8196 - val_accuracy: 0.7322\n",
      "Epoch 5/12\n",
      "263/263 [==============================] - 109s 416ms/step - loss: 0.8804 - accuracy: 0.7128 - val_loss: 0.7832 - val_accuracy: 0.7622\n",
      "Epoch 6/12\n",
      "263/263 [==============================] - 109s 415ms/step - loss: 0.7795 - accuracy: 0.7472 - val_loss: 0.5988 - val_accuracy: 0.8038\n",
      "Epoch 7/12\n",
      "263/263 [==============================] - 108s 409ms/step - loss: 0.6963 - accuracy: 0.7725 - val_loss: 0.6222 - val_accuracy: 0.7954\n",
      "Epoch 8/12\n",
      "263/263 [==============================] - 109s 415ms/step - loss: 0.7479 - accuracy: 0.7637 - val_loss: 0.5307 - val_accuracy: 0.8292\n",
      "Epoch 9/12\n",
      "263/263 [==============================] - 109s 415ms/step - loss: 0.6276 - accuracy: 0.7978 - val_loss: 0.5215 - val_accuracy: 0.8241\n",
      "Epoch 10/12\n",
      "263/263 [==============================] - 109s 416ms/step - loss: 0.5671 - accuracy: 0.8174 - val_loss: 0.4769 - val_accuracy: 0.8378\n",
      "Epoch 11/12\n",
      "263/263 [==============================] - 109s 414ms/step - loss: 0.5176 - accuracy: 0.8319 - val_loss: 0.4366 - val_accuracy: 0.8625\n",
      "Epoch 12/12\n",
      "263/263 [==============================] - 109s 415ms/step - loss: 0.5244 - accuracy: 0.8352 - val_loss: 0.4375 - val_accuracy: 0.8614\n",
      "117/117 [==============================] - 5s 38ms/step - loss: 0.4375 - accuracy: 0.8614\n",
      "Test loss: 0.4374510645866394\n",
      "Test accuracy: 0.8613941073417664\n",
      "[    0     1     2 ... 37300 37301 37302] [26113 26114 26115 ... 29840 29841 29842]\n",
      "-----------breaking line--------------\n",
      "----------------------------\n",
      "8\n",
      "----------------------------\n",
      "Epoch 1/12\n",
      "  2/263 [..............................] - ETA: 3:03 - loss: 6.4710 - accuracy: 0.1172WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4238s vs `on_train_batch_end` time: 0.9858s). Check your callbacks.\n",
      "263/263 [==============================] - 112s 426ms/step - loss: 2.0346 - accuracy: 0.3115 - val_loss: 1.5584 - val_accuracy: 0.4630\n",
      "Epoch 2/12\n",
      "263/263 [==============================] - 111s 424ms/step - loss: 1.4475 - accuracy: 0.4947 - val_loss: 1.1799 - val_accuracy: 0.5912\n",
      "Epoch 3/12\n",
      "263/263 [==============================] - 111s 423ms/step - loss: 1.1975 - accuracy: 0.5959 - val_loss: 1.0350 - val_accuracy: 0.6614\n",
      "Epoch 4/12\n",
      "263/263 [==============================] - 111s 421ms/step - loss: 0.9962 - accuracy: 0.6723 - val_loss: 0.8459 - val_accuracy: 0.7247\n",
      "Epoch 5/12\n",
      "263/263 [==============================] - 110s 419ms/step - loss: 0.8844 - accuracy: 0.7141 - val_loss: 0.7755 - val_accuracy: 0.7493\n",
      "Epoch 6/12\n",
      "263/263 [==============================] - 110s 418ms/step - loss: 0.7776 - accuracy: 0.7516 - val_loss: 0.6898 - val_accuracy: 0.7764\n",
      "Epoch 7/12\n",
      "263/263 [==============================] - 111s 421ms/step - loss: 0.6850 - accuracy: 0.7787 - val_loss: 0.5732 - val_accuracy: 0.8075\n",
      "Epoch 8/12\n",
      "263/263 [==============================] - 111s 422ms/step - loss: 0.6475 - accuracy: 0.7936 - val_loss: 0.5691 - val_accuracy: 0.8102\n",
      "Epoch 9/12\n",
      "263/263 [==============================] - 111s 421ms/step - loss: 0.5648 - accuracy: 0.8184 - val_loss: 0.4892 - val_accuracy: 0.8394\n",
      "Epoch 10/12\n",
      "263/263 [==============================] - 111s 421ms/step - loss: 0.5480 - accuracy: 0.8270 - val_loss: 0.4406 - val_accuracy: 0.8501\n",
      "Epoch 11/12\n",
      "263/263 [==============================] - 111s 421ms/step - loss: 0.5736 - accuracy: 0.8199 - val_loss: 0.4860 - val_accuracy: 0.8424\n",
      "Epoch 12/12\n",
      "263/263 [==============================] - 111s 421ms/step - loss: 0.4845 - accuracy: 0.8488 - val_loss: 0.4158 - val_accuracy: 0.8654\n",
      "117/117 [==============================] - 4s 38ms/step - loss: 0.4158 - accuracy: 0.8654\n",
      "Test loss: 0.4158027768135071\n",
      "Test accuracy: 0.8654155731201172\n",
      "[    0     1     2 ... 37300 37301 37302] [29843 29844 29845 ... 33570 33571 33572]\n",
      "-----------breaking line--------------\n",
      "----------------------------\n",
      "9\n",
      "----------------------------\n",
      "Epoch 1/12\n",
      "  2/263 [..............................] - ETA: 2:54 - loss: 6.0395 - accuracy: 0.1133WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4345s vs `on_train_batch_end` time: 0.9004s). Check your callbacks.\n",
      "263/263 [==============================] - 114s 433ms/step - loss: 2.0045 - accuracy: 0.3140 - val_loss: 1.5655 - val_accuracy: 0.4863\n",
      "Epoch 2/12\n",
      "263/263 [==============================] - 113s 428ms/step - loss: 1.4144 - accuracy: 0.5122 - val_loss: 1.3084 - val_accuracy: 0.5306\n",
      "Epoch 3/12\n",
      "263/263 [==============================] - 111s 423ms/step - loss: 1.1912 - accuracy: 0.5901 - val_loss: 1.0779 - val_accuracy: 0.6327\n",
      "Epoch 4/12\n",
      "263/263 [==============================] - 111s 422ms/step - loss: 1.0273 - accuracy: 0.6544 - val_loss: 0.9566 - val_accuracy: 0.6979\n",
      "Epoch 5/12\n",
      "263/263 [==============================] - 110s 419ms/step - loss: 0.9585 - accuracy: 0.6814 - val_loss: 0.7909 - val_accuracy: 0.7416\n",
      "Epoch 6/12\n",
      "263/263 [==============================] - 111s 422ms/step - loss: 0.8146 - accuracy: 0.7327 - val_loss: 0.7797 - val_accuracy: 0.7525\n",
      "Epoch 7/12\n",
      "263/263 [==============================] - 111s 423ms/step - loss: 0.7354 - accuracy: 0.7594 - val_loss: 0.6675 - val_accuracy: 0.7887\n",
      "Epoch 8/12\n",
      "263/263 [==============================] - 110s 419ms/step - loss: 0.6626 - accuracy: 0.7803 - val_loss: 0.6111 - val_accuracy: 0.8024\n",
      "Epoch 9/12\n",
      "263/263 [==============================] - 111s 420ms/step - loss: 0.6129 - accuracy: 0.7965 - val_loss: 0.5731 - val_accuracy: 0.8196\n",
      "Epoch 10/12\n",
      "263/263 [==============================] - 111s 422ms/step - loss: 0.5748 - accuracy: 0.8118 - val_loss: 0.5611 - val_accuracy: 0.8233\n",
      "Epoch 11/12\n",
      "263/263 [==============================] - 111s 421ms/step - loss: 0.5800 - accuracy: 0.8135 - val_loss: 0.5374 - val_accuracy: 0.8343\n",
      "Epoch 12/12\n",
      "263/263 [==============================] - 111s 422ms/step - loss: 0.5059 - accuracy: 0.8345 - val_loss: 0.5092 - val_accuracy: 0.8402\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.5092 - accuracy: 0.8402\n",
      "Test loss: 0.5091978907585144\n",
      "Test accuracy: 0.8402144908905029\n",
      "[    0     1     2 ... 33570 33571 33572] [33573 33574 33575 ... 37300 37301 37302]\n",
      "-----------breaking line--------------\n",
      "----------------------------\n",
      "10\n",
      "----------------------------\n",
      "Epoch 1/12\n",
      "  2/263 [..............................] - ETA: 2:25 - loss: 8.3300 - accuracy: 0.0938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4248s vs `on_train_batch_end` time: 0.6886s). Check your callbacks.\n",
      "263/263 [==============================] - 114s 433ms/step - loss: 2.0859 - accuracy: 0.2993 - val_loss: 1.5345 - val_accuracy: 0.4550\n",
      "Epoch 2/12\n",
      "263/263 [==============================] - 111s 421ms/step - loss: 1.4331 - accuracy: 0.4940 - val_loss: 1.2325 - val_accuracy: 0.5828\n",
      "Epoch 3/12\n",
      "263/263 [==============================] - 110s 418ms/step - loss: 1.2020 - accuracy: 0.5817 - val_loss: 1.0450 - val_accuracy: 0.6416\n",
      "Epoch 4/12\n",
      "263/263 [==============================] - 110s 418ms/step - loss: 1.0935 - accuracy: 0.6321 - val_loss: 0.9331 - val_accuracy: 0.6914\n",
      "Epoch 5/12\n",
      "263/263 [==============================] - 110s 420ms/step - loss: 0.9280 - accuracy: 0.6883 - val_loss: 0.8565 - val_accuracy: 0.7110\n",
      "Epoch 6/12\n",
      "263/263 [==============================] - 111s 421ms/step - loss: 0.8479 - accuracy: 0.7183 - val_loss: 0.7568 - val_accuracy: 0.7472\n",
      "Epoch 7/12\n",
      "263/263 [==============================] - 110s 419ms/step - loss: 0.7779 - accuracy: 0.7427 - val_loss: 0.7032 - val_accuracy: 0.7654\n",
      "Epoch 8/12\n",
      "263/263 [==============================] - 110s 419ms/step - loss: 0.6842 - accuracy: 0.7754 - val_loss: 0.6550 - val_accuracy: 0.7799\n",
      "Epoch 9/12\n",
      "263/263 [==============================] - 110s 417ms/step - loss: 0.6441 - accuracy: 0.7903 - val_loss: 0.6546 - val_accuracy: 0.7909\n",
      "Epoch 10/12\n",
      "263/263 [==============================] - 110s 419ms/step - loss: 0.6195 - accuracy: 0.7965 - val_loss: 0.6181 - val_accuracy: 0.7893\n",
      "Epoch 11/12\n",
      "263/263 [==============================] - 110s 417ms/step - loss: 0.5570 - accuracy: 0.8190 - val_loss: 0.6812 - val_accuracy: 0.7855\n",
      "Epoch 12/12\n",
      "263/263 [==============================] - 110s 418ms/step - loss: 0.5260 - accuracy: 0.8271 - val_loss: 0.5731 - val_accuracy: 0.8102\n",
      "117/117 [==============================] - 5s 39ms/step - loss: 0.5731 - accuracy: 0.8102\n",
      "Test loss: 0.5731205344200134\n",
      "Test accuracy: 0.8101876378059387\n"
     ]
    }
   ],
   "source": [
    "for train_set, test_set in kf.split(dataset):\n",
    "     print( train_set, test_set)\n",
    "     print(\"-----------breaking line--------------\")\n",
    "     #X_train, X_test, y_train, y_test = dataset[train_set], dataset[test_set]\n",
    " \n",
    "     print('----------------------------')\n",
    "     count += 1\n",
    "     print(count)\n",
    "     print('----------------------------')\n",
    " \n",
    "     X_train,y_train = zip(*dataset[train_set])\n",
    "     X_test, y_test = zip(*dataset[test_set])\n",
    " \n",
    "     # Reshape for CNN input\n",
    "     X_train = np.array([x.reshape( (128, 128, 1) ) for x in X_train])\n",
    "     X_test = np.array([x.reshape( (128, 128, 1) ) for x in X_test])\n",
    " \n",
    "     # One-Hot encoding for classes\n",
    "     y_train = np.array(keras.utils.to_categorical(y_train, 10))\n",
    "     y_test = np.array(keras.utils.to_categorical(y_test, 10))\n",
    " \n",
    "     NAME = \"graphic-{}\".format(int(time.time()))\n",
    "     tensorboard = TensorBoard(log_dir='logs{}'.format(NAME +  str(count)))\n",
    " \n",
    " \n",
    "     model = Sequential()\n",
    "     input_shape=(128, 128, 1)\n",
    " \n",
    "     model.add(Conv2D(24, (5, 5), strides=(1, 1), input_shape=input_shape))\n",
    "     model.add(MaxPooling2D((4, 2), strides=(4, 2)))\n",
    "     model.add(Activation('relu'))\n",
    " \n",
    "     model.add(Conv2D(48, (5, 5), padding=\"valid\"))\n",
    "     model.add(MaxPooling2D((4, 2), strides=(4, 2)))\n",
    "     model.add(Activation('relu'))\n",
    " \n",
    "     model.add(Conv2D(48, (5, 5), padding=\"valid\"))\n",
    "     model.add(Activation('relu'))\n",
    " \n",
    "     model.add(Flatten())\n",
    "     model.add(Dropout(rate=0.5))\n",
    " \n",
    "     model.add(Dense(64))\n",
    "     model.add(Activation('relu'))\n",
    "     model.add(Dropout(rate=0.5))\n",
    " \n",
    "     model.add(Dense(10))\n",
    "     model.add(Activation('softmax'))\n",
    " \n",
    "     #convnet = tflearn.DNN(model, tensorboard_dir='log')\n",
    " \n",
    "     model.compile(\n",
    " \t    optimizer=\"Adam\",\n",
    " \t    loss=\"categorical_crossentropy\",\n",
    " \t    metrics=['accuracy']\n",
    "        )\n",
    " \n",
    "     model.fit(\n",
    " \t    x=X_train, \n",
    " \t    y=y_train,\n",
    "        epochs=12,\n",
    "        batch_size=128,\n",
    "        validation_data= (X_test, y_test),\n",
    " \t    callbacks=[tensorboard]\n",
    " \t    )\n",
    " \n",
    "     score = model.evaluate(\n",
    " \t    x=X_test,\n",
    " \t    y=y_test\n",
    "        )\n",
    " \n",
    "     print('Test loss:', score[0])\n",
    "     print('Test accuracy:', score[1])\n",
    "\n",
    "\n",
    "#model.save('SoundClassification.model')\n",
    "\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopExecution",
     "evalue": "",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "class StopExecution(Exception):\n",
    "    def _render_traceback_(self):\n",
    "        pass\n",
    "\n",
    "raise StopExecution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"SoundClassification.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_39 (Conv2D)           (None, 124, 124, 24)      624       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 31, 62, 24)        0         \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 31, 62, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 27, 58, 48)        28848     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 6, 29, 48)         0         \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 6, 29, 48)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 2, 25, 48)         57648     \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 2, 25, 48)         0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 2400)              0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 2400)              0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 64)                153664    \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 241,434\n",
      "Trainable params: 241,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(filepath):\n",
    "    y, sr = librosa.load(filepath, duration=2.97)\n",
    "    ps = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "    ps.shape\n",
    "    if ps.shape != (128,128):\n",
    "        new_image_width = 128\n",
    "        new_image_height = 128\n",
    "        color = (0)\n",
    "        result = np.full((new_image_height,new_image_width, 1), color, dtype=np.uint8)\n",
    "        return result.reshape(-1, 128, 128, 1)\n",
    "\n",
    "    else:\n",
    "        return ps.reshape(-1, 128, 128, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "['AC_0.wav', 'CarHorn_1.wav', 'ChildrenPlaying_2.wav', 'DogBark_3.wav', 'Drill_4.wav', 'EngineIdling_5_2.wav', 'GunShot_6.wav', 'Jackhammer_7.wav', 'Siren_8.wav', 'StreetMusic_9.wav']\n"
     ]
    }
   ],
   "source": [
    "from os import walk\n",
    "\n",
    "mypath = 'Test/'\n",
    "f = []\n",
    "for (dirpath, dirnames, filenames) in walk(mypath):\n",
    "    f.extend(filenames)\n",
    "    break\n",
    "print(len(f))\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 th\n",
      "AC_0.wav\n",
      "Match accuracy: 0.9998098\n",
      "class: [0]\n",
      "[[9.99809802e-01 2.70643397e-09 4.41718475e-06 5.53512280e-07\n",
      "  3.20673280e-07 8.20838977e-05 4.13059073e-13 6.39630713e-08\n",
      "  1.17617034e-07 1.02443548e-04]]\n",
      "-----------------------\n",
      "2 th\n",
      "CarHorn_1.wav\n",
      "Match accuracy: 0.4805191\n",
      "class: [1]\n",
      "[[0.00645272 0.4805191  0.10963776 0.03157154 0.10333343 0.00288624\n",
      "  0.00109647 0.0019503  0.02308445 0.23946798]]\n",
      "-----------------------\n",
      "3 th\n",
      "ChildrenPlaying_2.wav\n",
      "Match accuracy: 0.7953603\n",
      "class: [2]\n",
      "[[4.4691302e-03 6.1881873e-03 7.9536033e-01 7.2379373e-02 7.9130955e-02\n",
      "  7.6757849e-04 9.7827622e-05 2.4308448e-04 3.8589225e-03 3.7504550e-02]]\n",
      "-----------------------\n",
      "4 th\n",
      "DogBark_3.wav\n",
      "Match accuracy: 1.0\n",
      "class: [3]\n",
      "[[1.05189425e-26 0.00000000e+00 2.65052402e-09 1.00000000e+00\n",
      "  9.17498966e-28 1.61384472e-21 5.58384245e-34 0.00000000e+00\n",
      "  6.58862350e-32 1.16946660e-22]]\n",
      "-----------------------\n",
      "5 th\n",
      "Drill_4.wav\n",
      "Match accuracy: 0.99755186\n",
      "class: [4]\n",
      "[[1.7529866e-04 1.7387159e-06 8.4873165e-05 1.6416368e-04 9.9755186e-01\n",
      "  2.9186212e-06 7.3047090e-08 1.9781131e-03 5.3993053e-06 3.5529236e-05]]\n",
      "-----------------------\n",
      "6 th\n",
      "EngineIdling_5_2.wav\n",
      "Match accuracy: 1.0\n",
      "class: [5]\n",
      "[[2.40171314e-08 1.32762592e-18 1.02906765e-13 9.06072006e-12\n",
      "  2.46908310e-11 1.00000000e+00 5.39704616e-23 2.26570407e-09\n",
      "  6.34780076e-11 4.04132153e-12]]\n",
      "-----------------------\n",
      "7 th\n",
      "GunShot_6.wav\n",
      "Match accuracy: 0.9999852\n",
      "class: [6]\n",
      "[[1.3972716e-10 2.5905389e-09 1.4543739e-05 1.7851914e-07 1.8411422e-08\n",
      "  1.0126465e-09 9.9998522e-01 4.6923127e-15 2.2173353e-13 2.5093390e-08]]\n",
      "-----------------------\n",
      "8 th\n",
      "Jackhammer_7.wav\n",
      "Match accuracy: 0.9832865\n",
      "class: [7]\n",
      "[[1.0003986e-05 2.9291201e-07 2.5465971e-07 1.6532484e-06 1.6701208e-02\n",
      "  7.8884327e-08 3.9900770e-15 9.8328650e-01 1.1997524e-13 1.3457012e-08]]\n",
      "-----------------------\n",
      "9 th\n",
      "Siren_8.wav\n",
      "Match accuracy: 0.7903103\n",
      "class: [8]\n",
      "[[5.3352069e-06 4.3723211e-04 1.3438669e-04 8.6311993e-05 3.3539305e-05\n",
      "  9.8828405e-06 2.5291492e-06 9.7866439e-07 7.9031032e-01 2.0897956e-01]]\n",
      "-----------------------\n",
      "10 th\n",
      "StreetMusic_9.wav\n",
      "Match accuracy: 1.0\n",
      "class: [9]\n",
      "[[4.4842861e-16 5.0269719e-24 1.2808934e-24 6.2301675e-22 7.2903819e-32\n",
      "  2.7576952e-14 0.0000000e+00 3.9086707e-30 4.3332066e-24 1.0000000e+00]]\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for file in f:\n",
    "    count += 1\n",
    "    prediction = model.predict([prepare('Test/'+file)])\n",
    "    y_classes = prediction.argmax(axis=-1)\n",
    "    max = np.amax(prediction)\n",
    "    print(str(count) + \" th\")\n",
    "    print(file)\n",
    "    print(\"Match accuracy: \" + str(max))\n",
    "    print(\"class: \" + str(y_classes))\n",
    "    print(prediction)\n",
    "    print(\"-----------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
