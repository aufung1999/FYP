{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Activation, Dense, Dropout, Conv1D, \\\n",
    "                         Flatten, MaxPooling1D\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import TensorBoard\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice_file_name</th>\n",
       "      <th>fsID</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>salience</th>\n",
       "      <th>fold</th>\n",
       "      <th>classID</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100032-3-0-0.wav</td>\n",
       "      <td>100032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.317551</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100263-2-0-117.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>58.5</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100263-2-0-121.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>60.5</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100263-2-0-126.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>63.0</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100263-2-0-137.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>68.5</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      slice_file_name    fsID  start        end  salience  fold  classID  \\\n",
       "0    100032-3-0-0.wav  100032    0.0   0.317551         1     5        3   \n",
       "1  100263-2-0-117.wav  100263   58.5  62.500000         1     5        2   \n",
       "2  100263-2-0-121.wav  100263   60.5  64.500000         1     5        2   \n",
       "3  100263-2-0-126.wav  100263   63.0  67.000000         1     5        2   \n",
       "4  100263-2-0-137.wav  100263   68.5  72.500000         1     5        2   \n",
       "\n",
       "              class  \n",
       "0          dog_bark  \n",
       "1  children_playing  \n",
       "2  children_playing  \n",
       "3  children_playing  \n",
       "4  children_playing  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Data\n",
    "data = pd.read_csv('UrbanSounds8K/metadata/UrbanSound8K.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8732, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7468, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get data over 3 seconds long\n",
    "valid_data = data[['slice_file_name', 'fold' ,'classID', 'class']][ data['end']-data['start'] >= 3 ]\n",
    "valid_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<librosa.display.AdaptiveWaveplot at 0x1db76419e08>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y, sr = librosa.load('UrbanSounds8K/audio/fold9/13579-2-0-16.wav', mono=True ,duration=3)\n",
    "fig, ax = plt.subplots(nrows=1, sharex=True)\n",
    "librosa.display.waveshow(y, sr=sr, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data['path'] = 'fold' + valid_data['fold'].astype('str') + '/' + valid_data['slice_file_name'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\OTSANY~1\\AppData\\Local\\Temp\\2/ipykernel_7964/3049176910.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'raw_train_data.npy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m###############################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mD\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreates_train_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\OTSANY~1\\AppData\\Local\\Temp\\2/ipykernel_7964/3049176910.py\u001b[0m in \u001b[0;36mcreates_train_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalid_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitertuples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'UrbanSounds8K/audio/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#2.97 = 3*1000 - 3*1000/128  ###############################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassID\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'raw_train_data.npy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m###############################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\backup_20220216\\lib\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr_native\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\backup_20220216\\lib\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36mresample\u001b[1;34m(y, orig_sr, target_sr, res_type, fix, scale, **kwargs)\u001b[0m\n\u001b[0;32m    602\u001b[0m         \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoxr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morig_sr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_sr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquality\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    603\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 604\u001b[1;33m         \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresampy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morig_sr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_sr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    605\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfix\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\backup_20220216\\lib\\site-packages\\resampy\\core.py\u001b[0m in \u001b[0;36mresample\u001b[1;34m(x, sr_orig, sr_new, axis, filter, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[0mx_2d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[0my_2d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m     \u001b[0mresample_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_ratio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterp_win\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterp_delta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Use it to create data ######################################################################\n",
    "def creates_train_data():\n",
    "    D = [] # Dataset\n",
    "\n",
    "    for row in valid_data.itertuples():\n",
    "        y, sr = librosa.load('UrbanSounds8K/audio/' + row.path, duration=3)  #2.97 = 3*1000 - 3*1000/128  ###############################\n",
    "        D.append( (y, row.classID) )\n",
    "    np.save('raw_train_data.npy', D) ###############################\n",
    "    return D\n",
    "D = creates_train_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each time if you want to create a new '.npy' file \n",
    "MAKE SURE you delete the previous(old) one in the directory!!!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of samples: \", len(D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopExecution",
     "evalue": "",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "class StopExecution(Exception):\n",
    "    def _render_traceback_(self):\n",
    "        pass\n",
    "\n",
    "raise StopExecution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37303"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load.__defaults__=(None, True, True, 'ASCII')\n",
    "a = np.load('raw_train_data.npy')\n",
    "a = np.load('train_data.npy')\n",
    "b = np.load('train_data_augmented_speed_81.npy')\n",
    "c = np.load('train_data_augmented_speed_107.npy')\n",
    "d = np.load('train_data_augmented_ps1_2.npy')\n",
    "e = np.load('train_data_augmented_ps2_m25.npy')\n",
    "#np.savez('train.npz',a,b,c,d,e) ############################################################################\n",
    "#r = np.load('train.npz') ############################################################################\n",
    "#locals().update(r) ############################################################################\n",
    "tuple = (a,b,c,d,e)\n",
    "tuplearr = np.vstack(tuple)\n",
    "# np.load.__defaults__=(None, True, True, 'ASCII')\n",
    "# a = np.load('raw_train_data.npy')\n",
    "dataset = tuplearr\n",
    "random.shuffle(dataset)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a[746][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To see how many samples are in X-train and y-train\n",
    "kf = KFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3731  3732  3733 ... 37300 37301 37302] [   0    1    2 ... 3728 3729 3730]\n",
      "-----------breaking line--------------\n",
      "----------------------------\n",
      "1\n",
      "----------------------------\n",
      "Epoch 1/12\n",
      "  1/263 [..............................] - ETA: 0s - loss: 6.7486 - accuracy: 0.0625WARNING:tensorflow:From C:\\Users\\Guest1\\anaconda3\\envs\\backup_20220216_20220322\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "263/263 [==============================] - 91s 346ms/step - loss: 1.6981 - accuracy: 0.4279 - val_loss: 0.9290 - val_accuracy: 0.7100\n",
      "Epoch 2/12\n",
      "263/263 [==============================] - 89s 337ms/step - loss: 1.1739 - accuracy: 0.5985 - val_loss: 0.6754 - val_accuracy: 0.7858\n",
      "Epoch 3/12\n",
      "263/263 [==============================] - 88s 333ms/step - loss: 0.9805 - accuracy: 0.6706 - val_loss: 0.5093 - val_accuracy: 0.8408\n",
      "Epoch 4/12\n",
      "263/263 [==============================] - 87s 332ms/step - loss: 0.8912 - accuracy: 0.7037 - val_loss: 0.4197 - val_accuracy: 0.8604\n",
      "Epoch 5/12\n",
      "263/263 [==============================] - 88s 335ms/step - loss: 0.8139 - accuracy: 0.7322 - val_loss: 0.3824 - val_accuracy: 0.8914\n",
      "Epoch 6/12\n",
      "263/263 [==============================] - 89s 337ms/step - loss: 0.7320 - accuracy: 0.7569 - val_loss: 0.3034 - val_accuracy: 0.9137\n",
      "Epoch 7/12\n",
      "263/263 [==============================] - 87s 330ms/step - loss: 0.6817 - accuracy: 0.7725 - val_loss: 0.2967 - val_accuracy: 0.9107\n",
      "Epoch 8/12\n",
      "263/263 [==============================] - 87s 331ms/step - loss: 0.6820 - accuracy: 0.7793 - val_loss: 0.2553 - val_accuracy: 0.9142\n",
      "Epoch 9/12\n",
      "263/263 [==============================] - 87s 331ms/step - loss: 0.6192 - accuracy: 0.7961 - val_loss: 0.2102 - val_accuracy: 0.9410\n",
      "Epoch 10/12\n",
      "263/263 [==============================] - 87s 332ms/step - loss: 0.5837 - accuracy: 0.8063 - val_loss: 0.2166 - val_accuracy: 0.9359\n",
      "Epoch 11/12\n",
      "263/263 [==============================] - 88s 336ms/step - loss: 0.5819 - accuracy: 0.8095 - val_loss: 0.1635 - val_accuracy: 0.9550\n",
      "Epoch 12/12\n",
      "263/263 [==============================] - 89s 340ms/step - loss: 0.5166 - accuracy: 0.8256 - val_loss: 0.1590 - val_accuracy: 0.9568\n",
      "117/117 [==============================] - 2s 18ms/step - loss: 0.1590 - accuracy: 0.9568\n",
      "Test loss: 0.15898747742176056\n",
      "Test accuracy: 0.9568480253219604\n",
      "[    0     1     2 ... 37300 37301 37302] [3731 3732 3733 ... 7459 7460 7461]\n",
      "-----------breaking line--------------\n",
      "----------------------------\n",
      "2\n",
      "----------------------------\n",
      "Epoch 1/12\n",
      "  2/263 [..............................] - ETA: 2:34 - loss: 5.2137 - accuracy: 0.1328WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4101s vs `on_train_batch_end` time: 0.7719s). Check your callbacks.\n",
      "263/263 [==============================] - 97s 370ms/step - loss: 1.7123 - accuracy: 0.4276 - val_loss: 1.0709 - val_accuracy: 0.6636\n",
      "Epoch 2/12\n",
      "263/263 [==============================] - 91s 348ms/step - loss: 1.1886 - accuracy: 0.5897 - val_loss: 0.8143 - val_accuracy: 0.7245\n",
      "Epoch 3/12\n",
      "263/263 [==============================] - 87s 330ms/step - loss: 1.0343 - accuracy: 0.6495 - val_loss: 0.6142 - val_accuracy: 0.8161\n",
      "Epoch 4/12\n",
      "263/263 [==============================] - 87s 333ms/step - loss: 0.9270 - accuracy: 0.6914 - val_loss: 0.5902 - val_accuracy: 0.8432\n",
      "Epoch 5/12\n",
      "263/263 [==============================] - 87s 330ms/step - loss: 0.8387 - accuracy: 0.7216 - val_loss: 0.4544 - val_accuracy: 0.8727\n",
      "Epoch 6/12\n",
      "263/263 [==============================] - 88s 334ms/step - loss: 0.7853 - accuracy: 0.7397 - val_loss: 0.4061 - val_accuracy: 0.8888\n",
      "Epoch 7/12\n",
      "263/263 [==============================] - 89s 340ms/step - loss: 0.7062 - accuracy: 0.7641 - val_loss: 0.3736 - val_accuracy: 0.8909\n",
      "Epoch 8/12\n",
      "263/263 [==============================] - 87s 330ms/step - loss: 0.6751 - accuracy: 0.7760 - val_loss: 0.3253 - val_accuracy: 0.9062\n",
      "Epoch 9/12\n",
      "263/263 [==============================] - 87s 331ms/step - loss: 0.6336 - accuracy: 0.7887 - val_loss: 0.2935 - val_accuracy: 0.9129\n",
      "Epoch 10/12\n",
      "263/263 [==============================] - 90s 342ms/step - loss: 0.5849 - accuracy: 0.8059 - val_loss: 0.2649 - val_accuracy: 0.9233\n",
      "Epoch 11/12\n",
      "263/263 [==============================] - 89s 337ms/step - loss: 0.5468 - accuracy: 0.8181 - val_loss: 0.2553 - val_accuracy: 0.9284\n",
      "Epoch 12/12\n",
      "263/263 [==============================] - 89s 337ms/step - loss: 0.5320 - accuracy: 0.8234 - val_loss: 0.2331 - val_accuracy: 0.9338\n",
      "117/117 [==============================] - 2s 18ms/step - loss: 0.2331 - accuracy: 0.9338\n",
      "Test loss: 0.23314128816127777\n",
      "Test accuracy: 0.9337978959083557\n",
      "[    0     1     2 ... 37300 37301 37302] [ 7462  7463  7464 ... 11190 11191 11192]\n",
      "-----------breaking line--------------\n",
      "----------------------------\n",
      "3\n",
      "----------------------------\n",
      "Epoch 1/12\n",
      "  2/263 [..............................] - ETA: 2:41 - loss: 6.2553 - accuracy: 0.1289WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.4420s vs `on_train_batch_end` time: 0.7921s). Check your callbacks.\n",
      "263/263 [==============================] - 91s 348ms/step - loss: 1.6468 - accuracy: 0.4612 - val_loss: 1.0294 - val_accuracy: 0.6773\n",
      "Epoch 2/12\n",
      "263/263 [==============================] - 89s 338ms/step - loss: 1.1109 - accuracy: 0.6265 - val_loss: 0.7552 - val_accuracy: 0.7598\n",
      "Epoch 3/12\n",
      "263/263 [==============================] - 87s 331ms/step - loss: 0.9470 - accuracy: 0.6885 - val_loss: 0.6872 - val_accuracy: 0.7775\n",
      "Epoch 4/12\n",
      "263/263 [==============================] - 87s 330ms/step - loss: 0.8456 - accuracy: 0.7212 - val_loss: 0.5511 - val_accuracy: 0.8145\n",
      "Epoch 5/12\n",
      "263/263 [==============================] - 85s 324ms/step - loss: 0.7628 - accuracy: 0.7506 - val_loss: 0.4932 - val_accuracy: 0.8365\n",
      "Epoch 6/12\n",
      "263/263 [==============================] - 85s 323ms/step - loss: 0.7282 - accuracy: 0.7592 - val_loss: 0.4654 - val_accuracy: 0.8542\n",
      "Epoch 7/12\n",
      "263/263 [==============================] - 85s 323ms/step - loss: 0.6473 - accuracy: 0.7849 - val_loss: 0.4083 - val_accuracy: 0.8673\n",
      "Epoch 8/12\n",
      "263/263 [==============================] - 85s 324ms/step - loss: 0.6223 - accuracy: 0.7971 - val_loss: 0.3632 - val_accuracy: 0.8842\n",
      "Epoch 9/12\n",
      "263/263 [==============================] - 85s 323ms/step - loss: 0.5764 - accuracy: 0.8089 - val_loss: 0.3261 - val_accuracy: 0.8925\n",
      "Epoch 10/12\n",
      "263/263 [==============================] - 85s 323ms/step - loss: 0.5712 - accuracy: 0.8144 - val_loss: 0.3083 - val_accuracy: 0.8909\n",
      "Epoch 11/12\n",
      "263/263 [==============================] - 85s 322ms/step - loss: 0.5195 - accuracy: 0.8288 - val_loss: 0.2982 - val_accuracy: 0.8987\n",
      "Epoch 12/12\n",
      "263/263 [==============================] - 85s 322ms/step - loss: 0.4858 - accuracy: 0.8376 - val_loss: 0.2572 - val_accuracy: 0.9228\n",
      "117/117 [==============================] - 2s 17ms/step - loss: 0.2572 - accuracy: 0.9228\n",
      "Test loss: 0.25720885396003723\n",
      "Test accuracy: 0.9228088855743408\n",
      "[    0     1     2 ... 37300 37301 37302] [11193 11194 11195 ... 14920 14921 14922]\n",
      "-----------breaking line--------------\n",
      "----------------------------\n",
      "4\n",
      "----------------------------\n",
      "Epoch 1/12\n",
      "263/263 [==============================] - 89s 337ms/step - loss: 1.7043 - accuracy: 0.4382 - val_loss: 1.0729 - val_accuracy: 0.6802\n",
      "Epoch 2/12\n",
      "263/263 [==============================] - 87s 331ms/step - loss: 1.1597 - accuracy: 0.6144 - val_loss: 0.8309 - val_accuracy: 0.7244\n",
      "Epoch 3/12\n",
      "263/263 [==============================] - 85s 325ms/step - loss: 0.9624 - accuracy: 0.6798 - val_loss: 0.7606 - val_accuracy: 0.7751\n",
      "Epoch 4/12\n",
      "263/263 [==============================] - 86s 328ms/step - loss: 0.8768 - accuracy: 0.7142 - val_loss: 0.6024 - val_accuracy: 0.8110\n",
      "Epoch 5/12\n",
      "263/263 [==============================] - 86s 327ms/step - loss: 0.7765 - accuracy: 0.7462 - val_loss: 0.5207 - val_accuracy: 0.8357\n",
      "Epoch 6/12\n",
      "263/263 [==============================] - 85s 325ms/step - loss: 0.7111 - accuracy: 0.7678 - val_loss: 0.4763 - val_accuracy: 0.8445\n",
      "Epoch 7/12\n",
      "263/263 [==============================] - 86s 326ms/step - loss: 0.6672 - accuracy: 0.7820 - val_loss: 0.4171 - val_accuracy: 0.8745\n",
      "Epoch 8/12\n",
      "263/263 [==============================] - 86s 326ms/step - loss: 0.6313 - accuracy: 0.7953 - val_loss: 0.3793 - val_accuracy: 0.8783\n",
      "Epoch 9/12\n",
      "263/263 [==============================] - 85s 324ms/step - loss: 0.5659 - accuracy: 0.8138 - val_loss: 0.4011 - val_accuracy: 0.8839\n",
      "Epoch 10/12\n",
      "263/263 [==============================] - 86s 327ms/step - loss: 0.5341 - accuracy: 0.8241 - val_loss: 0.2991 - val_accuracy: 0.9075\n",
      "Epoch 11/12\n",
      "263/263 [==============================] - 86s 327ms/step - loss: 0.5394 - accuracy: 0.8238 - val_loss: 0.2833 - val_accuracy: 0.9161\n",
      "Epoch 12/12\n",
      "263/263 [==============================] - 86s 328ms/step - loss: 0.4830 - accuracy: 0.8418 - val_loss: 0.3398 - val_accuracy: 0.8941\n",
      "117/117 [==============================] - 2s 17ms/step - loss: 0.3398 - accuracy: 0.8941\n",
      "Test loss: 0.3398294448852539\n",
      "Test accuracy: 0.8941018581390381\n",
      "[    0     1     2 ... 37300 37301 37302] [14923 14924 14925 ... 18650 18651 18652]\n",
      "-----------breaking line--------------\n",
      "----------------------------\n",
      "5\n",
      "----------------------------\n",
      "Epoch 1/12\n",
      "  2/263 [..............................] - ETA: 2:35 - loss: 7.6494 - accuracy: 0.1719WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.3942s vs `on_train_batch_end` time: 0.7996s). Check your callbacks.\n",
      "263/263 [==============================] - 95s 359ms/step - loss: 1.6712 - accuracy: 0.4579 - val_loss: 1.0777 - val_accuracy: 0.6614\n",
      "Epoch 2/12\n",
      "263/263 [==============================] - 88s 336ms/step - loss: 1.1218 - accuracy: 0.6241 - val_loss: 0.8396 - val_accuracy: 0.7389\n",
      "Epoch 3/12\n",
      "263/263 [==============================] - 86s 328ms/step - loss: 0.9602 - accuracy: 0.6802 - val_loss: 0.6837 - val_accuracy: 0.7802\n",
      "Epoch 4/12\n",
      "263/263 [==============================] - 86s 327ms/step - loss: 0.8416 - accuracy: 0.7241 - val_loss: 0.6036 - val_accuracy: 0.8107\n",
      "Epoch 5/12\n",
      "263/263 [==============================] - 86s 327ms/step - loss: 0.7827 - accuracy: 0.7455 - val_loss: 0.5056 - val_accuracy: 0.8440\n",
      "Epoch 6/12\n",
      "263/263 [==============================] - 86s 327ms/step - loss: 0.7018 - accuracy: 0.7698 - val_loss: 0.4761 - val_accuracy: 0.8485\n",
      "Epoch 7/12\n",
      "263/263 [==============================] - 86s 328ms/step - loss: 0.6420 - accuracy: 0.7874 - val_loss: 0.4198 - val_accuracy: 0.8710\n",
      "Epoch 8/12\n",
      "263/263 [==============================] - 86s 327ms/step - loss: 0.5978 - accuracy: 0.8019 - val_loss: 0.3827 - val_accuracy: 0.8729\n",
      "Epoch 9/12\n",
      "263/263 [==============================] - 86s 328ms/step - loss: 0.5768 - accuracy: 0.8139 - val_loss: 0.3664 - val_accuracy: 0.8871\n",
      "Epoch 10/12\n",
      "263/263 [==============================] - 87s 329ms/step - loss: 0.5521 - accuracy: 0.8164 - val_loss: 0.3060 - val_accuracy: 0.8995\n",
      "Epoch 11/12\n",
      "263/263 [==============================] - 87s 331ms/step - loss: 0.5200 - accuracy: 0.8290 - val_loss: 0.3074 - val_accuracy: 0.9051\n",
      "Epoch 12/12\n",
      "263/263 [==============================] - 86s 327ms/step - loss: 0.4918 - accuracy: 0.8375 - val_loss: 0.2930 - val_accuracy: 0.9067\n",
      "117/117 [==============================] - 2s 17ms/step - loss: 0.2930 - accuracy: 0.9067\n",
      "Test loss: 0.2930349111557007\n",
      "Test accuracy: 0.9067023992538452\n",
      "[    0     1     2 ... 37300 37301 37302] [18653 18654 18655 ... 22380 22381 22382]\n",
      "-----------breaking line--------------\n",
      "----------------------------\n",
      "6\n",
      "----------------------------\n",
      "Epoch 1/12\n",
      "263/263 [==============================] - 89s 338ms/step - loss: 1.6851 - accuracy: 0.4440 - val_loss: 1.1359 - val_accuracy: 0.6488\n",
      "Epoch 2/12\n",
      "263/263 [==============================] - 87s 331ms/step - loss: 1.1290 - accuracy: 0.6220 - val_loss: 0.8071 - val_accuracy: 0.7477\n",
      "Epoch 3/12\n",
      "263/263 [==============================] - 86s 329ms/step - loss: 0.9571 - accuracy: 0.6821 - val_loss: 0.7136 - val_accuracy: 0.7853\n",
      "Epoch 4/12\n",
      "263/263 [==============================] - 88s 334ms/step - loss: 0.8443 - accuracy: 0.7254 - val_loss: 0.6003 - val_accuracy: 0.8123\n",
      "Epoch 5/12\n",
      "263/263 [==============================] - 88s 333ms/step - loss: 0.7727 - accuracy: 0.7470 - val_loss: 0.5649 - val_accuracy: 0.8201\n",
      "Epoch 6/12\n",
      "263/263 [==============================] - 91s 345ms/step - loss: 0.7199 - accuracy: 0.7656 - val_loss: 0.4883 - val_accuracy: 0.8528\n",
      "Epoch 7/12\n",
      "263/263 [==============================] - 89s 338ms/step - loss: 0.6326 - accuracy: 0.7897 - val_loss: 0.4767 - val_accuracy: 0.8461\n",
      "Epoch 8/12\n",
      "263/263 [==============================] - 89s 338ms/step - loss: 0.6126 - accuracy: 0.8004 - val_loss: 0.4045 - val_accuracy: 0.8692\n",
      "Epoch 9/12\n",
      "263/263 [==============================] - 89s 337ms/step - loss: 0.5778 - accuracy: 0.8139 - val_loss: 0.3725 - val_accuracy: 0.8855\n",
      "Epoch 10/12\n",
      "263/263 [==============================] - 87s 332ms/step - loss: 0.5313 - accuracy: 0.8230 - val_loss: 0.3238 - val_accuracy: 0.8962\n",
      "Epoch 11/12\n",
      "263/263 [==============================] - 86s 329ms/step - loss: 0.5109 - accuracy: 0.8317 - val_loss: 0.3241 - val_accuracy: 0.9075\n",
      "Epoch 12/12\n",
      "263/263 [==============================] - 85s 322ms/step - loss: 0.4840 - accuracy: 0.8419 - val_loss: 0.3048 - val_accuracy: 0.9000\n",
      "117/117 [==============================] - 2s 17ms/step - loss: 0.3048 - accuracy: 0.9000\n",
      "Test loss: 0.3047846555709839\n",
      "Test accuracy: 0.8999999761581421\n",
      "[    0     1     2 ... 37300 37301 37302] [22383 22384 22385 ... 26110 26111 26112]\n",
      "-----------breaking line--------------\n",
      "----------------------------\n",
      "7\n",
      "----------------------------\n",
      "Epoch 1/12\n",
      "263/263 [==============================] - 96s 366ms/step - loss: 1.6524 - accuracy: 0.4622 - val_loss: 1.1217 - val_accuracy: 0.6531\n",
      "Epoch 2/12\n",
      "263/263 [==============================] - 94s 357ms/step - loss: 1.1214 - accuracy: 0.6251 - val_loss: 0.8138 - val_accuracy: 0.7370\n",
      "Epoch 3/12\n",
      "263/263 [==============================] - 92s 351ms/step - loss: 0.9582 - accuracy: 0.6859 - val_loss: 0.7758 - val_accuracy: 0.7445\n",
      "Epoch 4/12\n",
      "263/263 [==============================] - 93s 352ms/step - loss: 0.8837 - accuracy: 0.7124 - val_loss: 0.6705 - val_accuracy: 0.7898\n",
      "Epoch 5/12\n",
      "263/263 [==============================] - 92s 351ms/step - loss: 0.7723 - accuracy: 0.7435 - val_loss: 0.5948 - val_accuracy: 0.8113\n",
      "Epoch 6/12\n",
      "263/263 [==============================] - 93s 352ms/step - loss: 0.7298 - accuracy: 0.7578 - val_loss: 0.5218 - val_accuracy: 0.8330\n",
      "Epoch 7/12\n",
      "263/263 [==============================] - 93s 354ms/step - loss: 0.6822 - accuracy: 0.7776 - val_loss: 0.5088 - val_accuracy: 0.8346\n",
      "Epoch 8/12\n",
      "263/263 [==============================] - 93s 353ms/step - loss: 0.6324 - accuracy: 0.7928 - val_loss: 0.4307 - val_accuracy: 0.8611\n",
      "Epoch 9/12\n",
      "263/263 [==============================] - 93s 356ms/step - loss: 0.6032 - accuracy: 0.8004 - val_loss: 0.4037 - val_accuracy: 0.8633\n",
      "Epoch 10/12\n",
      "263/263 [==============================] - 93s 352ms/step - loss: 0.5953 - accuracy: 0.8076 - val_loss: 0.4279 - val_accuracy: 0.8641\n",
      "Epoch 11/12\n",
      "263/263 [==============================] - 93s 353ms/step - loss: 0.5403 - accuracy: 0.8201 - val_loss: 0.3639 - val_accuracy: 0.8834\n",
      "Epoch 12/12\n",
      "263/263 [==============================] - 92s 351ms/step - loss: 0.5041 - accuracy: 0.8316 - val_loss: 0.3524 - val_accuracy: 0.8820\n",
      "117/117 [==============================] - 2s 18ms/step - loss: 0.3524 - accuracy: 0.8820\n",
      "Test loss: 0.3523710072040558\n",
      "Test accuracy: 0.8820375204086304\n",
      "[    0     1     2 ... 37300 37301 37302] [26113 26114 26115 ... 29840 29841 29842]\n",
      "-----------breaking line--------------\n",
      "----------------------------\n",
      "8\n",
      "----------------------------\n",
      "Epoch 1/12\n",
      "263/263 [==============================] - 87s 330ms/step - loss: 1.6511 - accuracy: 0.4513 - val_loss: 1.1280 - val_accuracy: 0.6485\n",
      "Epoch 2/12\n",
      "263/263 [==============================] - 87s 329ms/step - loss: 1.1381 - accuracy: 0.6134 - val_loss: 0.9745 - val_accuracy: 0.6976\n",
      "Epoch 3/12\n",
      "263/263 [==============================] - 85s 323ms/step - loss: 0.9864 - accuracy: 0.6659 - val_loss: 0.8123 - val_accuracy: 0.7432\n",
      "Epoch 4/12\n",
      "263/263 [==============================] - 85s 324ms/step - loss: 0.8892 - accuracy: 0.7074 - val_loss: 0.7628 - val_accuracy: 0.7641\n",
      "Epoch 5/12\n",
      "263/263 [==============================] - 85s 324ms/step - loss: 0.7920 - accuracy: 0.7383 - val_loss: 0.6569 - val_accuracy: 0.7987\n",
      "Epoch 6/12\n",
      "263/263 [==============================] - 85s 323ms/step - loss: 0.7671 - accuracy: 0.7496 - val_loss: 0.6809 - val_accuracy: 0.8032\n",
      "Epoch 7/12\n",
      "263/263 [==============================] - 85s 323ms/step - loss: 0.7062 - accuracy: 0.7692 - val_loss: 0.5708 - val_accuracy: 0.8239\n",
      "Epoch 8/12\n",
      "263/263 [==============================] - 85s 324ms/step - loss: 0.6505 - accuracy: 0.7846 - val_loss: 0.5930 - val_accuracy: 0.8327\n",
      "Epoch 9/12\n",
      "263/263 [==============================] - 85s 321ms/step - loss: 0.6164 - accuracy: 0.7968 - val_loss: 0.4901 - val_accuracy: 0.8534\n",
      "Epoch 10/12\n",
      "263/263 [==============================] - 84s 321ms/step - loss: 0.5703 - accuracy: 0.8133 - val_loss: 0.5298 - val_accuracy: 0.8539\n",
      "Epoch 11/12\n",
      "263/263 [==============================] - 85s 322ms/step - loss: 0.5397 - accuracy: 0.8242 - val_loss: 0.4903 - val_accuracy: 0.8550\n",
      "Epoch 12/12\n",
      "263/263 [==============================] - 84s 321ms/step - loss: 0.5370 - accuracy: 0.8235 - val_loss: 0.4364 - val_accuracy: 0.8745\n",
      "117/117 [==============================] - 2s 17ms/step - loss: 0.4364 - accuracy: 0.8745\n",
      "Test loss: 0.43642809987068176\n",
      "Test accuracy: 0.8745308518409729\n",
      "[    0     1     2 ... 37300 37301 37302] [29843 29844 29845 ... 33570 33571 33572]\n",
      "-----------breaking line--------------\n",
      "----------------------------\n",
      "9\n",
      "----------------------------\n",
      "Epoch 1/12\n",
      "  2/263 [..............................] - ETA: 2:12 - loss: 5.3609 - accuracy: 0.1445WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.3670s vs `on_train_batch_end` time: 0.6434s). Check your callbacks.\n",
      "263/263 [==============================] - 95s 360ms/step - loss: 1.5461 - accuracy: 0.4800 - val_loss: 1.0852 - val_accuracy: 0.6370\n",
      "Epoch 2/12\n",
      "263/263 [==============================] - 95s 360ms/step - loss: 1.1003 - accuracy: 0.6250 - val_loss: 0.9462 - val_accuracy: 0.7043\n",
      "Epoch 3/12\n",
      "263/263 [==============================] - 93s 354ms/step - loss: 0.9625 - accuracy: 0.6784 - val_loss: 1.0109 - val_accuracy: 0.7051\n",
      "Epoch 4/12\n",
      "263/263 [==============================] - 93s 353ms/step - loss: 0.8920 - accuracy: 0.7056 - val_loss: 0.8219 - val_accuracy: 0.7542\n",
      "Epoch 5/12\n",
      "263/263 [==============================] - 93s 353ms/step - loss: 0.7837 - accuracy: 0.7441 - val_loss: 0.7213 - val_accuracy: 0.7694\n",
      "Epoch 6/12\n",
      "263/263 [==============================] - 94s 357ms/step - loss: 0.7489 - accuracy: 0.7559 - val_loss: 0.6434 - val_accuracy: 0.7997\n",
      "Epoch 7/12\n",
      "263/263 [==============================] - 93s 353ms/step - loss: 0.6669 - accuracy: 0.7769 - val_loss: 0.6399 - val_accuracy: 0.8029\n",
      "Epoch 8/12\n",
      "263/263 [==============================] - 93s 355ms/step - loss: 0.6355 - accuracy: 0.7905 - val_loss: 0.5783 - val_accuracy: 0.8201\n",
      "Epoch 9/12\n",
      "263/263 [==============================] - 93s 354ms/step - loss: 0.6005 - accuracy: 0.8006 - val_loss: 0.5535 - val_accuracy: 0.8378\n",
      "Epoch 10/12\n",
      "263/263 [==============================] - 93s 354ms/step - loss: 0.5872 - accuracy: 0.8078 - val_loss: 0.5185 - val_accuracy: 0.8491\n",
      "Epoch 11/12\n",
      "263/263 [==============================] - 93s 352ms/step - loss: 0.5663 - accuracy: 0.8136 - val_loss: 0.5055 - val_accuracy: 0.8453\n",
      "Epoch 12/12\n",
      "263/263 [==============================] - 93s 353ms/step - loss: 0.5258 - accuracy: 0.8258 - val_loss: 0.5096 - val_accuracy: 0.8555\n",
      "117/117 [==============================] - 2s 17ms/step - loss: 0.5096 - accuracy: 0.8555\n",
      "Test loss: 0.5095680952072144\n",
      "Test accuracy: 0.8554959893226624\n",
      "[    0     1     2 ... 33570 33571 33572] [33573 33574 33575 ... 37300 37301 37302]\n",
      "-----------breaking line--------------\n",
      "----------------------------\n",
      "10\n",
      "----------------------------\n",
      "Epoch 1/12\n",
      "263/263 [==============================] - 87s 332ms/step - loss: 1.6831 - accuracy: 0.4474 - val_loss: 1.1634 - val_accuracy: 0.6332\n",
      "Epoch 2/12\n",
      "263/263 [==============================] - 86s 329ms/step - loss: 1.1332 - accuracy: 0.6171 - val_loss: 0.9530 - val_accuracy: 0.7011\n",
      "Epoch 3/12\n",
      "263/263 [==============================] - 85s 323ms/step - loss: 0.9431 - accuracy: 0.6905 - val_loss: 0.8742 - val_accuracy: 0.7442\n",
      "Epoch 4/12\n",
      "263/263 [==============================] - 86s 326ms/step - loss: 0.8346 - accuracy: 0.7285 - val_loss: 0.8181 - val_accuracy: 0.7466\n",
      "Epoch 5/12\n",
      "263/263 [==============================] - 85s 324ms/step - loss: 0.7646 - accuracy: 0.7491 - val_loss: 0.7515 - val_accuracy: 0.7751\n",
      "Epoch 6/12\n",
      "263/263 [==============================] - 85s 324ms/step - loss: 0.6976 - accuracy: 0.7717 - val_loss: 0.7823 - val_accuracy: 0.7861\n",
      "Epoch 7/12\n",
      "263/263 [==============================] - 85s 324ms/step - loss: 0.6723 - accuracy: 0.7785 - val_loss: 0.6420 - val_accuracy: 0.8115\n",
      "Epoch 8/12\n",
      "263/263 [==============================] - 85s 324ms/step - loss: 0.6032 - accuracy: 0.7985 - val_loss: 0.7727 - val_accuracy: 0.7649\n",
      "Epoch 9/12\n",
      "263/263 [==============================] - 85s 324ms/step - loss: 0.5880 - accuracy: 0.8059 - val_loss: 0.5830 - val_accuracy: 0.8244\n",
      "Epoch 10/12\n",
      "263/263 [==============================] - 85s 323ms/step - loss: 0.5643 - accuracy: 0.8146 - val_loss: 0.5517 - val_accuracy: 0.8365\n",
      "Epoch 11/12\n",
      "263/263 [==============================] - 85s 324ms/step - loss: 0.5064 - accuracy: 0.8318 - val_loss: 0.5586 - val_accuracy: 0.8445\n",
      "Epoch 12/12\n",
      "263/263 [==============================] - 86s 325ms/step - loss: 0.4773 - accuracy: 0.8417 - val_loss: 0.5108 - val_accuracy: 0.8576\n",
      "117/117 [==============================] - 2s 17ms/step - loss: 0.5108 - accuracy: 0.8576\n",
      "Test loss: 0.5108177065849304\n",
      "Test accuracy: 0.8576407432556152\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for train_set, test_set in kf.split(dataset):\n",
    "     print( train_set, test_set)\n",
    "     print(\"-----------breaking line--------------\")\n",
    "     #X_train, X_test, y_train, y_test = dataset[train_set], dataset[test_set]\n",
    " \n",
    "     print('----------------------------')\n",
    "     count += 1\n",
    "     print(count)\n",
    "     print('----------------------------')\n",
    " \n",
    "     X_train, y_train = zip(*dataset[train_set])\n",
    "     X_test, y_test = zip(*dataset[test_set])\n",
    " \n",
    "     # Reshape for CNN input\n",
    "     X_train = np.array([x.reshape( (16384, 1) ) for x in X_train])\n",
    "     X_test = np.array([x.reshape( (16384, 1) ) for x in X_test])\n",
    " \n",
    "     # One-Hot encoding for classes\n",
    "     y_train = np.array(keras.utils.to_categorical(y_train, 10))\n",
    "     y_test = np.array(keras.utils.to_categorical(y_test, 10))\n",
    " \n",
    "     NAME = \"graphic-{}-\".format(int(time.time()))\n",
    "     tensorboard = TensorBoard(log_dir='G{}'.format(NAME +  str(count)))\n",
    " \n",
    " \n",
    "     model = Sequential()\n",
    "\n",
    "     model.add(\n",
    "        Conv1D(24, kernel_size=(80), input_shape=(16384, 1))\n",
    "        )\n",
    "\n",
    "     model.add(MaxPooling1D(8))\n",
    "     model.add(Activation('relu'))\n",
    " \n",
    "     model.add(Conv1D(48, kernel_size=(3), padding=\"valid\"))\n",
    "     model.add(MaxPooling1D(8))\n",
    "     model.add(Activation('relu'))\n",
    " \n",
    "     model.add(Conv1D(48, kernel_size=(3), padding=\"valid\"))\n",
    "     model.add(Activation('relu'))\n",
    " \n",
    "     model.add(Flatten())\n",
    "     model.add(Dropout(rate=0.5))\n",
    " \n",
    "     model.add(Dense(64))\n",
    "     model.add(Activation('relu'))\n",
    "     model.add(Dropout(rate=0.5))\n",
    " \n",
    "     model.add(Dense(10))\n",
    "     model.add(Activation('softmax'))\n",
    " \n",
    "     #convnet = tflearn.DNN(model, tensorboard_dir='log')\n",
    " \n",
    "     model.compile(\n",
    " \t    optimizer=\"Adam\",\n",
    " \t    loss=\"categorical_crossentropy\",\n",
    " \t    metrics=['accuracy']\n",
    "        )\n",
    " \n",
    "     model.fit(\n",
    " \t    x=X_train, \n",
    " \t    y=y_train,\n",
    "        epochs=12,\n",
    "        batch_size=128,\n",
    "        validation_data= (X_test, y_test),\n",
    " \t    callbacks=[tensorboard]\n",
    " \t    )\n",
    " \n",
    "     score = model.evaluate(\n",
    " \t    x=X_test,\n",
    " \t    y=y_test\n",
    "        )\n",
    " \n",
    "     print('Test loss:', score[0])\n",
    "     print('Test accuracy:', score[1])\n",
    "\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('SoundClassificationTEST.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopExecution",
     "evalue": "",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "class StopExecution(Exception):\n",
    "    def _render_traceback_(self):\n",
    "        pass\n",
    "\n",
    "raise StopExecution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"\"\n",
    "\n",
    "#Audio-Convertor\n",
    "def audioCon(filename):\n",
    "   from os import path\n",
    "   from pydub import AudioSegment\n",
    "   \n",
    "   # files                                                                         \n",
    "   src = \"Test/{filename}.mp3\"\n",
    "   dst = \"Test/{filename}.wav\"\n",
    "   \n",
    "   # convert wav to mp3                                                            \n",
    "   sound = AudioSegment.from_mp3(src)\n",
    "   sound.export(dst, format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audioCon()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(filepath):\n",
    "    y, sr = librosa.load(filepath, duration=2.97)\n",
    "    ps = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "    ps.shape\n",
    "    return ps.reshape(-1, 128, 128, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"SoundClassification.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_39 (Conv2D)           (None, 124, 124, 24)      624       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 31, 62, 24)        0         \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 31, 62, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 27, 58, 48)        28848     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 6, 29, 48)         0         \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 6, 29, 48)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 2, 25, 48)         57648     \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 2, 25, 48)         0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 2400)              0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 2400)              0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 64)                153664    \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 241,434\n",
      "Trainable params: 241,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.90739536\n",
      "[[9.0739536e-01 1.0987020e-05 7.2039278e-05 7.7610814e-05 1.3195210e-02\n",
      "  9.4531840e-03 1.2650190e-07 6.9615506e-02 4.5010489e-05 1.3501685e-04]]\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict([prepare('Test/airc.wav')])\n",
    "max = np.amax(prediction)\n",
    "print(max)\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
