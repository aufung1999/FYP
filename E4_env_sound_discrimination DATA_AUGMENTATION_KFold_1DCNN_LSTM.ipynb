{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Activation, Dense, Dropout, Conv2D, \\\n",
    "                         Flatten, MaxPooling2D, LSTM, TimeDistributed, Reshape, Lambda, Conv1D, MaxPooling1D, BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import TensorBoard\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice_file_name</th>\n",
       "      <th>fsID</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>salience</th>\n",
       "      <th>fold</th>\n",
       "      <th>classID</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100032-3-0-0.wav</td>\n",
       "      <td>100032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.317551</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100263-2-0-117.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>58.5</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100263-2-0-121.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>60.5</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100263-2-0-126.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>63.0</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100263-2-0-137.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>68.5</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      slice_file_name    fsID  start        end  salience  fold  classID  \\\n",
       "0    100032-3-0-0.wav  100032    0.0   0.317551         1     5        3   \n",
       "1  100263-2-0-117.wav  100263   58.5  62.500000         1     5        2   \n",
       "2  100263-2-0-121.wav  100263   60.5  64.500000         1     5        2   \n",
       "3  100263-2-0-126.wav  100263   63.0  67.000000         1     5        2   \n",
       "4  100263-2-0-137.wav  100263   68.5  72.500000         1     5        2   \n",
       "\n",
       "              class  \n",
       "0          dog_bark  \n",
       "1  children_playing  \n",
       "2  children_playing  \n",
       "3  children_playing  \n",
       "4  children_playing  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Data\n",
    "data = pd.read_csv('UrbanSounds8K/metadata/UrbanSound8K.csv')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8732, 8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7468, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get data over 3 seconds long\n",
    "valid_data = data[['slice_file_name', 'fold' ,'classID', 'class']][ data['end']-data['start'] >= 3 ]\n",
    "valid_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x21cdb1785c8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y, sr = librosa.load('UrbanSounds8K/audio/fold9/13579-2-0-16.wav', duration=2.97)\n",
    "ps = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "ps.shape\n",
    "\n",
    "mel_sgram = librosa.amplitude_to_db(ps, ref=np.min)\n",
    "\n",
    "librosa.display.specshow(ps, y_axis='mel', x_axis='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data['path'] = 'fold' + valid_data['fold'].astype('str') + '/' + valid_data['slice_file_name'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use it to create data ######################################################################\n",
    "def creates_train_data():\n",
    "    D = [] # Dataset\n",
    "\n",
    "    for row in valid_data.itertuples():\n",
    "        y, sr = librosa.load('UrbanSounds8K/augmented/ps2_m25/' + row.path, duration=2.97)  #2.97 = 3*1000 - 3*1000/128  ###############################\n",
    "        ps = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "        if ps.shape != (128, 128): continue\n",
    "        D.append( (ps, row.classID) )\n",
    "    np.save('train_data_augmented_ps2_m25.npy', D) ###############################\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37303"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load.__defaults__=(None, True, True, 'ASCII')\n",
    "a = np.load('train_data.npy')\n",
    "b = np.load('train_data_augmented_speed_81.npy')\n",
    "c = np.load('train_data_augmented_speed_107.npy')\n",
    "d = np.load('train_data_augmented_ps1_2.npy')\n",
    "e = np.load('train_data_augmented_ps2_m25.npy')\n",
    "\n",
    "# np.savez('train.npz',a,b,c,d,e) ############################################################################\n",
    "# r = np.load('train.npz') ############################################################################\n",
    "# locals().update(r) ############################################################################\n",
    "\n",
    "tuple = (a,b,c,d,e)\n",
    "tuplearr = np.vstack(tuple)\n",
    "len(tuplearr)\n",
    "dataset = tuplearr\n",
    "random.shuffle(dataset)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3731  3732  3733 ... 37300 37301 37302] [   0    1    2 ... 3728 3729 3730]\n",
      "-----------breaking line--------------\n",
      "----------------------------\n",
      "1\n",
      "----------------------------\n",
      "Epoch 1/48\n",
      "  1/263 [..............................] - ETA: 0s - loss: 2.7834 - accuracy: 0.1094WARNING:tensorflow:From C:\\Users\\Guest1\\anaconda3\\envs\\backup_20220216_20220322\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "  2/263 [..............................] - ETA: 8s - loss: 2.8809 - accuracy: 0.0859WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0205s vs `on_train_batch_end` time: 0.0481s). Check your callbacks.\n",
      "263/263 [==============================] - 6s 22ms/step - loss: 2.3997 - accuracy: 0.1524 - val_loss: 2.2433 - val_accuracy: 0.2219\n",
      "Epoch 2/48\n",
      "263/263 [==============================] - 4s 17ms/step - loss: 2.1796 - accuracy: 0.2042 - val_loss: 1.9930 - val_accuracy: 0.3031\n",
      "Epoch 3/48\n",
      "263/263 [==============================] - 4s 17ms/step - loss: 2.0467 - accuracy: 0.2411 - val_loss: 1.8798 - val_accuracy: 0.3358\n",
      "Epoch 4/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.9806 - accuracy: 0.2685 - val_loss: 1.8405 - val_accuracy: 0.3492\n",
      "Epoch 5/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.9408 - accuracy: 0.2763 - val_loss: 1.7954 - val_accuracy: 0.3498\n",
      "Epoch 6/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.9121 - accuracy: 0.2940 - val_loss: 1.7523 - val_accuracy: 0.3624\n",
      "Epoch 7/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.8845 - accuracy: 0.3019 - val_loss: 1.7220 - val_accuracy: 0.4069\n",
      "Epoch 8/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.8604 - accuracy: 0.3135 - val_loss: 1.7092 - val_accuracy: 0.3610\n",
      "Epoch 9/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.8364 - accuracy: 0.3231 - val_loss: 1.6683 - val_accuracy: 0.3683\n",
      "Epoch 10/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.8132 - accuracy: 0.3279 - val_loss: 1.6411 - val_accuracy: 0.3811\n",
      "Epoch 11/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.8117 - accuracy: 0.3347 - val_loss: 1.6556 - val_accuracy: 0.3878\n",
      "Epoch 12/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.7975 - accuracy: 0.3393 - val_loss: 1.6176 - val_accuracy: 0.4077\n",
      "Epoch 13/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.7726 - accuracy: 0.3482 - val_loss: 1.5993 - val_accuracy: 0.4101\n",
      "Epoch 14/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.7578 - accuracy: 0.3537 - val_loss: 1.5948 - val_accuracy: 0.4288\n",
      "Epoch 15/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.7464 - accuracy: 0.3609 - val_loss: 1.5666 - val_accuracy: 0.4645\n",
      "Epoch 16/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.7315 - accuracy: 0.3637 - val_loss: 1.5534 - val_accuracy: 0.4390\n",
      "Epoch 17/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.7161 - accuracy: 0.3714 - val_loss: 1.5418 - val_accuracy: 0.4519\n",
      "Epoch 18/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.7118 - accuracy: 0.3782 - val_loss: 1.5162 - val_accuracy: 0.4991\n",
      "Epoch 19/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.7004 - accuracy: 0.3831 - val_loss: 1.5098 - val_accuracy: 0.5243\n",
      "Epoch 20/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6864 - accuracy: 0.3870 - val_loss: 1.5145 - val_accuracy: 0.5015\n",
      "Epoch 21/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6778 - accuracy: 0.3921 - val_loss: 1.5041 - val_accuracy: 0.4991\n",
      "Epoch 22/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6648 - accuracy: 0.3973 - val_loss: 1.4936 - val_accuracy: 0.5092\n",
      "Epoch 23/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6584 - accuracy: 0.4015 - val_loss: 1.4902 - val_accuracy: 0.5245\n",
      "Epoch 24/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6542 - accuracy: 0.4041 - val_loss: 1.4639 - val_accuracy: 0.5393\n",
      "Epoch 25/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6503 - accuracy: 0.4086 - val_loss: 1.4652 - val_accuracy: 0.5256\n",
      "Epoch 26/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6343 - accuracy: 0.4127 - val_loss: 1.4328 - val_accuracy: 0.5468\n",
      "Epoch 27/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6263 - accuracy: 0.4156 - val_loss: 1.4334 - val_accuracy: 0.5403\n",
      "Epoch 28/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6264 - accuracy: 0.4173 - val_loss: 1.4175 - val_accuracy: 0.5422\n",
      "Epoch 29/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6141 - accuracy: 0.4225 - val_loss: 1.4403 - val_accuracy: 0.5275\n",
      "Epoch 30/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6201 - accuracy: 0.4200 - val_loss: 1.4074 - val_accuracy: 0.5548\n",
      "Epoch 31/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6117 - accuracy: 0.4217 - val_loss: 1.4333 - val_accuracy: 0.5358\n",
      "Epoch 32/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6069 - accuracy: 0.4262 - val_loss: 1.4142 - val_accuracy: 0.5486\n",
      "Epoch 33/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5959 - accuracy: 0.4305 - val_loss: 1.4109 - val_accuracy: 0.5586\n",
      "Epoch 34/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5829 - accuracy: 0.4341 - val_loss: 1.4004 - val_accuracy: 0.5562\n",
      "Epoch 35/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5898 - accuracy: 0.4292 - val_loss: 1.4052 - val_accuracy: 0.5425\n",
      "Epoch 36/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5814 - accuracy: 0.4318 - val_loss: 1.3937 - val_accuracy: 0.5401\n",
      "Epoch 37/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5759 - accuracy: 0.4355 - val_loss: 1.4011 - val_accuracy: 0.5414\n",
      "Epoch 38/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5755 - accuracy: 0.4366 - val_loss: 1.3574 - val_accuracy: 0.5545\n",
      "Epoch 39/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5717 - accuracy: 0.4410 - val_loss: 1.3776 - val_accuracy: 0.5556\n",
      "Epoch 40/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5650 - accuracy: 0.4416 - val_loss: 1.3484 - val_accuracy: 0.5696\n",
      "Epoch 41/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5735 - accuracy: 0.4385 - val_loss: 1.3567 - val_accuracy: 0.5588\n",
      "Epoch 42/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.5636 - accuracy: 0.4416 - val_loss: 1.3453 - val_accuracy: 0.5537\n",
      "Epoch 43/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5602 - accuracy: 0.4426 - val_loss: 1.3555 - val_accuracy: 0.5564\n",
      "Epoch 44/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5537 - accuracy: 0.4458 - val_loss: 1.3349 - val_accuracy: 0.5594\n",
      "Epoch 45/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5457 - accuracy: 0.4486 - val_loss: 1.3411 - val_accuracy: 0.5591\n",
      "Epoch 46/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.5436 - accuracy: 0.4498 - val_loss: 1.3329 - val_accuracy: 0.5658\n",
      "Epoch 47/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.5414 - accuracy: 0.4512 - val_loss: 1.3263 - val_accuracy: 0.5623\n",
      "Epoch 48/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5320 - accuracy: 0.4547 - val_loss: 1.3509 - val_accuracy: 0.5495\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1.3509 - accuracy: 0.5495\n",
      "Test loss: 1.3508867025375366\n",
      "Test accuracy: 0.5494505763053894\n",
      "[    0     1     2 ... 37300 37301 37302] [3731 3732 3733 ... 7459 7460 7461]\n",
      "-----------breaking line--------------\n",
      "----------------------------\n",
      "2\n",
      "----------------------------\n",
      "Epoch 1/48\n",
      "  2/263 [..............................] - ETA: 4:07 - loss: 2.9597 - accuracy: 0.0859WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0140s vs `on_train_batch_end` time: 1.8824s). Check your callbacks.\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 2.4260 - accuracy: 0.1442 - val_loss: 2.2762 - val_accuracy: 0.2107\n",
      "Epoch 2/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.2527 - accuracy: 0.1800 - val_loss: 2.1511 - val_accuracy: 0.2876\n",
      "Epoch 3/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.1544 - accuracy: 0.2142 - val_loss: 1.8957 - val_accuracy: 0.3045\n",
      "Epoch 4/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 2.0430 - accuracy: 0.2537 - val_loss: 1.8591 - val_accuracy: 0.2967\n",
      "Epoch 5/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.9780 - accuracy: 0.2688 - val_loss: 1.8287 - val_accuracy: 0.3168\n",
      "Epoch 6/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.9425 - accuracy: 0.2804 - val_loss: 1.8794 - val_accuracy: 0.3189\n",
      "Epoch 7/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.9148 - accuracy: 0.2889 - val_loss: 1.7827 - val_accuracy: 0.3399\n",
      "Epoch 8/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.8897 - accuracy: 0.2980 - val_loss: 1.7518 - val_accuracy: 0.3624\n",
      "Epoch 9/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.8725 - accuracy: 0.3078 - val_loss: 1.7266 - val_accuracy: 0.3739\n",
      "Epoch 10/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.8482 - accuracy: 0.3146 - val_loss: 1.6866 - val_accuracy: 0.3838\n",
      "Epoch 11/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.8222 - accuracy: 0.3284 - val_loss: 1.6514 - val_accuracy: 0.3924\n",
      "Epoch 12/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.7984 - accuracy: 0.3385 - val_loss: 1.6498 - val_accuracy: 0.3948\n",
      "Epoch 13/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.7860 - accuracy: 0.3461 - val_loss: 1.6049 - val_accuracy: 0.4246\n",
      "Epoch 14/48\n",
      "263/263 [==============================] - 4s 13ms/step - loss: 1.7615 - accuracy: 0.3557 - val_loss: 1.5875 - val_accuracy: 0.4275\n",
      "Epoch 15/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.7465 - accuracy: 0.3621 - val_loss: 1.5605 - val_accuracy: 0.4489\n",
      "Epoch 16/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.7303 - accuracy: 0.3706 - val_loss: 1.5350 - val_accuracy: 0.4449\n",
      "Epoch 17/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.7181 - accuracy: 0.3709 - val_loss: 1.5273 - val_accuracy: 0.4516\n",
      "Epoch 18/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.7067 - accuracy: 0.3820 - val_loss: 1.5650 - val_accuracy: 0.4219\n",
      "Epoch 19/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6928 - accuracy: 0.3864 - val_loss: 1.5093 - val_accuracy: 0.4554\n",
      "Epoch 20/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6719 - accuracy: 0.3971 - val_loss: 1.4858 - val_accuracy: 0.4522\n",
      "Epoch 21/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6667 - accuracy: 0.3969 - val_loss: 1.4729 - val_accuracy: 0.4690\n",
      "Epoch 22/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.6580 - accuracy: 0.3957 - val_loss: 1.4807 - val_accuracy: 0.4615\n",
      "Epoch 23/48\n",
      "263/263 [==============================] - 4s 13ms/step - loss: 1.6461 - accuracy: 0.4027 - val_loss: 1.4570 - val_accuracy: 0.4728\n",
      "Epoch 24/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6417 - accuracy: 0.4066 - val_loss: 1.4511 - val_accuracy: 0.4728\n",
      "Epoch 25/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.6277 - accuracy: 0.4147 - val_loss: 1.4506 - val_accuracy: 0.4733\n",
      "Epoch 26/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.6199 - accuracy: 0.4188 - val_loss: 1.4230 - val_accuracy: 0.5063\n",
      "Epoch 27/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.6104 - accuracy: 0.4212 - val_loss: 1.4167 - val_accuracy: 0.4929\n",
      "Epoch 28/48\n",
      "263/263 [==============================] - 4s 13ms/step - loss: 1.6181 - accuracy: 0.4192 - val_loss: 1.4267 - val_accuracy: 0.4827\n",
      "Epoch 29/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6053 - accuracy: 0.4239 - val_loss: 1.4305 - val_accuracy: 0.4964\n",
      "Epoch 30/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6113 - accuracy: 0.4227 - val_loss: 1.4467 - val_accuracy: 0.4857\n",
      "Epoch 31/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.5932 - accuracy: 0.4304 - val_loss: 1.4085 - val_accuracy: 0.5047\n",
      "Epoch 32/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5869 - accuracy: 0.4335 - val_loss: 1.3912 - val_accuracy: 0.5151\n",
      "Epoch 33/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5775 - accuracy: 0.4341 - val_loss: 1.3917 - val_accuracy: 0.5058\n",
      "Epoch 34/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5711 - accuracy: 0.4402 - val_loss: 1.3688 - val_accuracy: 0.5210\n",
      "Epoch 35/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5684 - accuracy: 0.4388 - val_loss: 1.3674 - val_accuracy: 0.5224\n",
      "Epoch 36/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.5630 - accuracy: 0.4427 - val_loss: 1.4056 - val_accuracy: 0.4854\n",
      "Epoch 37/48\n",
      "263/263 [==============================] - 4s 13ms/step - loss: 1.5584 - accuracy: 0.4485 - val_loss: 1.3570 - val_accuracy: 0.5275\n",
      "Epoch 38/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5517 - accuracy: 0.4485 - val_loss: 1.3448 - val_accuracy: 0.5285\n",
      "Epoch 39/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5442 - accuracy: 0.4534 - val_loss: 1.3717 - val_accuracy: 0.5218\n",
      "Epoch 40/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.5437 - accuracy: 0.4535 - val_loss: 1.3490 - val_accuracy: 0.5326\n",
      "Epoch 41/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.5400 - accuracy: 0.4531 - val_loss: 1.3382 - val_accuracy: 0.5328\n",
      "Epoch 42/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5396 - accuracy: 0.4528 - val_loss: 1.3492 - val_accuracy: 0.5245\n",
      "Epoch 43/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5308 - accuracy: 0.4545 - val_loss: 1.3258 - val_accuracy: 0.5387\n",
      "Epoch 44/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5325 - accuracy: 0.4554 - val_loss: 1.3469 - val_accuracy: 0.5339\n",
      "Epoch 45/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.5380 - accuracy: 0.4534 - val_loss: 1.3580 - val_accuracy: 0.5210\n",
      "Epoch 46/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5307 - accuracy: 0.4569 - val_loss: 1.3379 - val_accuracy: 0.5296\n",
      "Epoch 47/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5305 - accuracy: 0.4599 - val_loss: 1.3265 - val_accuracy: 0.5395\n",
      "Epoch 48/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5257 - accuracy: 0.4607 - val_loss: 1.3163 - val_accuracy: 0.5438\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1.3163 - accuracy: 0.5438\n",
      "Test loss: 1.3163141012191772\n",
      "Test accuracy: 0.5438220500946045\n",
      "[    0     1     2 ... 37300 37301 37302] [ 7462  7463  7464 ... 11190 11191 11192]\n",
      "-----------breaking line--------------\n",
      "----------------------------\n",
      "3\n",
      "----------------------------\n",
      "Epoch 1/48\n",
      "  2/263 [..............................] - ETA: 3:03 - loss: 2.9129 - accuracy: 0.0664WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0129s vs `on_train_batch_end` time: 1.3919s). Check your callbacks.\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 2.4123 - accuracy: 0.1514 - val_loss: 2.2426 - val_accuracy: 0.2297\n",
      "Epoch 2/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.1605 - accuracy: 0.2191 - val_loss: 1.9752 - val_accuracy: 0.2549\n",
      "Epoch 3/48\n",
      "263/263 [==============================] - 4s 17ms/step - loss: 2.0245 - accuracy: 0.2535 - val_loss: 1.9306 - val_accuracy: 0.2806\n",
      "Epoch 4/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.9700 - accuracy: 0.2737 - val_loss: 1.8858 - val_accuracy: 0.3058\n",
      "Epoch 5/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.9337 - accuracy: 0.2890 - val_loss: 1.8333 - val_accuracy: 0.3559\n",
      "Epoch 6/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.9024 - accuracy: 0.3013 - val_loss: 1.8037 - val_accuracy: 0.3382\n",
      "Epoch 7/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.8780 - accuracy: 0.3116 - val_loss: 1.7603 - val_accuracy: 0.3768\n",
      "Epoch 8/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.8533 - accuracy: 0.3209 - val_loss: 1.7185 - val_accuracy: 0.3932\n",
      "Epoch 9/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.8365 - accuracy: 0.3210 - val_loss: 1.7002 - val_accuracy: 0.3897\n",
      "Epoch 10/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.8098 - accuracy: 0.3373 - val_loss: 1.6885 - val_accuracy: 0.3707\n",
      "Epoch 11/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.7873 - accuracy: 0.3444 - val_loss: 1.6521 - val_accuracy: 0.4090\n",
      "Epoch 12/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.7681 - accuracy: 0.3599 - val_loss: 1.6391 - val_accuracy: 0.4085\n",
      "Epoch 13/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.7517 - accuracy: 0.3655 - val_loss: 1.6388 - val_accuracy: 0.4125\n",
      "Epoch 14/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.7381 - accuracy: 0.3737 - val_loss: 1.6001 - val_accuracy: 0.4288\n",
      "Epoch 15/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.7259 - accuracy: 0.3801 - val_loss: 1.5859 - val_accuracy: 0.4369\n",
      "Epoch 16/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.7047 - accuracy: 0.3847 - val_loss: 1.5720 - val_accuracy: 0.4380\n",
      "Epoch 17/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.6938 - accuracy: 0.3898 - val_loss: 1.5675 - val_accuracy: 0.4438\n",
      "Epoch 18/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6789 - accuracy: 0.3999 - val_loss: 1.5628 - val_accuracy: 0.4251\n",
      "Epoch 19/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6711 - accuracy: 0.3995 - val_loss: 1.5291 - val_accuracy: 0.4436\n",
      "Epoch 20/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6559 - accuracy: 0.4046 - val_loss: 1.5356 - val_accuracy: 0.4755\n",
      "Epoch 21/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.6474 - accuracy: 0.4146 - val_loss: 1.5134 - val_accuracy: 0.4723\n",
      "Epoch 22/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6405 - accuracy: 0.4162 - val_loss: 1.5124 - val_accuracy: 0.4798\n",
      "Epoch 23/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6362 - accuracy: 0.4214 - val_loss: 1.5082 - val_accuracy: 0.4739\n",
      "Epoch 24/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6259 - accuracy: 0.4205 - val_loss: 1.5147 - val_accuracy: 0.4795\n",
      "Epoch 25/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.6307 - accuracy: 0.4217 - val_loss: 1.5028 - val_accuracy: 0.4816\n",
      "Epoch 26/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.6195 - accuracy: 0.4288 - val_loss: 1.4938 - val_accuracy: 0.4854\n",
      "Epoch 27/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6079 - accuracy: 0.4317 - val_loss: 1.4938 - val_accuracy: 0.4867\n",
      "Epoch 28/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6002 - accuracy: 0.4313 - val_loss: 1.4787 - val_accuracy: 0.4891\n",
      "Epoch 29/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5921 - accuracy: 0.4349 - val_loss: 1.4715 - val_accuracy: 0.4878\n",
      "Epoch 30/48\n",
      "263/263 [==============================] - 4s 17ms/step - loss: 1.6040 - accuracy: 0.4336 - val_loss: 1.4774 - val_accuracy: 0.4803\n",
      "Epoch 31/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5893 - accuracy: 0.4383 - val_loss: 1.4644 - val_accuracy: 0.4956\n",
      "Epoch 32/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5791 - accuracy: 0.4375 - val_loss: 1.4686 - val_accuracy: 0.4937\n",
      "Epoch 33/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5722 - accuracy: 0.4456 - val_loss: 1.4857 - val_accuracy: 0.4940\n",
      "Epoch 34/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.5722 - accuracy: 0.4429 - val_loss: 1.4539 - val_accuracy: 0.5012\n",
      "Epoch 35/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.5692 - accuracy: 0.4469 - val_loss: 1.4588 - val_accuracy: 0.5039\n",
      "Epoch 36/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5620 - accuracy: 0.4458 - val_loss: 1.4504 - val_accuracy: 0.5063\n",
      "Epoch 37/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5632 - accuracy: 0.4477 - val_loss: 1.4544 - val_accuracy: 0.5001\n",
      "Epoch 38/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5578 - accuracy: 0.4528 - val_loss: 1.4427 - val_accuracy: 0.5047\n",
      "Epoch 39/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.5529 - accuracy: 0.4524 - val_loss: 1.4596 - val_accuracy: 0.4999\n",
      "Epoch 40/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5577 - accuracy: 0.4511 - val_loss: 1.4389 - val_accuracy: 0.5071\n",
      "Epoch 41/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5457 - accuracy: 0.4530 - val_loss: 1.4471 - val_accuracy: 0.5050\n",
      "Epoch 42/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5418 - accuracy: 0.4540 - val_loss: 1.4283 - val_accuracy: 0.5194\n",
      "Epoch 43/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.5367 - accuracy: 0.4609 - val_loss: 1.4344 - val_accuracy: 0.5095\n",
      "Epoch 44/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.5407 - accuracy: 0.4584 - val_loss: 1.4803 - val_accuracy: 0.4851\n",
      "Epoch 45/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5362 - accuracy: 0.4576 - val_loss: 1.4471 - val_accuracy: 0.5052\n",
      "Epoch 46/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5251 - accuracy: 0.4657 - val_loss: 1.4141 - val_accuracy: 0.5224\n",
      "Epoch 47/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5179 - accuracy: 0.4666 - val_loss: 1.4148 - val_accuracy: 0.5264\n",
      "Epoch 48/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.5215 - accuracy: 0.4646 - val_loss: 1.4320 - val_accuracy: 0.5090\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1.4320 - accuracy: 0.5090\n",
      "Test loss: 1.432007074356079\n",
      "Test accuracy: 0.5089788436889648\n",
      "[    0     1     2 ... 37300 37301 37302] [11193 11194 11195 ... 14920 14921 14922]\n",
      "-----------breaking line--------------\n",
      "----------------------------\n",
      "4\n",
      "----------------------------\n",
      "Epoch 1/48\n",
      "  2/263 [..............................] - ETA: 3:09 - loss: 2.7513 - accuracy: 0.1016WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0155s vs `on_train_batch_end` time: 1.4329s). Check your callbacks.\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 2.4015 - accuracy: 0.1533 - val_loss: 2.2553 - val_accuracy: 0.1668\n",
      "Epoch 2/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.1574 - accuracy: 0.2208 - val_loss: 2.0073 - val_accuracy: 0.2590\n",
      "Epoch 3/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.0328 - accuracy: 0.2558 - val_loss: 1.9300 - val_accuracy: 0.2611\n",
      "Epoch 4/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.9733 - accuracy: 0.2758 - val_loss: 1.9017 - val_accuracy: 0.2799\n",
      "Epoch 5/48\n",
      "263/263 [==============================] - 4s 17ms/step - loss: 1.9397 - accuracy: 0.2914 - val_loss: 1.8673 - val_accuracy: 0.3091\n",
      "Epoch 6/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.9081 - accuracy: 0.2949 - val_loss: 1.8413 - val_accuracy: 0.3161\n",
      "Epoch 7/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.8815 - accuracy: 0.3098 - val_loss: 1.8153 - val_accuracy: 0.3271\n",
      "Epoch 8/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.8562 - accuracy: 0.3177 - val_loss: 1.7789 - val_accuracy: 0.3547\n",
      "Epoch 9/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.8287 - accuracy: 0.3318 - val_loss: 1.7471 - val_accuracy: 0.3625\n",
      "Epoch 10/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.8060 - accuracy: 0.3459 - val_loss: 1.7298 - val_accuracy: 0.3678\n",
      "Epoch 11/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.7866 - accuracy: 0.3537 - val_loss: 1.6996 - val_accuracy: 0.3938\n",
      "Epoch 12/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.7655 - accuracy: 0.3626 - val_loss: 1.6936 - val_accuracy: 0.4134\n",
      "Epoch 13/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.7499 - accuracy: 0.3717 - val_loss: 1.6841 - val_accuracy: 0.3949\n",
      "Epoch 14/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.7291 - accuracy: 0.3783 - val_loss: 1.6479 - val_accuracy: 0.4260\n",
      "Epoch 15/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.7195 - accuracy: 0.3847 - val_loss: 1.6372 - val_accuracy: 0.4324\n",
      "Epoch 16/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.7080 - accuracy: 0.3925 - val_loss: 1.6204 - val_accuracy: 0.4517\n",
      "Epoch 17/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6901 - accuracy: 0.3985 - val_loss: 1.6163 - val_accuracy: 0.4477\n",
      "Epoch 18/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.6752 - accuracy: 0.4052 - val_loss: 1.6138 - val_accuracy: 0.4413\n",
      "Epoch 19/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.6634 - accuracy: 0.4077 - val_loss: 1.5910 - val_accuracy: 0.4507\n",
      "Epoch 20/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6561 - accuracy: 0.4119 - val_loss: 1.5848 - val_accuracy: 0.4603\n",
      "Epoch 21/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6403 - accuracy: 0.4209 - val_loss: 1.5848 - val_accuracy: 0.4509\n",
      "Epoch 22/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6278 - accuracy: 0.4286 - val_loss: 1.5564 - val_accuracy: 0.4625\n",
      "Epoch 23/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.6164 - accuracy: 0.4296 - val_loss: 1.5643 - val_accuracy: 0.4491\n",
      "Epoch 24/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6060 - accuracy: 0.4309 - val_loss: 1.5430 - val_accuracy: 0.4702\n",
      "Epoch 25/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6046 - accuracy: 0.4337 - val_loss: 1.5464 - val_accuracy: 0.4684\n",
      "Epoch 26/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6021 - accuracy: 0.4390 - val_loss: 1.5365 - val_accuracy: 0.4665\n",
      "Epoch 27/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.5889 - accuracy: 0.4411 - val_loss: 1.5367 - val_accuracy: 0.4700\n",
      "Epoch 28/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5825 - accuracy: 0.4417 - val_loss: 1.5115 - val_accuracy: 0.4732\n",
      "Epoch 29/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5769 - accuracy: 0.4447 - val_loss: 1.5216 - val_accuracy: 0.4761\n",
      "Epoch 30/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5682 - accuracy: 0.4507 - val_loss: 1.5148 - val_accuracy: 0.4700\n",
      "Epoch 31/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5583 - accuracy: 0.4543 - val_loss: 1.4901 - val_accuracy: 0.4826\n",
      "Epoch 32/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.5592 - accuracy: 0.4516 - val_loss: 1.5055 - val_accuracy: 0.4751\n",
      "Epoch 33/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5581 - accuracy: 0.4538 - val_loss: 1.4850 - val_accuracy: 0.4853\n",
      "Epoch 34/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5421 - accuracy: 0.4579 - val_loss: 1.4947 - val_accuracy: 0.4804\n",
      "Epoch 35/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5484 - accuracy: 0.4570 - val_loss: 1.4942 - val_accuracy: 0.4812\n",
      "Epoch 36/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.5349 - accuracy: 0.4618 - val_loss: 1.4865 - val_accuracy: 0.4820\n",
      "Epoch 37/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5359 - accuracy: 0.4611 - val_loss: 1.4810 - val_accuracy: 0.4826\n",
      "Epoch 38/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5350 - accuracy: 0.4642 - val_loss: 1.4743 - val_accuracy: 0.4938\n",
      "Epoch 39/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5272 - accuracy: 0.4636 - val_loss: 1.4632 - val_accuracy: 0.4914\n",
      "Epoch 40/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.5304 - accuracy: 0.4633 - val_loss: 1.4700 - val_accuracy: 0.4909\n",
      "Epoch 41/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.5181 - accuracy: 0.4684 - val_loss: 1.4616 - val_accuracy: 0.4989\n",
      "Epoch 42/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5198 - accuracy: 0.4676 - val_loss: 1.4582 - val_accuracy: 0.4992\n",
      "Epoch 43/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5188 - accuracy: 0.4682 - val_loss: 1.4525 - val_accuracy: 0.5024\n",
      "Epoch 44/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5053 - accuracy: 0.4737 - val_loss: 1.4441 - val_accuracy: 0.5016\n",
      "Epoch 45/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.5100 - accuracy: 0.4740 - val_loss: 1.4476 - val_accuracy: 0.4989\n",
      "Epoch 46/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5085 - accuracy: 0.4739 - val_loss: 1.4684 - val_accuracy: 0.4987\n",
      "Epoch 47/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5036 - accuracy: 0.4730 - val_loss: 1.4705 - val_accuracy: 0.4890\n",
      "Epoch 48/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5025 - accuracy: 0.4764 - val_loss: 1.4351 - val_accuracy: 0.5046\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1.4351 - accuracy: 0.5046\n",
      "Test loss: 1.435064673423767\n",
      "Test accuracy: 0.5045576691627502\n",
      "[    0     1     2 ... 37300 37301 37302] [14923 14924 14925 ... 18650 18651 18652]\n",
      "-----------breaking line--------------\n",
      "----------------------------\n",
      "5\n",
      "----------------------------\n",
      "Epoch 1/48\n",
      "  2/263 [..............................] - ETA: 3:51 - loss: 2.8188 - accuracy: 0.1016WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0144s vs `on_train_batch_end` time: 1.7566s). Check your callbacks.\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 2.3987 - accuracy: 0.1631 - val_loss: 2.2512 - val_accuracy: 0.2378\n",
      "Epoch 2/48\n",
      "263/263 [==============================] - 5s 18ms/step - loss: 2.1641 - accuracy: 0.2199 - val_loss: 2.0155 - val_accuracy: 0.2646\n",
      "Epoch 3/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.0423 - accuracy: 0.2485 - val_loss: 1.9785 - val_accuracy: 0.3102\n",
      "Epoch 4/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.9856 - accuracy: 0.2660 - val_loss: 1.9330 - val_accuracy: 0.3113\n",
      "Epoch 5/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.9438 - accuracy: 0.2859 - val_loss: 1.9200 - val_accuracy: 0.3247\n",
      "Epoch 6/48\n",
      "263/263 [==============================] - 4s 17ms/step - loss: 1.9172 - accuracy: 0.2934 - val_loss: 1.8713 - val_accuracy: 0.3413\n",
      "Epoch 7/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.8897 - accuracy: 0.3045 - val_loss: 1.8341 - val_accuracy: 0.3319\n",
      "Epoch 8/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.8623 - accuracy: 0.3172 - val_loss: 1.8186 - val_accuracy: 0.3340\n",
      "Epoch 9/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.8377 - accuracy: 0.3273 - val_loss: 1.7808 - val_accuracy: 0.3525\n",
      "Epoch 10/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.8188 - accuracy: 0.3353 - val_loss: 1.7583 - val_accuracy: 0.3520\n",
      "Epoch 11/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.7968 - accuracy: 0.3432 - val_loss: 1.7432 - val_accuracy: 0.3622\n",
      "Epoch 12/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.7749 - accuracy: 0.3522 - val_loss: 1.7327 - val_accuracy: 0.3901\n",
      "Epoch 13/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.7572 - accuracy: 0.3639 - val_loss: 1.6947 - val_accuracy: 0.3928\n",
      "Epoch 14/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.7362 - accuracy: 0.3724 - val_loss: 1.6744 - val_accuracy: 0.4064\n",
      "Epoch 15/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.7195 - accuracy: 0.3808 - val_loss: 1.6619 - val_accuracy: 0.4118\n",
      "Epoch 16/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.7173 - accuracy: 0.3825 - val_loss: 1.6407 - val_accuracy: 0.4241\n",
      "Epoch 17/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.7047 - accuracy: 0.3860 - val_loss: 1.6657 - val_accuracy: 0.4169\n",
      "Epoch 18/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.7109 - accuracy: 0.3876 - val_loss: 1.6500 - val_accuracy: 0.4214\n",
      "Epoch 19/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.6860 - accuracy: 0.3945 - val_loss: 1.6256 - val_accuracy: 0.4252\n",
      "Epoch 20/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6654 - accuracy: 0.4048 - val_loss: 1.6059 - val_accuracy: 0.4426\n",
      "Epoch 21/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6512 - accuracy: 0.4112 - val_loss: 1.6171 - val_accuracy: 0.4198\n",
      "Epoch 22/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.6432 - accuracy: 0.4176 - val_loss: 1.5935 - val_accuracy: 0.4357\n",
      "Epoch 23/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.6419 - accuracy: 0.4191 - val_loss: 1.5845 - val_accuracy: 0.4389\n",
      "Epoch 24/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6217 - accuracy: 0.4237 - val_loss: 1.5916 - val_accuracy: 0.4311\n",
      "Epoch 25/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6159 - accuracy: 0.4281 - val_loss: 1.5768 - val_accuracy: 0.4394\n",
      "Epoch 26/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6099 - accuracy: 0.4258 - val_loss: 1.5664 - val_accuracy: 0.4410\n",
      "Epoch 27/48\n",
      "263/263 [==============================] - 4s 17ms/step - loss: 1.6067 - accuracy: 0.4307 - val_loss: 1.5554 - val_accuracy: 0.4480\n",
      "Epoch 28/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5951 - accuracy: 0.4366 - val_loss: 1.5428 - val_accuracy: 0.4488\n",
      "Epoch 29/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5942 - accuracy: 0.4341 - val_loss: 1.5639 - val_accuracy: 0.4434\n",
      "Epoch 30/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5949 - accuracy: 0.4407 - val_loss: 1.5505 - val_accuracy: 0.4509\n",
      "Epoch 31/48\n",
      "263/263 [==============================] - 4s 17ms/step - loss: 1.5737 - accuracy: 0.4443 - val_loss: 1.5370 - val_accuracy: 0.4528\n",
      "Epoch 32/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5674 - accuracy: 0.4476 - val_loss: 1.5158 - val_accuracy: 0.4568\n",
      "Epoch 33/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5576 - accuracy: 0.4509 - val_loss: 1.5312 - val_accuracy: 0.4550\n",
      "Epoch 34/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5642 - accuracy: 0.4471 - val_loss: 1.5254 - val_accuracy: 0.4568\n",
      "Epoch 35/48\n",
      "263/263 [==============================] - 4s 17ms/step - loss: 1.5566 - accuracy: 0.4487 - val_loss: 1.5146 - val_accuracy: 0.4668\n",
      "Epoch 36/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5398 - accuracy: 0.4566 - val_loss: 1.5147 - val_accuracy: 0.4678\n",
      "Epoch 37/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5458 - accuracy: 0.4567 - val_loss: 1.5166 - val_accuracy: 0.4678\n",
      "Epoch 38/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5358 - accuracy: 0.4645 - val_loss: 1.5039 - val_accuracy: 0.4729\n",
      "Epoch 39/48\n",
      "263/263 [==============================] - 4s 17ms/step - loss: 1.5236 - accuracy: 0.4690 - val_loss: 1.4924 - val_accuracy: 0.4708\n",
      "Epoch 40/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.5430 - accuracy: 0.4583 - val_loss: 1.5170 - val_accuracy: 0.4622\n",
      "Epoch 41/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5362 - accuracy: 0.4635 - val_loss: 1.5027 - val_accuracy: 0.4617\n",
      "Epoch 42/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.5287 - accuracy: 0.4622 - val_loss: 1.4914 - val_accuracy: 0.4716\n",
      "Epoch 43/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.5313 - accuracy: 0.4636 - val_loss: 1.4876 - val_accuracy: 0.4807\n",
      "Epoch 44/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.5146 - accuracy: 0.4672 - val_loss: 1.4980 - val_accuracy: 0.4737\n",
      "Epoch 45/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5208 - accuracy: 0.4689 - val_loss: 1.4965 - val_accuracy: 0.4802\n",
      "Epoch 46/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5114 - accuracy: 0.4731 - val_loss: 1.4867 - val_accuracy: 0.4702\n",
      "Epoch 47/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.5091 - accuracy: 0.4726 - val_loss: 1.4926 - val_accuracy: 0.4697\n",
      "Epoch 48/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.5157 - accuracy: 0.4714 - val_loss: 1.4940 - val_accuracy: 0.4791\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1.4940 - accuracy: 0.4791\n",
      "Test loss: 1.4939720630645752\n",
      "Test accuracy: 0.4790884852409363\n",
      "[    0     1     2 ... 37300 37301 37302] [18653 18654 18655 ... 22380 22381 22382]\n",
      "-----------breaking line--------------\n",
      "----------------------------\n",
      "6\n",
      "----------------------------\n",
      "Epoch 1/48\n",
      "  2/263 [..............................] - ETA: 3:15 - loss: 3.1201 - accuracy: 0.0742WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0166s vs `on_train_batch_end` time: 1.4790s). Check your callbacks.\n",
      "263/263 [==============================] - 6s 23ms/step - loss: 2.4281 - accuracy: 0.1532 - val_loss: 2.2797 - val_accuracy: 0.2196\n",
      "Epoch 2/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 2.2221 - accuracy: 0.1936 - val_loss: 2.0558 - val_accuracy: 0.2603\n",
      "Epoch 3/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 2.0798 - accuracy: 0.2400 - val_loss: 1.9566 - val_accuracy: 0.2957\n",
      "Epoch 4/48\n",
      "263/263 [==============================] - 4s 17ms/step - loss: 1.9974 - accuracy: 0.2618 - val_loss: 1.9248 - val_accuracy: 0.2946\n",
      "Epoch 5/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.9491 - accuracy: 0.2746 - val_loss: 1.9042 - val_accuracy: 0.3019\n",
      "Epoch 6/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.9225 - accuracy: 0.2821 - val_loss: 1.8803 - val_accuracy: 0.3180\n",
      "Epoch 7/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.9040 - accuracy: 0.2939 - val_loss: 1.8449 - val_accuracy: 0.3450\n",
      "Epoch 8/48\n",
      "263/263 [==============================] - 4s 17ms/step - loss: 1.8821 - accuracy: 0.3011 - val_loss: 1.8350 - val_accuracy: 0.3340\n",
      "Epoch 9/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.8493 - accuracy: 0.3114 - val_loss: 1.7904 - val_accuracy: 0.3381\n",
      "Epoch 10/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.8343 - accuracy: 0.3234 - val_loss: 1.7611 - val_accuracy: 0.3571\n",
      "Epoch 11/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.8072 - accuracy: 0.3343 - val_loss: 1.7382 - val_accuracy: 0.3909\n",
      "Epoch 12/48\n",
      "263/263 [==============================] - 4s 17ms/step - loss: 1.7826 - accuracy: 0.3436 - val_loss: 1.7130 - val_accuracy: 0.4019\n",
      "Epoch 13/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.7531 - accuracy: 0.3570 - val_loss: 1.6786 - val_accuracy: 0.4115\n",
      "Epoch 14/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.7325 - accuracy: 0.3713 - val_loss: 1.6559 - val_accuracy: 0.4257\n",
      "Epoch 15/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.7234 - accuracy: 0.3715 - val_loss: 1.6514 - val_accuracy: 0.4303\n",
      "Epoch 16/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.6982 - accuracy: 0.3873 - val_loss: 1.6528 - val_accuracy: 0.4271\n",
      "Epoch 17/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.6922 - accuracy: 0.3889 - val_loss: 1.6137 - val_accuracy: 0.4295\n",
      "Epoch 18/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.6698 - accuracy: 0.3970 - val_loss: 1.6005 - val_accuracy: 0.4386\n",
      "Epoch 19/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.6552 - accuracy: 0.4050 - val_loss: 1.6063 - val_accuracy: 0.4429\n",
      "Epoch 20/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.6345 - accuracy: 0.4148 - val_loss: 1.5802 - val_accuracy: 0.4531\n",
      "Epoch 21/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.6293 - accuracy: 0.4141 - val_loss: 1.6102 - val_accuracy: 0.4410\n",
      "Epoch 22/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.6293 - accuracy: 0.4183 - val_loss: 1.5729 - val_accuracy: 0.4509\n",
      "Epoch 23/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.6162 - accuracy: 0.4214 - val_loss: 1.5618 - val_accuracy: 0.4598\n",
      "Epoch 24/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.6042 - accuracy: 0.4300 - val_loss: 1.5458 - val_accuracy: 0.4566\n",
      "Epoch 25/48\n",
      "263/263 [==============================] - 4s 17ms/step - loss: 1.5893 - accuracy: 0.4354 - val_loss: 1.5457 - val_accuracy: 0.4579\n",
      "Epoch 26/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.5881 - accuracy: 0.4365 - val_loss: 1.5377 - val_accuracy: 0.4660\n",
      "Epoch 27/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.5773 - accuracy: 0.4423 - val_loss: 1.6248 - val_accuracy: 0.4349\n",
      "Epoch 28/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.5835 - accuracy: 0.4367 - val_loss: 1.5489 - val_accuracy: 0.4563\n",
      "Epoch 29/48\n",
      "263/263 [==============================] - 5s 17ms/step - loss: 1.5788 - accuracy: 0.4410 - val_loss: 1.5383 - val_accuracy: 0.4587\n",
      "Epoch 30/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5731 - accuracy: 0.4402 - val_loss: 1.5312 - val_accuracy: 0.4729\n",
      "Epoch 31/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.5546 - accuracy: 0.4488 - val_loss: 1.5214 - val_accuracy: 0.4678\n",
      "Epoch 32/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.5456 - accuracy: 0.4509 - val_loss: 1.5076 - val_accuracy: 0.4724\n",
      "Epoch 33/48\n",
      "263/263 [==============================] - 4s 17ms/step - loss: 1.5395 - accuracy: 0.4536 - val_loss: 1.4897 - val_accuracy: 0.4761\n",
      "Epoch 34/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5382 - accuracy: 0.4532 - val_loss: 1.5183 - val_accuracy: 0.4724\n",
      "Epoch 35/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5373 - accuracy: 0.4565 - val_loss: 1.4959 - val_accuracy: 0.4777\n",
      "Epoch 36/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5272 - accuracy: 0.4607 - val_loss: 1.4869 - val_accuracy: 0.4866\n",
      "Epoch 37/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.5309 - accuracy: 0.4606 - val_loss: 1.5167 - val_accuracy: 0.4761\n",
      "Epoch 38/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.5198 - accuracy: 0.4632 - val_loss: 1.4837 - val_accuracy: 0.4871\n",
      "Epoch 39/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5213 - accuracy: 0.4616 - val_loss: 1.5007 - val_accuracy: 0.4681\n",
      "Epoch 40/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5136 - accuracy: 0.4671 - val_loss: 1.4920 - val_accuracy: 0.4826\n",
      "Epoch 41/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.5086 - accuracy: 0.4659 - val_loss: 1.4837 - val_accuracy: 0.4901\n",
      "Epoch 42/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.5033 - accuracy: 0.4708 - val_loss: 1.4781 - val_accuracy: 0.4893\n",
      "Epoch 43/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5122 - accuracy: 0.4652 - val_loss: 1.4753 - val_accuracy: 0.4820\n",
      "Epoch 44/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5016 - accuracy: 0.4760 - val_loss: 1.4789 - val_accuracy: 0.4877\n",
      "Epoch 45/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.4929 - accuracy: 0.4757 - val_loss: 1.4713 - val_accuracy: 0.4920\n",
      "Epoch 46/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.4901 - accuracy: 0.4799 - val_loss: 1.4687 - val_accuracy: 0.4930\n",
      "Epoch 47/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.4905 - accuracy: 0.4788 - val_loss: 1.4595 - val_accuracy: 0.4909\n",
      "Epoch 48/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.4935 - accuracy: 0.4724 - val_loss: 1.4539 - val_accuracy: 0.4933\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1.4539 - accuracy: 0.4933\n",
      "Test loss: 1.4539116621017456\n",
      "Test accuracy: 0.4932975769042969\n",
      "[    0     1     2 ... 37300 37301 37302] [22383 22384 22385 ... 26110 26111 26112]\n",
      "-----------breaking line--------------\n",
      "----------------------------\n",
      "7\n",
      "----------------------------\n",
      "Epoch 1/48\n",
      "  2/263 [..............................] - ETA: 3:08 - loss: 2.8815 - accuracy: 0.2461WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0130s vs `on_train_batch_end` time: 1.4316s). Check your callbacks.\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 2.4342 - accuracy: 0.1420 - val_loss: 2.2949 - val_accuracy: 0.1660\n",
      "Epoch 2/48\n",
      "263/263 [==============================] - 4s 17ms/step - loss: 2.2734 - accuracy: 0.1595 - val_loss: 2.2378 - val_accuracy: 0.1858\n",
      "Epoch 3/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.2370 - accuracy: 0.1677 - val_loss: 2.1828 - val_accuracy: 0.2209\n",
      "Epoch 4/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 2.1774 - accuracy: 0.1948 - val_loss: 1.9762 - val_accuracy: 0.2225\n",
      "Epoch 5/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 2.0405 - accuracy: 0.2504 - val_loss: 1.8916 - val_accuracy: 0.3110\n",
      "Epoch 6/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.9730 - accuracy: 0.2719 - val_loss: 1.8966 - val_accuracy: 0.3110\n",
      "Epoch 7/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.9316 - accuracy: 0.2918 - val_loss: 1.8330 - val_accuracy: 0.3483\n",
      "Epoch 8/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.9057 - accuracy: 0.3014 - val_loss: 1.8208 - val_accuracy: 0.3298\n",
      "Epoch 9/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.8799 - accuracy: 0.3136 - val_loss: 1.7846 - val_accuracy: 0.3590\n",
      "Epoch 10/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.8507 - accuracy: 0.3214 - val_loss: 1.7396 - val_accuracy: 0.3625\n",
      "Epoch 11/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.8283 - accuracy: 0.3353 - val_loss: 1.7214 - val_accuracy: 0.3831\n",
      "Epoch 12/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.8023 - accuracy: 0.3455 - val_loss: 1.6856 - val_accuracy: 0.3954\n",
      "Epoch 13/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.7843 - accuracy: 0.3512 - val_loss: 1.6933 - val_accuracy: 0.3794\n",
      "Epoch 14/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.7671 - accuracy: 0.3608 - val_loss: 1.6793 - val_accuracy: 0.4051\n",
      "Epoch 15/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.7610 - accuracy: 0.3626 - val_loss: 1.6622 - val_accuracy: 0.4166\n",
      "Epoch 16/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.7464 - accuracy: 0.3708 - val_loss: 1.6654 - val_accuracy: 0.4209\n",
      "Epoch 17/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.7309 - accuracy: 0.3775 - val_loss: 1.6476 - val_accuracy: 0.4335\n",
      "Epoch 18/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.7275 - accuracy: 0.3800 - val_loss: 1.6364 - val_accuracy: 0.4209\n",
      "Epoch 19/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.7056 - accuracy: 0.3841 - val_loss: 1.6352 - val_accuracy: 0.4214\n",
      "Epoch 20/48\n",
      "263/263 [==============================] - 4s 17ms/step - loss: 1.6966 - accuracy: 0.3906 - val_loss: 1.6442 - val_accuracy: 0.4161\n",
      "Epoch 21/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6808 - accuracy: 0.3958 - val_loss: 1.5959 - val_accuracy: 0.4424\n",
      "Epoch 22/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6670 - accuracy: 0.4016 - val_loss: 1.5734 - val_accuracy: 0.4520\n",
      "Epoch 23/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6525 - accuracy: 0.4076 - val_loss: 1.5861 - val_accuracy: 0.4370\n",
      "Epoch 24/48\n",
      "263/263 [==============================] - 4s 17ms/step - loss: 1.6330 - accuracy: 0.4152 - val_loss: 1.5883 - val_accuracy: 0.4450\n",
      "Epoch 25/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6278 - accuracy: 0.4173 - val_loss: 1.5633 - val_accuracy: 0.4547\n",
      "Epoch 26/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6278 - accuracy: 0.4141 - val_loss: 1.5669 - val_accuracy: 0.4515\n",
      "Epoch 27/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6273 - accuracy: 0.4176 - val_loss: 1.5528 - val_accuracy: 0.4576\n",
      "Epoch 28/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.6094 - accuracy: 0.4284 - val_loss: 1.5459 - val_accuracy: 0.4649\n",
      "Epoch 29/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.5989 - accuracy: 0.4283 - val_loss: 1.5563 - val_accuracy: 0.4523\n",
      "Epoch 30/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5936 - accuracy: 0.4318 - val_loss: 1.5261 - val_accuracy: 0.4700\n",
      "Epoch 31/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5922 - accuracy: 0.4323 - val_loss: 1.5242 - val_accuracy: 0.4686\n",
      "Epoch 32/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5777 - accuracy: 0.4410 - val_loss: 1.5161 - val_accuracy: 0.4686\n",
      "Epoch 33/48\n",
      "263/263 [==============================] - 4s 17ms/step - loss: 1.5721 - accuracy: 0.4440 - val_loss: 1.5123 - val_accuracy: 0.4662\n",
      "Epoch 34/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5679 - accuracy: 0.4453 - val_loss: 1.5062 - val_accuracy: 0.4791\n",
      "Epoch 35/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5679 - accuracy: 0.4454 - val_loss: 1.5155 - val_accuracy: 0.4759\n",
      "Epoch 36/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5545 - accuracy: 0.4483 - val_loss: 1.5086 - val_accuracy: 0.4759\n",
      "Epoch 37/48\n",
      "263/263 [==============================] - 4s 17ms/step - loss: 1.5504 - accuracy: 0.4538 - val_loss: 1.5032 - val_accuracy: 0.4721\n",
      "Epoch 38/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5458 - accuracy: 0.4536 - val_loss: 1.4903 - val_accuracy: 0.4788\n",
      "Epoch 39/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5477 - accuracy: 0.4532 - val_loss: 1.4882 - val_accuracy: 0.4796\n",
      "Epoch 40/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5485 - accuracy: 0.4524 - val_loss: 1.4868 - val_accuracy: 0.4823\n",
      "Epoch 41/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.5375 - accuracy: 0.4592 - val_loss: 1.4910 - val_accuracy: 0.4735\n",
      "Epoch 42/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.5287 - accuracy: 0.4597 - val_loss: 1.5110 - val_accuracy: 0.4668\n",
      "Epoch 43/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5317 - accuracy: 0.4585 - val_loss: 1.5527 - val_accuracy: 0.4587\n",
      "Epoch 44/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5242 - accuracy: 0.4641 - val_loss: 1.4761 - val_accuracy: 0.4866\n",
      "Epoch 45/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.5268 - accuracy: 0.4631 - val_loss: 1.4743 - val_accuracy: 0.4842\n",
      "Epoch 46/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.5252 - accuracy: 0.4623 - val_loss: 1.4814 - val_accuracy: 0.4796\n",
      "Epoch 47/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5185 - accuracy: 0.4647 - val_loss: 1.4763 - val_accuracy: 0.4799\n",
      "Epoch 48/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.5061 - accuracy: 0.4670 - val_loss: 1.4713 - val_accuracy: 0.4893\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.4737 - accuracy: 0.48 - 0s 2ms/step - loss: 1.4713 - accuracy: 0.4893\n",
      "Test loss: 1.4712916612625122\n",
      "Test accuracy: 0.48927614092826843\n",
      "[    0     1     2 ... 37300 37301 37302] [26113 26114 26115 ... 29840 29841 29842]\n",
      "-----------breaking line--------------\n",
      "----------------------------\n",
      "8\n",
      "----------------------------\n",
      "Epoch 1/48\n",
      "  2/263 [..............................] - ETA: 4:16 - loss: 2.8667 - accuracy: 0.1016WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0211s vs `on_train_batch_end` time: 1.9417s). Check your callbacks.\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 2.4254 - accuracy: 0.1402 - val_loss: 2.3027 - val_accuracy: 0.1456\n",
      "Epoch 2/48\n",
      "263/263 [==============================] - 4s 17ms/step - loss: 2.2585 - accuracy: 0.1720 - val_loss: 2.1761 - val_accuracy: 0.2231\n",
      "Epoch 3/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 2.1338 - accuracy: 0.2217 - val_loss: 1.9820 - val_accuracy: 0.2823\n",
      "Epoch 4/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 2.0108 - accuracy: 0.2606 - val_loss: 1.9350 - val_accuracy: 0.2794\n",
      "Epoch 5/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.9520 - accuracy: 0.2824 - val_loss: 1.9182 - val_accuracy: 0.2954\n",
      "Epoch 6/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.9235 - accuracy: 0.2919 - val_loss: 1.8968 - val_accuracy: 0.3115\n",
      "Epoch 7/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.8903 - accuracy: 0.3025 - val_loss: 1.8274 - val_accuracy: 0.3477\n",
      "Epoch 8/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.8656 - accuracy: 0.3130 - val_loss: 1.8126 - val_accuracy: 0.3525\n",
      "Epoch 9/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.8335 - accuracy: 0.3260 - val_loss: 1.7770 - val_accuracy: 0.3788\n",
      "Epoch 10/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.8056 - accuracy: 0.3393 - val_loss: 1.7552 - val_accuracy: 0.3850\n",
      "Epoch 11/48\n",
      "263/263 [==============================] - 4s 17ms/step - loss: 1.7946 - accuracy: 0.3478 - val_loss: 1.7368 - val_accuracy: 0.3769\n",
      "Epoch 12/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.7730 - accuracy: 0.3599 - val_loss: 1.7259 - val_accuracy: 0.4043\n",
      "Epoch 13/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.7623 - accuracy: 0.3677 - val_loss: 1.6931 - val_accuracy: 0.4043\n",
      "Epoch 14/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.7300 - accuracy: 0.3791 - val_loss: 1.6739 - val_accuracy: 0.4166\n",
      "Epoch 15/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.7157 - accuracy: 0.3850 - val_loss: 1.6659 - val_accuracy: 0.4158\n",
      "Epoch 16/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.6989 - accuracy: 0.3930 - val_loss: 1.6430 - val_accuracy: 0.4185\n",
      "Epoch 17/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6865 - accuracy: 0.3990 - val_loss: 1.6497 - val_accuracy: 0.4118\n",
      "Epoch 18/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.6760 - accuracy: 0.4070 - val_loss: 1.6351 - val_accuracy: 0.4391\n",
      "Epoch 19/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.6614 - accuracy: 0.4094 - val_loss: 1.6250 - val_accuracy: 0.4402\n",
      "Epoch 20/48\n",
      "263/263 [==============================] - 4s 17ms/step - loss: 1.6449 - accuracy: 0.4129 - val_loss: 1.6063 - val_accuracy: 0.4442\n",
      "Epoch 21/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6321 - accuracy: 0.4230 - val_loss: 1.5934 - val_accuracy: 0.4534\n",
      "Epoch 22/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6130 - accuracy: 0.4320 - val_loss: 1.5926 - val_accuracy: 0.4595\n",
      "Epoch 23/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.6038 - accuracy: 0.4311 - val_loss: 1.6012 - val_accuracy: 0.4434\n",
      "Epoch 24/48\n",
      "263/263 [==============================] - 5s 17ms/step - loss: 1.6024 - accuracy: 0.4354 - val_loss: 1.5673 - val_accuracy: 0.4475\n",
      "Epoch 25/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.5930 - accuracy: 0.4398 - val_loss: 1.5735 - val_accuracy: 0.4515\n",
      "Epoch 26/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.5765 - accuracy: 0.4416 - val_loss: 1.5588 - val_accuracy: 0.4472\n",
      "Epoch 27/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.5751 - accuracy: 0.4446 - val_loss: 1.5659 - val_accuracy: 0.4678\n",
      "Epoch 28/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.5785 - accuracy: 0.4462 - val_loss: 1.5495 - val_accuracy: 0.4713\n",
      "Epoch 29/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.5652 - accuracy: 0.4516 - val_loss: 1.5385 - val_accuracy: 0.4654\n",
      "Epoch 30/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5613 - accuracy: 0.4487 - val_loss: 1.5415 - val_accuracy: 0.4702\n",
      "Epoch 31/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5599 - accuracy: 0.4512 - val_loss: 1.5686 - val_accuracy: 0.4611\n",
      "Epoch 32/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5449 - accuracy: 0.4576 - val_loss: 1.5349 - val_accuracy: 0.4753\n",
      "Epoch 33/48\n",
      "263/263 [==============================] - 4s 17ms/step - loss: 1.5546 - accuracy: 0.4495 - val_loss: 1.5315 - val_accuracy: 0.4756\n",
      "Epoch 34/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5502 - accuracy: 0.4547 - val_loss: 1.5407 - val_accuracy: 0.4799\n",
      "Epoch 35/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5328 - accuracy: 0.4609 - val_loss: 1.5265 - val_accuracy: 0.4807\n",
      "Epoch 36/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5269 - accuracy: 0.4618 - val_loss: 1.5128 - val_accuracy: 0.4928\n",
      "Epoch 37/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.5292 - accuracy: 0.4621 - val_loss: 1.5163 - val_accuracy: 0.4735\n",
      "Epoch 38/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5186 - accuracy: 0.4659 - val_loss: 1.5139 - val_accuracy: 0.4807\n",
      "Epoch 39/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5323 - accuracy: 0.4608 - val_loss: 1.5216 - val_accuracy: 0.4786\n",
      "Epoch 40/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5251 - accuracy: 0.4651 - val_loss: 1.5230 - val_accuracy: 0.4791\n",
      "Epoch 41/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.5251 - accuracy: 0.4653 - val_loss: 1.5083 - val_accuracy: 0.4887\n",
      "Epoch 42/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.5043 - accuracy: 0.4727 - val_loss: 1.5028 - val_accuracy: 0.4898\n",
      "Epoch 43/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5087 - accuracy: 0.4716 - val_loss: 1.5048 - val_accuracy: 0.4936\n",
      "Epoch 44/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5084 - accuracy: 0.4723 - val_loss: 1.5023 - val_accuracy: 0.4949\n",
      "Epoch 45/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.4959 - accuracy: 0.4768 - val_loss: 1.4898 - val_accuracy: 0.4936\n",
      "Epoch 46/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.4973 - accuracy: 0.4780 - val_loss: 1.4961 - val_accuracy: 0.4887\n",
      "Epoch 47/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.4972 - accuracy: 0.4775 - val_loss: 1.4931 - val_accuracy: 0.4968\n",
      "Epoch 48/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.4918 - accuracy: 0.4766 - val_loss: 1.4879 - val_accuracy: 0.4979\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1.4879 - accuracy: 0.4979\n",
      "Test loss: 1.487869143486023\n",
      "Test accuracy: 0.49785521626472473\n",
      "[    0     1     2 ... 37300 37301 37302] [29843 29844 29845 ... 33570 33571 33572]\n",
      "-----------breaking line--------------\n",
      "----------------------------\n",
      "9\n",
      "----------------------------\n",
      "Epoch 1/48\n",
      "  2/263 [..............................] - ETA: 3:34 - loss: 2.8515 - accuracy: 0.1016WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0143s vs `on_train_batch_end` time: 1.6256s). Check your callbacks.\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 2.4205 - accuracy: 0.1624 - val_loss: 2.2718 - val_accuracy: 0.2204\n",
      "Epoch 2/48\n",
      "263/263 [==============================] - 5s 17ms/step - loss: 2.1760 - accuracy: 0.2089 - val_loss: 2.0326 - val_accuracy: 0.2810\n",
      "Epoch 3/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.0397 - accuracy: 0.2530 - val_loss: 1.9263 - val_accuracy: 0.3048\n",
      "Epoch 4/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.9784 - accuracy: 0.2723 - val_loss: 1.8949 - val_accuracy: 0.3056\n",
      "Epoch 5/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.9422 - accuracy: 0.2883 - val_loss: 1.8820 - val_accuracy: 0.3070\n",
      "Epoch 6/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.9132 - accuracy: 0.2944 - val_loss: 1.8426 - val_accuracy: 0.3349\n",
      "Epoch 7/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.8893 - accuracy: 0.3059 - val_loss: 1.8042 - val_accuracy: 0.3550\n",
      "Epoch 8/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.8697 - accuracy: 0.3136 - val_loss: 1.7903 - val_accuracy: 0.3560\n",
      "Epoch 9/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.8470 - accuracy: 0.3215 - val_loss: 1.7688 - val_accuracy: 0.3445\n",
      "Epoch 10/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.8217 - accuracy: 0.3365 - val_loss: 1.7382 - val_accuracy: 0.3705\n",
      "Epoch 11/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.7977 - accuracy: 0.3452 - val_loss: 1.7126 - val_accuracy: 0.3946\n",
      "Epoch 12/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.7811 - accuracy: 0.3560 - val_loss: 1.6941 - val_accuracy: 0.3743\n",
      "Epoch 13/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.7559 - accuracy: 0.3647 - val_loss: 1.6697 - val_accuracy: 0.4155\n",
      "Epoch 14/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.7352 - accuracy: 0.3732 - val_loss: 1.6713 - val_accuracy: 0.4064\n",
      "Epoch 15/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.7431 - accuracy: 0.3702 - val_loss: 1.6536 - val_accuracy: 0.4172\n",
      "Epoch 16/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.7070 - accuracy: 0.3891 - val_loss: 1.6447 - val_accuracy: 0.4223\n",
      "Epoch 17/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.6899 - accuracy: 0.3945 - val_loss: 1.6293 - val_accuracy: 0.4239\n",
      "Epoch 18/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6725 - accuracy: 0.4042 - val_loss: 1.6228 - val_accuracy: 0.4397\n",
      "Epoch 19/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.6701 - accuracy: 0.4068 - val_loss: 1.6104 - val_accuracy: 0.4434\n",
      "Epoch 20/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.6547 - accuracy: 0.4125 - val_loss: 1.6049 - val_accuracy: 0.4413\n",
      "Epoch 21/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6422 - accuracy: 0.4191 - val_loss: 1.5836 - val_accuracy: 0.4493\n",
      "Epoch 22/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6403 - accuracy: 0.4193 - val_loss: 1.5867 - val_accuracy: 0.4542\n",
      "Epoch 23/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.6214 - accuracy: 0.4280 - val_loss: 1.5711 - val_accuracy: 0.4568\n",
      "Epoch 24/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.6194 - accuracy: 0.4261 - val_loss: 1.5813 - val_accuracy: 0.4480\n",
      "Epoch 25/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5986 - accuracy: 0.4364 - val_loss: 1.5686 - val_accuracy: 0.4536\n",
      "Epoch 26/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5899 - accuracy: 0.4373 - val_loss: 1.5512 - val_accuracy: 0.4584\n",
      "Epoch 27/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5830 - accuracy: 0.4410 - val_loss: 1.5593 - val_accuracy: 0.4493\n",
      "Epoch 28/48\n",
      "263/263 [==============================] - 4s 17ms/step - loss: 1.5913 - accuracy: 0.4376 - val_loss: 1.5325 - val_accuracy: 0.4681\n",
      "Epoch 29/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5848 - accuracy: 0.4449 - val_loss: 1.5387 - val_accuracy: 0.4550\n",
      "Epoch 30/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5773 - accuracy: 0.4429 - val_loss: 1.5370 - val_accuracy: 0.4737\n",
      "Epoch 31/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5761 - accuracy: 0.4487 - val_loss: 1.5331 - val_accuracy: 0.4665\n",
      "Epoch 32/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.5709 - accuracy: 0.4488 - val_loss: 1.5341 - val_accuracy: 0.4657\n",
      "Epoch 33/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.5764 - accuracy: 0.4431 - val_loss: 1.5325 - val_accuracy: 0.4660\n",
      "Epoch 34/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5535 - accuracy: 0.4561 - val_loss: 1.5303 - val_accuracy: 0.4681\n",
      "Epoch 35/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5448 - accuracy: 0.4591 - val_loss: 1.5188 - val_accuracy: 0.4718\n",
      "Epoch 36/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5479 - accuracy: 0.4574 - val_loss: 1.5251 - val_accuracy: 0.4665\n",
      "Epoch 37/48\n",
      "263/263 [==============================] - 4s 17ms/step - loss: 1.5388 - accuracy: 0.4606 - val_loss: 1.5220 - val_accuracy: 0.4745\n",
      "Epoch 38/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5307 - accuracy: 0.4613 - val_loss: 1.5132 - val_accuracy: 0.4700\n",
      "Epoch 39/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5278 - accuracy: 0.4656 - val_loss: 1.5189 - val_accuracy: 0.4759\n",
      "Epoch 40/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5302 - accuracy: 0.4643 - val_loss: 1.5031 - val_accuracy: 0.4729\n",
      "Epoch 41/48\n",
      "263/263 [==============================] - 5s 17ms/step - loss: 1.5288 - accuracy: 0.4664 - val_loss: 1.5240 - val_accuracy: 0.4670\n",
      "Epoch 42/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.5230 - accuracy: 0.4706 - val_loss: 1.5052 - val_accuracy: 0.4735\n",
      "Epoch 43/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.5216 - accuracy: 0.4695 - val_loss: 1.5119 - val_accuracy: 0.4697\n",
      "Epoch 44/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.5234 - accuracy: 0.4671 - val_loss: 1.5062 - val_accuracy: 0.4769\n",
      "Epoch 45/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.5178 - accuracy: 0.4717 - val_loss: 1.4991 - val_accuracy: 0.4871\n",
      "Epoch 46/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.5041 - accuracy: 0.4752 - val_loss: 1.5150 - val_accuracy: 0.4740\n",
      "Epoch 47/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5093 - accuracy: 0.4754 - val_loss: 1.5050 - val_accuracy: 0.4769\n",
      "Epoch 48/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.5053 - accuracy: 0.4760 - val_loss: 1.4917 - val_accuracy: 0.4831\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 1.4917 - accuracy: 0.4831\n",
      "Test loss: 1.4917329549789429\n",
      "Test accuracy: 0.4831099212169647\n",
      "[    0     1     2 ... 33570 33571 33572] [33573 33574 33575 ... 37300 37301 37302]\n",
      "-----------breaking line--------------\n",
      "----------------------------\n",
      "10\n",
      "----------------------------\n",
      "Epoch 1/48\n",
      "  2/263 [..............................] - ETA: 3:20 - loss: 2.8762 - accuracy: 0.1094WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0053s vs `on_train_batch_end` time: 1.5293s). Check your callbacks.\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 2.4235 - accuracy: 0.1510 - val_loss: 2.2865 - val_accuracy: 0.1710\n",
      "Epoch 2/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 2.2129 - accuracy: 0.1994 - val_loss: 2.0475 - val_accuracy: 0.2410\n",
      "Epoch 3/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 2.0630 - accuracy: 0.2548 - val_loss: 1.9474 - val_accuracy: 0.3048\n",
      "Epoch 4/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.9863 - accuracy: 0.2800 - val_loss: 1.9072 - val_accuracy: 0.3097\n",
      "Epoch 5/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.9466 - accuracy: 0.2922 - val_loss: 1.9052 - val_accuracy: 0.3083\n",
      "Epoch 6/48\n",
      "263/263 [==============================] - 5s 18ms/step - loss: 1.9221 - accuracy: 0.2977 - val_loss: 1.8728 - val_accuracy: 0.3137\n",
      "Epoch 7/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.8871 - accuracy: 0.3112 - val_loss: 1.8558 - val_accuracy: 0.3322\n",
      "Epoch 8/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.8722 - accuracy: 0.3194 - val_loss: 1.8358 - val_accuracy: 0.3244\n",
      "Epoch 9/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.8559 - accuracy: 0.3240 - val_loss: 1.8233 - val_accuracy: 0.3330\n",
      "Epoch 10/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.8498 - accuracy: 0.3241 - val_loss: 1.7962 - val_accuracy: 0.3450\n",
      "Epoch 11/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.8254 - accuracy: 0.3333 - val_loss: 1.7854 - val_accuracy: 0.3692\n",
      "Epoch 12/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.7948 - accuracy: 0.3459 - val_loss: 1.7593 - val_accuracy: 0.3694\n",
      "Epoch 13/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.7780 - accuracy: 0.3525 - val_loss: 1.7375 - val_accuracy: 0.3617\n",
      "Epoch 14/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.7663 - accuracy: 0.3558 - val_loss: 1.7313 - val_accuracy: 0.3914\n",
      "Epoch 15/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.7423 - accuracy: 0.3669 - val_loss: 1.6913 - val_accuracy: 0.4027\n",
      "Epoch 16/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.7354 - accuracy: 0.3741 - val_loss: 1.6769 - val_accuracy: 0.3869\n",
      "Epoch 17/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.7153 - accuracy: 0.3838 - val_loss: 1.6826 - val_accuracy: 0.4016\n",
      "Epoch 18/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.7070 - accuracy: 0.3878 - val_loss: 1.6552 - val_accuracy: 0.4137\n",
      "Epoch 19/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.6884 - accuracy: 0.3934 - val_loss: 1.6547 - val_accuracy: 0.4094\n",
      "Epoch 20/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6766 - accuracy: 0.4004 - val_loss: 1.6324 - val_accuracy: 0.4196\n",
      "Epoch 21/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6656 - accuracy: 0.4059 - val_loss: 1.6231 - val_accuracy: 0.4201\n",
      "Epoch 22/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6448 - accuracy: 0.4147 - val_loss: 1.6225 - val_accuracy: 0.4292\n",
      "Epoch 23/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.6348 - accuracy: 0.4201 - val_loss: 1.6130 - val_accuracy: 0.4346\n",
      "Epoch 24/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6338 - accuracy: 0.4222 - val_loss: 1.6176 - val_accuracy: 0.4217\n",
      "Epoch 25/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6225 - accuracy: 0.4261 - val_loss: 1.5940 - val_accuracy: 0.4362\n",
      "Epoch 26/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.6160 - accuracy: 0.4287 - val_loss: 1.5950 - val_accuracy: 0.4365\n",
      "Epoch 27/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.5959 - accuracy: 0.4336 - val_loss: 1.5954 - val_accuracy: 0.4271\n",
      "Epoch 28/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.5904 - accuracy: 0.4394 - val_loss: 1.5825 - val_accuracy: 0.4408\n",
      "Epoch 29/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5806 - accuracy: 0.4430 - val_loss: 1.5772 - val_accuracy: 0.4434\n",
      "Epoch 30/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5700 - accuracy: 0.4464 - val_loss: 1.5607 - val_accuracy: 0.4445\n",
      "Epoch 31/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5633 - accuracy: 0.4506 - val_loss: 1.5683 - val_accuracy: 0.4456\n",
      "Epoch 32/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.5656 - accuracy: 0.4474 - val_loss: 1.5604 - val_accuracy: 0.4383\n",
      "Epoch 33/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5565 - accuracy: 0.4504 - val_loss: 1.5543 - val_accuracy: 0.4413\n",
      "Epoch 34/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5565 - accuracy: 0.4492 - val_loss: 1.5477 - val_accuracy: 0.4539\n",
      "Epoch 35/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5543 - accuracy: 0.4540 - val_loss: 1.5648 - val_accuracy: 0.4375\n",
      "Epoch 36/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.5383 - accuracy: 0.4597 - val_loss: 1.5336 - val_accuracy: 0.4566\n",
      "Epoch 37/48\n",
      "263/263 [==============================] - 4s 15ms/step - loss: 1.5353 - accuracy: 0.4625 - val_loss: 1.5506 - val_accuracy: 0.4542\n",
      "Epoch 38/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5296 - accuracy: 0.4650 - val_loss: 1.5276 - val_accuracy: 0.4576\n",
      "Epoch 39/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5213 - accuracy: 0.4667 - val_loss: 1.5527 - val_accuracy: 0.4523\n",
      "Epoch 40/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5456 - accuracy: 0.4565 - val_loss: 1.5543 - val_accuracy: 0.4432\n",
      "Epoch 41/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.5373 - accuracy: 0.4589 - val_loss: 1.5287 - val_accuracy: 0.4665\n",
      "Epoch 42/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5360 - accuracy: 0.4624 - val_loss: 1.5221 - val_accuracy: 0.4684\n",
      "Epoch 43/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5369 - accuracy: 0.4624 - val_loss: 1.5318 - val_accuracy: 0.4603\n",
      "Epoch 44/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5268 - accuracy: 0.4660 - val_loss: 1.5288 - val_accuracy: 0.4641\n",
      "Epoch 45/48\n",
      "263/263 [==============================] - 4s 16ms/step - loss: 1.5092 - accuracy: 0.4743 - val_loss: 1.5241 - val_accuracy: 0.4611\n",
      "Epoch 46/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5039 - accuracy: 0.4751 - val_loss: 1.5526 - val_accuracy: 0.4552\n",
      "Epoch 47/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.5024 - accuracy: 0.4746 - val_loss: 1.5152 - val_accuracy: 0.4713\n",
      "Epoch 48/48\n",
      "263/263 [==============================] - 4s 14ms/step - loss: 1.4962 - accuracy: 0.4769 - val_loss: 1.5206 - val_accuracy: 0.4595\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1.5206 - accuracy: 0.4595\n",
      "Test loss: 1.5205641984939575\n",
      "Test accuracy: 0.4595174193382263\n",
      "WARNING:tensorflow:From C:\\Users\\Guest1\\anaconda3\\envs\\backup_20220216_20220322\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\Guest1\\anaconda3\\envs\\backup_20220216_20220322\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: SoundClassification-E4.model\\assets\n"
     ]
    }
   ],
   "source": [
    "#To see how many samples are in X-train and y-train\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "count = 0\n",
    "\n",
    "keras.backend.clear_session()\n",
    "\n",
    "def ReshapeLayer(x):\n",
    "    \n",
    "    shape = x.shape\n",
    "    \n",
    "    # 1 possibility: H,W*channel\n",
    "    reshape = Reshape((shape[1],shape[2]*shape[3]))(x)\n",
    "    \n",
    "    # 2 possibility: W,H*channel\n",
    "    # transpose = Permute((2,1,3))(x)\n",
    "    # reshape = Reshape((shape[1],shape[2]*shape[3]))(transpose)\n",
    "    \n",
    "    return reshape\n",
    "\n",
    "for train_set, test_set in kf.split(dataset):\n",
    "     print( train_set, test_set)\n",
    "     print(\"-----------breaking line--------------\")\n",
    "     #X_train, X_test, y_train, y_test = dataset[train_set], dataset[test_set]\n",
    " \n",
    "     print('----------------------------')\n",
    "     count += 1\n",
    "     print(count)\n",
    "     print('----------------------------')\n",
    " \n",
    "     X_train,y_train = zip(*dataset[train_set])\n",
    "     X_test, y_test = zip(*dataset[test_set])\n",
    " \n",
    "     # Reshape for CNN input\n",
    "     X_train = np.array([x.reshape( (128, 128) ) for x in X_train])\n",
    "     X_test = np.array([x.reshape( (128, 128) ) for x in X_test])\n",
    " \n",
    "     # One-Hot encoding for classes\n",
    "     y_train = np.array(keras.utils.to_categorical(y_train, 10))\n",
    "     y_test = np.array(keras.utils.to_categorical(y_test, 10))\n",
    "\n",
    " \n",
    "     NAME = \"graphic-{}-\".format(int(time.time()))\n",
    "     tensorboard = TensorBoard(log_dir='E4-epoch_48-{}'.format(NAME +  str(count)))\n",
    " \n",
    " \n",
    "     model = Sequential()\n",
    "\n",
    "     model.add(\n",
    "        Conv1D(24, kernel_size=(5), input_shape=(128, 128), kernel_regularizer=keras.regularizers.l2(0.001))\n",
    "        )\n",
    "     model.add(MaxPooling1D(8))\n",
    "     model.add(Activation('relu'))\n",
    "     model.add(Dropout(rate=0.25))\n",
    " \n",
    "     model.add(Conv1D(48, kernel_size=(1), padding=\"valid\", kernel_regularizer=keras.regularizers.l2(0.001)))\n",
    "     model.add(MaxPooling1D(8))\n",
    "     model.add(Activation('relu'))\n",
    "     model.add(Dropout(rate=0.25))\n",
    " \n",
    "     model.add(Conv1D(48, kernel_size=(1), padding=\"valid\", kernel_regularizer=keras.regularizers.l2(0.001)))\n",
    "     model.add(Activation('relu'))\n",
    "\n",
    "     model.add(\n",
    "        LSTM(units = 32, dropout = 0.5, return_sequences=True)\n",
    "        ) \n",
    "   \n",
    "     model.add(LSTM(32, dropout = 0.5))\n",
    "\n",
    "     model.add(BatchNormalization())\n",
    "\n",
    "     model.add(Dense(10))\n",
    "     model.add(Activation('softmax'))\n",
    " \n",
    "     model.compile(\n",
    " \t    optimizer=\"Adam\",\n",
    " \t    loss=\"categorical_crossentropy\",\n",
    " \t    metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "\n",
    "     model.fit(\n",
    " \t    x=X_train, \n",
    " \t    y=y_train,\n",
    "        epochs=48,\n",
    "        batch_size=128,\n",
    "        validation_data = (X_test, y_test),\n",
    "        shuffle= False,\n",
    " \t      callbacks=[tensorboard]\n",
    " \t    )\n",
    " \n",
    "     score = model.evaluate(\n",
    " \t    x=X_test,\n",
    " \t    y=y_test\n",
    "        )\n",
    " \n",
    "     print('Test loss:', score[0])\n",
    "     print('Test accuracy:', score[1])\n",
    "    \n",
    "\n",
    "\n",
    "model.save('SoundClassification-E4.model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopExecution",
     "evalue": "",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "class StopExecution(Exception):\n",
    "    def _render_traceback_(self):\n",
    "        pass\n",
    "\n",
    "raise StopExecution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"SoundClassification-E4.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_27 (Conv1D)           (None, 124, 24)           15384     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 15, 24)            0         \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 15, 24)            0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 15, 24)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 15, 48)            1200      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 1, 48)             0         \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 1, 48)             0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 1, 48)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 1, 48)             2352      \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 1, 48)             0         \n",
      "_________________________________________________________________\n",
      "lstm_18 (LSTM)               (None, 1, 32)             10368     \n",
      "_________________________________________________________________\n",
      "lstm_19 (LSTM)               (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                330       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 38,082\n",
      "Trainable params: 38,018\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(filepath):\n",
    "    y, sr = librosa.load(filepath, duration=2.97)\n",
    "    ps = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "    ps.shape\n",
    "    if ps.shape != (128,128):\n",
    "        new_image_width = 128\n",
    "        new_image_height = 128\n",
    "        color = (0)\n",
    "        result = np.full((new_image_height,new_image_width, 1), color, dtype=np.uint8)\n",
    "        return result.reshape(1, 128, 128)\n",
    "\n",
    "    else:\n",
    "        return ps.reshape(-1, 128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "['AC_0.wav', 'CarHorn_1.wav', 'ChildrenPlaying_2.wav', 'DogBark_3.wav', 'Drill_4.wav', 'EngineIdling_5_2.wav', 'GunShot_6.wav', 'Jackhammer_7.wav', 'Siren_8.wav', 'StreetMusic_9.wav']\n"
     ]
    }
   ],
   "source": [
    "from os import walk\n",
    "\n",
    "mypath = 'Test/'\n",
    "f = []\n",
    "for (dirpath, dirnames, filenames) in walk(mypath):\n",
    "    f.extend(filenames)\n",
    "    break\n",
    "print(len(f))\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "for file in f:\n",
    "    count += 1\n",
    "    prediction = model.predict([prepare('Test/'+file)])\n",
    "    y_classes = prediction.argmax(axis=-1)\n",
    "    max = np.amax(prediction)\n",
    "    print(str(count) + \" th\")\n",
    "    print(file)\n",
    "    print(\"Match accuracy: \" + str(max))\n",
    "    print(\"class: \" + str(y_classes))\n",
    "    print(prediction)\n",
    "    print(\"-----------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
