{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Activation, Dense, Dropout, Conv2D, \\\n",
    "                         Flatten, MaxPooling2D, LSTM, TimeDistributed, Reshape, Lambda, Conv1D, MaxPooling1D\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import TensorBoard\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice_file_name</th>\n",
       "      <th>fsID</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>salience</th>\n",
       "      <th>fold</th>\n",
       "      <th>classID</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100032-3-0-0.wav</td>\n",
       "      <td>100032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.317551</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100263-2-0-117.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>58.5</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100263-2-0-121.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>60.5</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100263-2-0-126.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>63.0</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100263-2-0-137.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>68.5</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      slice_file_name    fsID  start        end  salience  fold  classID  \\\n",
       "0    100032-3-0-0.wav  100032    0.0   0.317551         1     5        3   \n",
       "1  100263-2-0-117.wav  100263   58.5  62.500000         1     5        2   \n",
       "2  100263-2-0-121.wav  100263   60.5  64.500000         1     5        2   \n",
       "3  100263-2-0-126.wav  100263   63.0  67.000000         1     5        2   \n",
       "4  100263-2-0-137.wav  100263   68.5  72.500000         1     5        2   \n",
       "\n",
       "              class  \n",
       "0          dog_bark  \n",
       "1  children_playing  \n",
       "2  children_playing  \n",
       "3  children_playing  \n",
       "4  children_playing  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Data\n",
    "data = pd.read_csv('UrbanSounds8K/metadata/UrbanSound8K.csv')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8732, 8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7468, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get data over 3 seconds long\n",
    "valid_data = data[['slice_file_name', 'fold' ,'classID', 'class']][ data['end']-data['start'] >= 3 ]\n",
    "valid_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x21cdb1785c8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y, sr = librosa.load('UrbanSounds8K/audio/fold9/13579-2-0-16.wav', duration=2.97)\n",
    "ps = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "ps.shape\n",
    "\n",
    "mel_sgram = librosa.amplitude_to_db(ps, ref=np.min)\n",
    "\n",
    "librosa.display.specshow(ps, y_axis='mel', x_axis='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data['path'] = 'fold' + valid_data['fold'].astype('str') + '/' + valid_data['slice_file_name'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use it to create data ######################################################################\n",
    "def creates_train_data():\n",
    "    D = [] # Dataset\n",
    "\n",
    "    for row in valid_data.itertuples():\n",
    "        y, sr = librosa.load('UrbanSounds8K/augmented/ps2_m25/' + row.path, duration=2.97)  #2.97 = 3*1000 - 3*1000/128  ###############################\n",
    "        ps = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "        if ps.shape != (128, 128): continue\n",
    "        D.append( (ps, row.classID) )\n",
    "    np.save('train_data_augmented_ps2_m25.npy', D) ###############################\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37303"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load.__defaults__=(None, True, True, 'ASCII')\n",
    "a = np.load('train_data.npy')\n",
    "b = np.load('train_data_augmented_speed_81.npy')\n",
    "c = np.load('train_data_augmented_speed_107.npy')\n",
    "d = np.load('train_data_augmented_ps1_2.npy')\n",
    "e = np.load('train_data_augmented_ps2_m25.npy')\n",
    "\n",
    "# np.savez('train.npz',a,b,c,d,e) ############################################################################\n",
    "# r = np.load('train.npz') ############################################################################\n",
    "# locals().update(r) ############################################################################\n",
    "\n",
    "tuple = (a,b,c,d,e)\n",
    "tuplearr = np.vstack(tuple)\n",
    "len(tuplearr)\n",
    "dataset = tuplearr\n",
    "random.shuffle(dataset)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3731  3732  3733 ... 37300 37301 37302] [   0    1    2 ... 3728 3729 3730]\n",
      "-----------breaking line--------------\n",
      "----------------------------\n",
      "1\n",
      "----------------------------\n",
      "Epoch 1/24\n",
      "  1/263 [..............................] - ETA: 0s - loss: 2.2977 - accuracy: 0.1328WARNING:tensorflow:From C:\\Users\\otsanyin6920\\anaconda3\\envs\\backup_20220216\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "  2/263 [..............................] - ETA: 20s - loss: 2.2968 - accuracy: 0.1484WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0342s vs `on_train_batch_end` time: 0.1172s). Check your callbacks.\n",
      "263/263 [==============================] - 8s 31ms/step - loss: 1.8028 - accuracy: 0.3228 - val_loss: 1.5113 - val_accuracy: 0.4559\n",
      "Epoch 2/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 1.5307 - accuracy: 0.4263 - val_loss: 1.3159 - val_accuracy: 0.5248\n",
      "Epoch 3/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 1.4220 - accuracy: 0.4803 - val_loss: 1.2687 - val_accuracy: 0.5352\n",
      "Epoch 4/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 1.3539 - accuracy: 0.5082 - val_loss: 1.1576 - val_accuracy: 0.5784\n",
      "Epoch 5/24\n",
      "263/263 [==============================] - 6s 25ms/step - loss: 1.2745 - accuracy: 0.5413 - val_loss: 1.0806 - val_accuracy: 0.6178\n",
      "Epoch 6/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 1.2101 - accuracy: 0.5707 - val_loss: 1.0372 - val_accuracy: 0.6352\n",
      "Epoch 7/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 1.1480 - accuracy: 0.5955 - val_loss: 0.9441 - val_accuracy: 0.6652\n",
      "Epoch 8/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 1.1166 - accuracy: 0.6083 - val_loss: 0.9040 - val_accuracy: 0.6851\n",
      "Epoch 9/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 1.0534 - accuracy: 0.6308 - val_loss: 0.8866 - val_accuracy: 0.6912\n",
      "Epoch 10/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 1.0172 - accuracy: 0.6473 - val_loss: 0.8424 - val_accuracy: 0.7215\n",
      "Epoch 11/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.9674 - accuracy: 0.6647 - val_loss: 0.7950 - val_accuracy: 0.7312\n",
      "Epoch 12/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.9561 - accuracy: 0.6698 - val_loss: 0.7505 - val_accuracy: 0.7456\n",
      "Epoch 13/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.9206 - accuracy: 0.6846 - val_loss: 0.7420 - val_accuracy: 0.7373\n",
      "Epoch 14/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.8786 - accuracy: 0.7028 - val_loss: 0.6709 - val_accuracy: 0.7743\n",
      "Epoch 15/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.8492 - accuracy: 0.7161 - val_loss: 0.6362 - val_accuracy: 0.8038\n",
      "Epoch 16/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.8172 - accuracy: 0.7249 - val_loss: 0.6400 - val_accuracy: 0.8033\n",
      "Epoch 17/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.7958 - accuracy: 0.7338 - val_loss: 0.6208 - val_accuracy: 0.8100\n",
      "Epoch 18/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.8036 - accuracy: 0.7321 - val_loss: 0.5734 - val_accuracy: 0.8234\n",
      "Epoch 19/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.7455 - accuracy: 0.7546 - val_loss: 0.5925 - val_accuracy: 0.8097\n",
      "Epoch 20/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.7461 - accuracy: 0.7518 - val_loss: 0.6383 - val_accuracy: 0.7858\n",
      "Epoch 21/24\n",
      "263/263 [==============================] - 6s 25ms/step - loss: 0.7260 - accuracy: 0.7619 - val_loss: 0.5617 - val_accuracy: 0.8180\n",
      "Epoch 22/24\n",
      "263/263 [==============================] - 6s 25ms/step - loss: 0.7052 - accuracy: 0.7686 - val_loss: 0.6611 - val_accuracy: 0.7869\n",
      "Epoch 23/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.6845 - accuracy: 0.7757 - val_loss: 0.5262 - val_accuracy: 0.8341\n",
      "Epoch 24/24\n",
      "263/263 [==============================] - 6s 25ms/step - loss: 0.6485 - accuracy: 0.7906 - val_loss: 0.5174 - val_accuracy: 0.8435\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.8435\n",
      "Test loss: 0.51735919713974\n",
      "Test accuracy: 0.8434736132621765\n",
      "[    0     1     2 ... 37300 37301 37302] [3731 3732 3733 ... 7459 7460 7461]\n",
      "-----------breaking line--------------\n",
      "----------------------------\n",
      "2\n",
      "----------------------------\n",
      "Epoch 1/24\n",
      "  2/263 [..............................] - ETA: 4:38 - loss: 2.2998 - accuracy: 0.0938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0264s vs `on_train_batch_end` time: 2.1034s). Check your callbacks.\n",
      "263/263 [==============================] - 11s 40ms/step - loss: 1.7949 - accuracy: 0.3360 - val_loss: 1.5505 - val_accuracy: 0.4275\n",
      "Epoch 2/24\n",
      "263/263 [==============================] - 7s 26ms/step - loss: 1.5140 - accuracy: 0.4386 - val_loss: 1.4309 - val_accuracy: 0.4626\n",
      "Epoch 3/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 1.3999 - accuracy: 0.4855 - val_loss: 1.3188 - val_accuracy: 0.5176\n",
      "Epoch 4/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 1.3012 - accuracy: 0.5312 - val_loss: 1.2714 - val_accuracy: 0.5417\n",
      "Epoch 5/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 1.2497 - accuracy: 0.5568 - val_loss: 1.1922 - val_accuracy: 0.5757\n",
      "Epoch 6/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 1.1634 - accuracy: 0.5909 - val_loss: 1.1322 - val_accuracy: 0.6009\n",
      "Epoch 7/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 1.1346 - accuracy: 0.6056 - val_loss: 1.0458 - val_accuracy: 0.6395\n",
      "Epoch 8/24\n",
      "263/263 [==============================] - 7s 26ms/step - loss: 1.0528 - accuracy: 0.6396 - val_loss: 1.0018 - val_accuracy: 0.6679\n",
      "Epoch 9/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.9972 - accuracy: 0.6621 - val_loss: 0.9528 - val_accuracy: 0.6861\n",
      "Epoch 10/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.9571 - accuracy: 0.6778 - val_loss: 0.8753 - val_accuracy: 0.7087\n",
      "Epoch 11/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.9353 - accuracy: 0.6872 - val_loss: 0.8365 - val_accuracy: 0.7408\n",
      "Epoch 12/24\n",
      "263/263 [==============================] - 6s 25ms/step - loss: 0.8873 - accuracy: 0.7050 - val_loss: 0.8236 - val_accuracy: 0.7365\n",
      "Epoch 13/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.8613 - accuracy: 0.7144 - val_loss: 0.7720 - val_accuracy: 0.7521\n",
      "Epoch 14/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.8383 - accuracy: 0.7238 - val_loss: 0.7602 - val_accuracy: 0.7545\n",
      "Epoch 15/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.8118 - accuracy: 0.7311 - val_loss: 0.7682 - val_accuracy: 0.7499\n",
      "Epoch 16/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.8043 - accuracy: 0.7314 - val_loss: 0.7398 - val_accuracy: 0.7692\n",
      "Epoch 17/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.7545 - accuracy: 0.7535 - val_loss: 0.6773 - val_accuracy: 0.7877\n",
      "Epoch 18/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.7315 - accuracy: 0.7614 - val_loss: 0.6823 - val_accuracy: 0.7891\n",
      "Epoch 19/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.7380 - accuracy: 0.7566 - val_loss: 0.6625 - val_accuracy: 0.7888\n",
      "Epoch 20/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.7018 - accuracy: 0.7704 - val_loss: 0.6530 - val_accuracy: 0.7939\n",
      "Epoch 21/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.6751 - accuracy: 0.7784 - val_loss: 0.6046 - val_accuracy: 0.8078\n",
      "Epoch 22/24\n",
      "263/263 [==============================] - 6s 25ms/step - loss: 0.6684 - accuracy: 0.7804 - val_loss: 0.6091 - val_accuracy: 0.8100\n",
      "Epoch 23/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.6501 - accuracy: 0.7877 - val_loss: 0.6248 - val_accuracy: 0.7968\n",
      "Epoch 24/24\n",
      "263/263 [==============================] - 6s 25ms/step - loss: 0.6543 - accuracy: 0.7855 - val_loss: 0.5907 - val_accuracy: 0.8183\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.5907 - accuracy: 0.8183\n",
      "Test loss: 0.5907083749771118\n",
      "Test accuracy: 0.8182792663574219\n",
      "[    0     1     2 ... 37300 37301 37302] [ 7462  7463  7464 ... 11190 11191 11192]\n",
      "-----------breaking line--------------\n",
      "----------------------------\n",
      "3\n",
      "----------------------------\n",
      "Epoch 1/24\n",
      "  2/263 [..............................] - ETA: 4:35 - loss: 2.3012 - accuracy: 0.1328WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0244s vs `on_train_batch_end` time: 2.0838s). Check your callbacks.\n",
      "263/263 [==============================] - 10s 38ms/step - loss: 1.7934 - accuracy: 0.3247 - val_loss: 1.6032 - val_accuracy: 0.3953\n",
      "Epoch 2/24\n",
      "263/263 [==============================] - 7s 26ms/step - loss: 1.5361 - accuracy: 0.4266 - val_loss: 1.5117 - val_accuracy: 0.4315\n",
      "Epoch 3/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 1.4327 - accuracy: 0.4666 - val_loss: 1.4740 - val_accuracy: 0.4420\n",
      "Epoch 4/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 1.3550 - accuracy: 0.5002 - val_loss: 1.3596 - val_accuracy: 0.4865\n",
      "Epoch 5/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 1.2719 - accuracy: 0.5379 - val_loss: 1.2826 - val_accuracy: 0.5374\n",
      "Epoch 6/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 1.1958 - accuracy: 0.5758 - val_loss: 1.2232 - val_accuracy: 0.5679\n",
      "Epoch 7/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 1.1390 - accuracy: 0.6005 - val_loss: 1.1317 - val_accuracy: 0.6033\n",
      "Epoch 8/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 1.0704 - accuracy: 0.6275 - val_loss: 1.1525 - val_accuracy: 0.5931\n",
      "Epoch 9/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 1.0317 - accuracy: 0.6425 - val_loss: 1.0559 - val_accuracy: 0.6425\n",
      "Epoch 10/24\n",
      "263/263 [==============================] - 6s 25ms/step - loss: 0.9692 - accuracy: 0.6701 - val_loss: 1.0330 - val_accuracy: 0.6441\n",
      "Epoch 11/24\n",
      "263/263 [==============================] - 6s 25ms/step - loss: 0.9507 - accuracy: 0.6743 - val_loss: 1.0502 - val_accuracy: 0.6451\n",
      "Epoch 12/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.9097 - accuracy: 0.6953 - val_loss: 0.9987 - val_accuracy: 0.6685\n",
      "Epoch 13/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 0.8750 - accuracy: 0.7046 - val_loss: 0.9385 - val_accuracy: 0.6934\n",
      "Epoch 14/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.8365 - accuracy: 0.7207 - val_loss: 0.9126 - val_accuracy: 0.7025\n",
      "Epoch 15/24\n",
      "263/263 [==============================] - 6s 25ms/step - loss: 0.8251 - accuracy: 0.7272 - val_loss: 0.9318 - val_accuracy: 0.6832\n",
      "Epoch 16/24\n",
      "263/263 [==============================] - 6s 25ms/step - loss: 0.8059 - accuracy: 0.7319 - val_loss: 0.8602 - val_accuracy: 0.7221\n",
      "Epoch 17/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.7532 - accuracy: 0.7533 - val_loss: 0.8566 - val_accuracy: 0.7231\n",
      "Epoch 18/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.7407 - accuracy: 0.7555 - val_loss: 0.8333 - val_accuracy: 0.7309\n",
      "Epoch 19/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.6993 - accuracy: 0.7721 - val_loss: 0.8309 - val_accuracy: 0.7274\n",
      "Epoch 20/24\n",
      "263/263 [==============================] - 6s 25ms/step - loss: 0.7017 - accuracy: 0.7695 - val_loss: 0.8219 - val_accuracy: 0.7347\n",
      "Epoch 21/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.7075 - accuracy: 0.7659 - val_loss: 0.7943 - val_accuracy: 0.7448\n",
      "Epoch 22/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.6900 - accuracy: 0.7739 - val_loss: 0.8542 - val_accuracy: 0.7255\n",
      "Epoch 23/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.6982 - accuracy: 0.7714 - val_loss: 1.0158 - val_accuracy: 0.6768\n",
      "Epoch 24/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.7558 - accuracy: 0.7490 - val_loss: 0.8910 - val_accuracy: 0.7060\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.8910 - accuracy: 0.7060\n",
      "Test loss: 0.8909904360771179\n",
      "Test accuracy: 0.7059769630432129\n",
      "[    0     1     2 ... 37300 37301 37302] [11193 11194 11195 ... 14920 14921 14922]\n",
      "-----------breaking line--------------\n",
      "----------------------------\n",
      "4\n",
      "----------------------------\n",
      "Epoch 1/24\n",
      "  2/263 [..............................] - ETA: 4:33 - loss: 2.2955 - accuracy: 0.1367WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0254s vs `on_train_batch_end` time: 2.0663s). Check your callbacks.\n",
      "263/263 [==============================] - 10s 38ms/step - loss: 1.7648 - accuracy: 0.3550 - val_loss: 1.5824 - val_accuracy: 0.3895\n",
      "Epoch 2/24\n",
      "263/263 [==============================] - 7s 26ms/step - loss: 1.5027 - accuracy: 0.4437 - val_loss: 1.4760 - val_accuracy: 0.4499\n",
      "Epoch 3/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 1.3903 - accuracy: 0.4859 - val_loss: 1.3631 - val_accuracy: 0.5024\n",
      "Epoch 4/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 1.2942 - accuracy: 0.5325 - val_loss: 1.3125 - val_accuracy: 0.5279\n",
      "Epoch 5/24\n",
      "263/263 [==============================] - 7s 26ms/step - loss: 1.2182 - accuracy: 0.5656 - val_loss: 1.2526 - val_accuracy: 0.5472\n",
      "Epoch 6/24\n",
      "263/263 [==============================] - 7s 26ms/step - loss: 1.1570 - accuracy: 0.5936 - val_loss: 1.2030 - val_accuracy: 0.5705\n",
      "Epoch 7/24\n",
      "263/263 [==============================] - 7s 28ms/step - loss: 1.1069 - accuracy: 0.6160 - val_loss: 1.1674 - val_accuracy: 0.5861\n",
      "Epoch 8/24\n",
      "263/263 [==============================] - 6s 25ms/step - loss: 1.0469 - accuracy: 0.6402 - val_loss: 1.1081 - val_accuracy: 0.6121\n",
      "Epoch 9/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.9905 - accuracy: 0.6624 - val_loss: 1.1133 - val_accuracy: 0.6182\n",
      "Epoch 10/24\n",
      "263/263 [==============================] - 7s 26ms/step - loss: 0.9804 - accuracy: 0.6675 - val_loss: 1.0682 - val_accuracy: 0.6276\n",
      "Epoch 11/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.9237 - accuracy: 0.6897 - val_loss: 0.9820 - val_accuracy: 0.6625\n",
      "Epoch 12/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.8732 - accuracy: 0.7063 - val_loss: 0.9643 - val_accuracy: 0.6729\n",
      "Epoch 13/24\n",
      "263/263 [==============================] - 7s 26ms/step - loss: 0.8524 - accuracy: 0.7178 - val_loss: 0.9467 - val_accuracy: 0.6799\n",
      "Epoch 14/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.8103 - accuracy: 0.7355 - val_loss: 0.9252 - val_accuracy: 0.6850\n",
      "Epoch 15/24\n",
      "263/263 [==============================] - 7s 26ms/step - loss: 0.7724 - accuracy: 0.7468 - val_loss: 0.9001 - val_accuracy: 0.7059\n",
      "Epoch 16/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.7469 - accuracy: 0.7566 - val_loss: 0.8778 - val_accuracy: 0.7129\n",
      "Epoch 17/24\n",
      "263/263 [==============================] - 7s 26ms/step - loss: 0.7250 - accuracy: 0.7649 - val_loss: 0.8345 - val_accuracy: 0.7241\n",
      "Epoch 18/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.6799 - accuracy: 0.7800 - val_loss: 0.8442 - val_accuracy: 0.7209\n",
      "Epoch 19/24\n",
      "263/263 [==============================] - 7s 26ms/step - loss: 0.6594 - accuracy: 0.7894 - val_loss: 0.8188 - val_accuracy: 0.7349\n",
      "Epoch 20/24\n",
      "263/263 [==============================] - 7s 26ms/step - loss: 0.6708 - accuracy: 0.7834 - val_loss: 0.8618 - val_accuracy: 0.7212\n",
      "Epoch 21/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.6617 - accuracy: 0.7852 - val_loss: 0.8392 - val_accuracy: 0.7260\n",
      "Epoch 22/24\n",
      "263/263 [==============================] - 7s 26ms/step - loss: 0.6406 - accuracy: 0.7936 - val_loss: 0.7677 - val_accuracy: 0.7606\n",
      "Epoch 23/24\n",
      "263/263 [==============================] - 7s 26ms/step - loss: 0.6405 - accuracy: 0.7950 - val_loss: 0.8195 - val_accuracy: 0.7316\n",
      "Epoch 24/24\n",
      "263/263 [==============================] - 7s 26ms/step - loss: 0.6158 - accuracy: 0.8039 - val_loss: 0.7613 - val_accuracy: 0.7547\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.7613 - accuracy: 0.7547\n",
      "Test loss: 0.7612866759300232\n",
      "Test accuracy: 0.7546916604042053\n",
      "[    0     1     2 ... 37300 37301 37302] [14923 14924 14925 ... 18650 18651 18652]\n",
      "-----------breaking line--------------\n",
      "----------------------------\n",
      "5\n",
      "----------------------------\n",
      "Epoch 1/24\n",
      "  2/263 [..............................] - ETA: 4:38 - loss: 2.3162 - accuracy: 0.0352WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0244s vs `on_train_batch_end` time: 2.1093s). Check your callbacks.\n",
      "263/263 [==============================] - 10s 40ms/step - loss: 1.7836 - accuracy: 0.3379 - val_loss: 1.6345 - val_accuracy: 0.3834\n",
      "Epoch 2/24\n",
      "263/263 [==============================] - 7s 27ms/step - loss: 1.5306 - accuracy: 0.4208 - val_loss: 1.5370 - val_accuracy: 0.4180\n",
      "Epoch 3/24\n",
      "263/263 [==============================] - 7s 26ms/step - loss: 1.4377 - accuracy: 0.4671 - val_loss: 1.4571 - val_accuracy: 0.4622\n",
      "Epoch 4/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 1.3517 - accuracy: 0.5063 - val_loss: 1.3837 - val_accuracy: 0.4997\n",
      "Epoch 5/24\n",
      "263/263 [==============================] - 7s 26ms/step - loss: 1.2729 - accuracy: 0.5439 - val_loss: 1.3148 - val_accuracy: 0.5279\n",
      "Epoch 6/24\n",
      "263/263 [==============================] - 7s 26ms/step - loss: 1.2267 - accuracy: 0.5602 - val_loss: 1.3189 - val_accuracy: 0.5206\n",
      "Epoch 7/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 1.1708 - accuracy: 0.5851 - val_loss: 1.2805 - val_accuracy: 0.5488\n",
      "Epoch 8/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 1.1162 - accuracy: 0.6101 - val_loss: 1.2023 - val_accuracy: 0.5869\n",
      "Epoch 9/24\n",
      "263/263 [==============================] - 7s 26ms/step - loss: 1.0604 - accuracy: 0.6319 - val_loss: 1.2344 - val_accuracy: 0.5678\n",
      "Epoch 10/24\n",
      "263/263 [==============================] - 7s 26ms/step - loss: 1.0202 - accuracy: 0.6510 - val_loss: 1.1546 - val_accuracy: 0.5930\n",
      "Epoch 11/24\n",
      "263/263 [==============================] - 7s 26ms/step - loss: 0.9744 - accuracy: 0.6675 - val_loss: 1.1055 - val_accuracy: 0.6276\n",
      "Epoch 12/24\n",
      "263/263 [==============================] - 7s 26ms/step - loss: 0.9457 - accuracy: 0.6769 - val_loss: 1.1098 - val_accuracy: 0.6180\n",
      "Epoch 13/24\n",
      "263/263 [==============================] - 7s 26ms/step - loss: 0.9477 - accuracy: 0.6782 - val_loss: 1.1303 - val_accuracy: 0.6134\n",
      "Epoch 14/24\n",
      "263/263 [==============================] - 7s 26ms/step - loss: 0.9178 - accuracy: 0.6871 - val_loss: 1.0496 - val_accuracy: 0.6378\n",
      "Epoch 15/24\n",
      "263/263 [==============================] - 7s 26ms/step - loss: 0.8662 - accuracy: 0.7053 - val_loss: 1.0546 - val_accuracy: 0.6496\n",
      "Epoch 16/24\n",
      "263/263 [==============================] - 7s 26ms/step - loss: 0.8459 - accuracy: 0.7149 - val_loss: 1.0113 - val_accuracy: 0.6619\n",
      "Epoch 17/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.8155 - accuracy: 0.7283 - val_loss: 1.0070 - val_accuracy: 0.6603\n",
      "Epoch 18/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.7898 - accuracy: 0.7378 - val_loss: 1.0122 - val_accuracy: 0.6598\n",
      "Epoch 19/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.7692 - accuracy: 0.7470 - val_loss: 0.9627 - val_accuracy: 0.6887\n",
      "Epoch 20/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.7569 - accuracy: 0.7502 - val_loss: 0.9481 - val_accuracy: 0.6895\n",
      "Epoch 21/24\n",
      "263/263 [==============================] - 7s 26ms/step - loss: 0.7295 - accuracy: 0.7571 - val_loss: 0.9374 - val_accuracy: 0.6962\n",
      "Epoch 22/24\n",
      "263/263 [==============================] - 7s 26ms/step - loss: 0.7173 - accuracy: 0.7620 - val_loss: 0.9441 - val_accuracy: 0.6895\n",
      "Epoch 23/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.6972 - accuracy: 0.7705 - val_loss: 0.9093 - val_accuracy: 0.6995\n",
      "Epoch 24/24\n",
      "263/263 [==============================] - 7s 26ms/step - loss: 0.7057 - accuracy: 0.7687 - val_loss: 0.9400 - val_accuracy: 0.7024\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.9400 - accuracy: 0.7024\n",
      "Test loss: 0.9400272369384766\n",
      "Test accuracy: 0.7024128437042236\n",
      "[    0     1     2 ... 37300 37301 37302] [18653 18654 18655 ... 22380 22381 22382]\n",
      "-----------breaking line--------------\n",
      "----------------------------\n",
      "6\n",
      "----------------------------\n",
      "Epoch 1/24\n",
      "  2/263 [..............................] - ETA: 4:33 - loss: 2.3050 - accuracy: 0.0898WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0254s vs `on_train_batch_end` time: 2.0677s). Check your callbacks.\n",
      "263/263 [==============================] - 10s 38ms/step - loss: 1.7887 - accuracy: 0.3316 - val_loss: 1.6081 - val_accuracy: 0.4003\n",
      "Epoch 2/24\n",
      "263/263 [==============================] - 7s 26ms/step - loss: 1.5253 - accuracy: 0.4264 - val_loss: 1.4896 - val_accuracy: 0.4421\n",
      "Epoch 3/24\n",
      "263/263 [==============================] - 7s 26ms/step - loss: 1.4234 - accuracy: 0.4638 - val_loss: 1.4300 - val_accuracy: 0.4558\n",
      "Epoch 4/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 1.3470 - accuracy: 0.4972 - val_loss: 1.3689 - val_accuracy: 0.4855\n",
      "Epoch 5/24\n",
      "263/263 [==============================] - 7s 26ms/step - loss: 1.2869 - accuracy: 0.5248 - val_loss: 1.3358 - val_accuracy: 0.5048\n",
      "Epoch 6/24\n",
      "263/263 [==============================] - 7s 26ms/step - loss: 1.2244 - accuracy: 0.5562 - val_loss: 1.2833 - val_accuracy: 0.5386\n",
      "Epoch 7/24\n",
      "263/263 [==============================] - 7s 26ms/step - loss: 1.1770 - accuracy: 0.5809 - val_loss: 1.2567 - val_accuracy: 0.5469\n",
      "Epoch 8/24\n",
      "263/263 [==============================] - 7s 26ms/step - loss: 1.1225 - accuracy: 0.6018 - val_loss: 1.2396 - val_accuracy: 0.5598\n",
      "Epoch 9/24\n",
      "263/263 [==============================] - 7s 27ms/step - loss: 1.0829 - accuracy: 0.6204 - val_loss: 1.2105 - val_accuracy: 0.5756\n",
      "Epoch 10/24\n",
      "263/263 [==============================] - 7s 26ms/step - loss: 1.0399 - accuracy: 0.6394 - val_loss: 1.1811 - val_accuracy: 0.5815\n",
      "Epoch 11/24\n",
      "263/263 [==============================] - 7s 26ms/step - loss: 1.0183 - accuracy: 0.6533 - val_loss: 1.2497 - val_accuracy: 0.5686\n",
      "Epoch 12/24\n",
      "263/263 [==============================] - 7s 26ms/step - loss: 0.9800 - accuracy: 0.6679 - val_loss: 1.1642 - val_accuracy: 0.6043\n",
      "Epoch 13/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.9392 - accuracy: 0.6847 - val_loss: 1.0875 - val_accuracy: 0.6249\n",
      "Epoch 14/24\n",
      "263/263 [==============================] - 7s 26ms/step - loss: 0.8963 - accuracy: 0.7014 - val_loss: 1.1286 - val_accuracy: 0.6180\n",
      "Epoch 15/24\n",
      "263/263 [==============================] - 7s 26ms/step - loss: 0.8850 - accuracy: 0.7073 - val_loss: 1.0812 - val_accuracy: 0.6381\n",
      "Epoch 16/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.8431 - accuracy: 0.7229 - val_loss: 1.0790 - val_accuracy: 0.6391\n",
      "Epoch 17/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.8297 - accuracy: 0.7273 - val_loss: 1.0404 - val_accuracy: 0.6579\n",
      "Epoch 18/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.8166 - accuracy: 0.7299 - val_loss: 1.0537 - val_accuracy: 0.6547\n",
      "Epoch 19/24\n",
      "263/263 [==============================] - 7s 26ms/step - loss: 0.8121 - accuracy: 0.7336 - val_loss: 1.0201 - val_accuracy: 0.6692\n",
      "Epoch 20/24\n",
      "263/263 [==============================] - 7s 26ms/step - loss: 0.7836 - accuracy: 0.7418 - val_loss: 1.0220 - val_accuracy: 0.6627\n",
      "Epoch 21/24\n",
      "263/263 [==============================] - 7s 26ms/step - loss: 0.7411 - accuracy: 0.7599 - val_loss: 0.9638 - val_accuracy: 0.6936\n",
      "Epoch 22/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.7347 - accuracy: 0.7613 - val_loss: 0.9553 - val_accuracy: 0.6874\n",
      "Epoch 23/24\n",
      "263/263 [==============================] - 7s 26ms/step - loss: 0.7385 - accuracy: 0.7584 - val_loss: 0.9933 - val_accuracy: 0.6802\n",
      "Epoch 24/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.7115 - accuracy: 0.7692 - val_loss: 0.9597 - val_accuracy: 0.6933\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.9597 - accuracy: 0.6933\n",
      "Test loss: 0.9596846103668213\n",
      "Test accuracy: 0.6932975649833679\n",
      "[    0     1     2 ... 37300 37301 37302] [22383 22384 22385 ... 26110 26111 26112]\n",
      "-----------breaking line--------------\n",
      "----------------------------\n",
      "7\n",
      "----------------------------\n",
      "Epoch 1/24\n",
      "  2/263 [..............................] - ETA: 4:46 - loss: 2.3034 - accuracy: 0.0703WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0264s vs `on_train_batch_end` time: 2.1690s). Check your callbacks.\n",
      "263/263 [==============================] - 11s 40ms/step - loss: 1.7973 - accuracy: 0.3300 - val_loss: 1.5924 - val_accuracy: 0.4029\n",
      "Epoch 2/24\n",
      "263/263 [==============================] - 7s 28ms/step - loss: 1.5047 - accuracy: 0.4406 - val_loss: 1.5376 - val_accuracy: 0.4241\n",
      "Epoch 3/24\n",
      "263/263 [==============================] - 7s 27ms/step - loss: 1.3997 - accuracy: 0.4831 - val_loss: 1.4348 - val_accuracy: 0.4842\n",
      "Epoch 4/24\n",
      "263/263 [==============================] - 7s 27ms/step - loss: 1.3087 - accuracy: 0.5225 - val_loss: 1.3874 - val_accuracy: 0.5094\n",
      "Epoch 5/24\n",
      "263/263 [==============================] - 7s 26ms/step - loss: 1.2274 - accuracy: 0.5596 - val_loss: 1.3082 - val_accuracy: 0.5472\n",
      "Epoch 6/24\n",
      "263/263 [==============================] - 7s 26ms/step - loss: 1.1605 - accuracy: 0.5951 - val_loss: 1.2833 - val_accuracy: 0.5536\n",
      "Epoch 7/24\n",
      "263/263 [==============================] - 7s 26ms/step - loss: 1.0901 - accuracy: 0.6208 - val_loss: 1.2337 - val_accuracy: 0.5676\n",
      "Epoch 8/24\n",
      "263/263 [==============================] - 6s 25ms/step - loss: 1.0593 - accuracy: 0.6340 - val_loss: 1.2046 - val_accuracy: 0.5764\n",
      "Epoch 9/24\n",
      "263/263 [==============================] - 7s 26ms/step - loss: 1.0120 - accuracy: 0.6519 - val_loss: 1.1577 - val_accuracy: 0.6059\n",
      "Epoch 10/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.9584 - accuracy: 0.6776 - val_loss: 1.1315 - val_accuracy: 0.6051\n",
      "Epoch 11/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 0.9227 - accuracy: 0.6903 - val_loss: 1.1140 - val_accuracy: 0.6247\n",
      "Epoch 12/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 0.8959 - accuracy: 0.7027 - val_loss: 1.0928 - val_accuracy: 0.6357\n",
      "Epoch 13/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 0.8345 - accuracy: 0.7255 - val_loss: 1.1299 - val_accuracy: 0.6268\n",
      "Epoch 14/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 0.8222 - accuracy: 0.7319 - val_loss: 1.0533 - val_accuracy: 0.6528\n",
      "Epoch 15/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 0.7879 - accuracy: 0.7423 - val_loss: 1.0713 - val_accuracy: 0.6504\n",
      "Epoch 16/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.8445 - accuracy: 0.7181 - val_loss: 1.0385 - val_accuracy: 0.6544\n",
      "Epoch 17/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.7863 - accuracy: 0.7403 - val_loss: 1.0143 - val_accuracy: 0.6716\n",
      "Epoch 18/24\n",
      "263/263 [==============================] - 6s 25ms/step - loss: 0.7438 - accuracy: 0.7573 - val_loss: 0.9928 - val_accuracy: 0.6853\n",
      "Epoch 19/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.7126 - accuracy: 0.7700 - val_loss: 0.9732 - val_accuracy: 0.6871\n",
      "Epoch 20/24\n",
      "263/263 [==============================] - 6s 25ms/step - loss: 0.6849 - accuracy: 0.7796 - val_loss: 0.9774 - val_accuracy: 0.6930\n",
      "Epoch 21/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.7086 - accuracy: 0.7679 - val_loss: 0.9648 - val_accuracy: 0.6877\n",
      "Epoch 22/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.6618 - accuracy: 0.7869 - val_loss: 0.9561 - val_accuracy: 0.7016\n",
      "Epoch 23/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 0.6334 - accuracy: 0.7977 - val_loss: 0.9528 - val_accuracy: 0.7086\n",
      "Epoch 24/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 0.6232 - accuracy: 0.8000 - val_loss: 0.9652 - val_accuracy: 0.6914\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 0.9652 - accuracy: 0.6914\n",
      "Test loss: 0.9652125239372253\n",
      "Test accuracy: 0.6914209127426147\n",
      "[    0     1     2 ... 37300 37301 37302] [26113 26114 26115 ... 29840 29841 29842]\n",
      "-----------breaking line--------------\n",
      "----------------------------\n",
      "8\n",
      "----------------------------\n",
      "Epoch 1/24\n",
      "  2/263 [..............................] - ETA: 4:30 - loss: 2.3007 - accuracy: 0.1523WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0225s vs `on_train_batch_end` time: 2.0478s). Check your callbacks.\n",
      "263/263 [==============================] - 10s 37ms/step - loss: 1.7889 - accuracy: 0.3328 - val_loss: 1.6456 - val_accuracy: 0.3802\n",
      "Epoch 2/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 1.4954 - accuracy: 0.4377 - val_loss: 1.4932 - val_accuracy: 0.4475\n",
      "Epoch 3/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 1.3719 - accuracy: 0.4902 - val_loss: 1.4505 - val_accuracy: 0.4584\n",
      "Epoch 4/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 1.2941 - accuracy: 0.5238 - val_loss: 1.3956 - val_accuracy: 0.4903\n",
      "Epoch 5/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 1.2596 - accuracy: 0.5428 - val_loss: 1.3303 - val_accuracy: 0.5145\n",
      "Epoch 6/24\n",
      "263/263 [==============================] - 6s 25ms/step - loss: 1.1785 - accuracy: 0.5798 - val_loss: 1.2664 - val_accuracy: 0.5437\n",
      "Epoch 7/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 1.0972 - accuracy: 0.6146 - val_loss: 1.2676 - val_accuracy: 0.5458\n",
      "Epoch 8/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 1.0518 - accuracy: 0.6325 - val_loss: 1.2141 - val_accuracy: 0.5769\n",
      "Epoch 9/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 1.0000 - accuracy: 0.6565 - val_loss: 1.1809 - val_accuracy: 0.6029\n",
      "Epoch 10/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.9559 - accuracy: 0.6766 - val_loss: 1.1512 - val_accuracy: 0.6102\n",
      "Epoch 11/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.9003 - accuracy: 0.6992 - val_loss: 1.1723 - val_accuracy: 0.6032\n",
      "Epoch 12/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.8992 - accuracy: 0.6981 - val_loss: 1.1106 - val_accuracy: 0.6252\n",
      "Epoch 13/24\n",
      "263/263 [==============================] - 6s 25ms/step - loss: 0.8526 - accuracy: 0.7195 - val_loss: 1.1329 - val_accuracy: 0.6244\n",
      "Epoch 14/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 0.8229 - accuracy: 0.7283 - val_loss: 1.1015 - val_accuracy: 0.6284\n",
      "Epoch 15/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 0.7880 - accuracy: 0.7400 - val_loss: 1.1121 - val_accuracy: 0.6308\n",
      "Epoch 16/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 0.7850 - accuracy: 0.7410 - val_loss: 1.1029 - val_accuracy: 0.6346\n",
      "Epoch 17/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 0.7412 - accuracy: 0.7574 - val_loss: 1.0518 - val_accuracy: 0.6584\n",
      "Epoch 18/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 0.7430 - accuracy: 0.7560 - val_loss: 1.0608 - val_accuracy: 0.6542\n",
      "Epoch 19/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 0.7100 - accuracy: 0.7693 - val_loss: 1.0702 - val_accuracy: 0.6587\n",
      "Epoch 20/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 0.6894 - accuracy: 0.7757 - val_loss: 1.0283 - val_accuracy: 0.6761\n",
      "Epoch 21/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 0.6683 - accuracy: 0.7839 - val_loss: 1.0338 - val_accuracy: 0.6718\n",
      "Epoch 22/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 0.6403 - accuracy: 0.7957 - val_loss: 1.0238 - val_accuracy: 0.6812\n",
      "Epoch 23/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 0.6441 - accuracy: 0.7900 - val_loss: 1.0639 - val_accuracy: 0.6614\n",
      "Epoch 24/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 0.6296 - accuracy: 0.7967 - val_loss: 1.0328 - val_accuracy: 0.6649\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 1.0328 - accuracy: 0.6649\n",
      "Test loss: 1.032830834388733\n",
      "Test accuracy: 0.6648793816566467\n",
      "[    0     1     2 ... 37300 37301 37302] [29843 29844 29845 ... 33570 33571 33572]\n",
      "-----------breaking line--------------\n",
      "----------------------------\n",
      "9\n",
      "----------------------------\n",
      "Epoch 1/24\n",
      "  2/263 [..............................] - ETA: 3:19 - loss: 2.2923 - accuracy: 0.1367WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0224s vs `on_train_batch_end` time: 1.5048s). Check your callbacks.\n",
      "263/263 [==============================] - 10s 37ms/step - loss: 1.7943 - accuracy: 0.3319 - val_loss: 1.6241 - val_accuracy: 0.3954\n",
      "Epoch 2/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 1.5078 - accuracy: 0.4420 - val_loss: 1.5166 - val_accuracy: 0.4370\n",
      "Epoch 3/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 1.3941 - accuracy: 0.4872 - val_loss: 1.4665 - val_accuracy: 0.4464\n",
      "Epoch 4/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 1.2974 - accuracy: 0.5322 - val_loss: 1.3882 - val_accuracy: 0.4968\n",
      "Epoch 5/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 1.2112 - accuracy: 0.5675 - val_loss: 1.3476 - val_accuracy: 0.5303\n",
      "Epoch 6/24\n",
      "263/263 [==============================] - 6s 25ms/step - loss: 1.1657 - accuracy: 0.5926 - val_loss: 1.3192 - val_accuracy: 0.5338\n",
      "Epoch 7/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 1.1231 - accuracy: 0.6072 - val_loss: 1.3094 - val_accuracy: 0.5397\n",
      "Epoch 8/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 1.0397 - accuracy: 0.6439 - val_loss: 1.2278 - val_accuracy: 0.5767\n",
      "Epoch 9/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 1.0037 - accuracy: 0.6587 - val_loss: 1.2517 - val_accuracy: 0.5743\n",
      "Epoch 10/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 0.9514 - accuracy: 0.6818 - val_loss: 1.1985 - val_accuracy: 0.6056\n",
      "Epoch 11/24\n",
      "263/263 [==============================] - 6s 25ms/step - loss: 0.9096 - accuracy: 0.6947 - val_loss: 1.1747 - val_accuracy: 0.6086\n",
      "Epoch 12/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 0.8694 - accuracy: 0.7091 - val_loss: 1.1507 - val_accuracy: 0.6185\n",
      "Epoch 13/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 0.8359 - accuracy: 0.7250 - val_loss: 1.1842 - val_accuracy: 0.6059\n",
      "Epoch 14/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 0.8033 - accuracy: 0.7358 - val_loss: 1.1558 - val_accuracy: 0.6236\n",
      "Epoch 15/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 0.7723 - accuracy: 0.7493 - val_loss: 1.1176 - val_accuracy: 0.6357\n",
      "Epoch 16/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 0.7536 - accuracy: 0.7531 - val_loss: 1.0913 - val_accuracy: 0.6499\n",
      "Epoch 17/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 0.7281 - accuracy: 0.7642 - val_loss: 1.0722 - val_accuracy: 0.6536\n",
      "Epoch 18/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 0.7353 - accuracy: 0.7601 - val_loss: 1.1686 - val_accuracy: 0.6212\n",
      "Epoch 19/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 0.7016 - accuracy: 0.7720 - val_loss: 1.0958 - val_accuracy: 0.6485\n",
      "Epoch 20/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 0.6626 - accuracy: 0.7867 - val_loss: 1.0902 - val_accuracy: 0.6555\n",
      "Epoch 21/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.6489 - accuracy: 0.7901 - val_loss: 1.1934 - val_accuracy: 0.6137\n",
      "Epoch 22/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 0.6624 - accuracy: 0.7874 - val_loss: 1.0286 - val_accuracy: 0.6772\n",
      "Epoch 23/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 0.5976 - accuracy: 0.8104 - val_loss: 1.0711 - val_accuracy: 0.6751\n",
      "Epoch 24/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 0.6408 - accuracy: 0.7929 - val_loss: 1.0520 - val_accuracy: 0.6702\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 1.0520 - accuracy: 0.6702\n",
      "Test loss: 1.0520367622375488\n",
      "Test accuracy: 0.6702412962913513\n",
      "[    0     1     2 ... 33570 33571 33572] [33573 33574 33575 ... 37300 37301 37302]\n",
      "-----------breaking line--------------\n",
      "----------------------------\n",
      "10\n",
      "----------------------------\n",
      "Epoch 1/24\n",
      "  2/263 [..............................] - ETA: 4:46 - loss: 2.2922 - accuracy: 0.0820WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0244s vs `on_train_batch_end` time: 2.1698s). Check your callbacks.\n",
      "263/263 [==============================] - 10s 38ms/step - loss: 1.7924 - accuracy: 0.3331 - val_loss: 1.6774 - val_accuracy: 0.3692\n",
      "Epoch 2/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 1.5262 - accuracy: 0.4302 - val_loss: 1.5623 - val_accuracy: 0.4209\n",
      "Epoch 3/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 1.4073 - accuracy: 0.4796 - val_loss: 1.4872 - val_accuracy: 0.4528\n",
      "Epoch 4/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 1.3307 - accuracy: 0.5109 - val_loss: 1.4436 - val_accuracy: 0.4823\n",
      "Epoch 5/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 1.2409 - accuracy: 0.5525 - val_loss: 1.3958 - val_accuracy: 0.4938\n",
      "Epoch 6/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 1.1802 - accuracy: 0.5799 - val_loss: 1.3603 - val_accuracy: 0.5180\n",
      "Epoch 7/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 1.1189 - accuracy: 0.6078 - val_loss: 1.3272 - val_accuracy: 0.5354\n",
      "Epoch 8/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 1.0658 - accuracy: 0.6293 - val_loss: 1.3141 - val_accuracy: 0.5429\n",
      "Epoch 9/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 1.0194 - accuracy: 0.6490 - val_loss: 1.4049 - val_accuracy: 0.5094\n",
      "Epoch 10/24\n",
      "263/263 [==============================] - 6s 25ms/step - loss: 1.0266 - accuracy: 0.6454 - val_loss: 1.2593 - val_accuracy: 0.5568\n",
      "Epoch 11/24\n",
      "263/263 [==============================] - 7s 25ms/step - loss: 0.9526 - accuracy: 0.6765 - val_loss: 1.2289 - val_accuracy: 0.5780\n",
      "Epoch 12/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 0.9074 - accuracy: 0.6959 - val_loss: 1.2250 - val_accuracy: 0.5850\n",
      "Epoch 13/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 0.8629 - accuracy: 0.7107 - val_loss: 1.2082 - val_accuracy: 0.5973\n",
      "Epoch 14/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 0.8251 - accuracy: 0.7242 - val_loss: 1.1757 - val_accuracy: 0.6024\n",
      "Epoch 15/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 0.8182 - accuracy: 0.7277 - val_loss: 1.1547 - val_accuracy: 0.6147\n",
      "Epoch 16/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 0.7557 - accuracy: 0.7524 - val_loss: 1.1498 - val_accuracy: 0.6198\n",
      "Epoch 17/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 0.7347 - accuracy: 0.7617 - val_loss: 1.1494 - val_accuracy: 0.6276\n",
      "Epoch 18/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 0.7249 - accuracy: 0.7618 - val_loss: 1.1441 - val_accuracy: 0.6298\n",
      "Epoch 19/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 0.6992 - accuracy: 0.7713 - val_loss: 1.1506 - val_accuracy: 0.6298\n",
      "Epoch 20/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 0.6973 - accuracy: 0.7724 - val_loss: 1.1237 - val_accuracy: 0.6445\n",
      "Epoch 21/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 0.6583 - accuracy: 0.7865 - val_loss: 1.1777 - val_accuracy: 0.6244\n",
      "Epoch 22/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 0.6814 - accuracy: 0.7784 - val_loss: 1.1281 - val_accuracy: 0.6402\n",
      "Epoch 23/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 0.6621 - accuracy: 0.7838 - val_loss: 1.1285 - val_accuracy: 0.6359\n",
      "Epoch 24/24\n",
      "263/263 [==============================] - 6s 24ms/step - loss: 0.6248 - accuracy: 0.7971 - val_loss: 1.1066 - val_accuracy: 0.6475\n",
      "117/117 [==============================] - 0s 3ms/step - loss: 1.1066 - accuracy: 0.6475\n",
      "Test loss: 1.1066277027130127\n",
      "Test accuracy: 0.6474530696868896\n"
     ]
    }
   ],
   "source": [
    "#To see how many samples are in X-train and y-train\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "count = 0\n",
    "\n",
    "keras.backend.clear_session()\n",
    "\n",
    "def ReshapeLayer(x):\n",
    "    \n",
    "    shape = x.shape\n",
    "    \n",
    "    # 1 possibility: H,W*channel\n",
    "    reshape = Reshape((shape[1],shape[2]*shape[3]))(x)\n",
    "    \n",
    "    # 2 possibility: W,H*channel\n",
    "    # transpose = Permute((2,1,3))(x)\n",
    "    # reshape = Reshape((shape[1],shape[2]*shape[3]))(transpose)\n",
    "    \n",
    "    return reshape\n",
    "\n",
    "for train_set, test_set in kf.split(dataset):\n",
    "     print( train_set, test_set)\n",
    "     print(\"-----------breaking line--------------\")\n",
    "     #X_train, X_test, y_train, y_test = dataset[train_set], dataset[test_set]\n",
    " \n",
    "     print('----------------------------')\n",
    "     count += 1\n",
    "     print(count)\n",
    "     print('----------------------------')\n",
    " \n",
    "     X_train,y_train = zip(*dataset[train_set])\n",
    "     X_test, y_test = zip(*dataset[test_set])\n",
    " \n",
    "     # Reshape for CNN input\n",
    "     X_train = np.array([x.reshape( (128, 128) ) for x in X_train])\n",
    "     X_test = np.array([x.reshape( (128, 128) ) for x in X_test])\n",
    "\n",
    "    #  X_train = np.expand_dims(X_train, axis=3)\n",
    "    #  X_test = np.expand_dims(X_test, axis=3)\n",
    " \n",
    "     # One-Hot encoding for classes\n",
    "     y_train = np.array(keras.utils.to_categorical(y_train, 10))\n",
    "     y_test = np.array(keras.utils.to_categorical(y_test, 10))\n",
    "\n",
    " \n",
    "     NAME = \"graphic-{}-\".format(int(time.time()))\n",
    "     tensorboard = TensorBoard(log_dir='E3-{}'.format(NAME +  str(count)))\n",
    " \n",
    " \n",
    "     model = Sequential()\n",
    "\n",
    "     model.add(\n",
    "        Conv1D(24, kernel_size=(5), input_shape=(128, 128))\n",
    "        )\n",
    "\n",
    "     model.add(MaxPooling1D(8))\n",
    "     model.add(Activation('relu'))\n",
    " \n",
    "     model.add(Conv1D(48, kernel_size=(1), padding=\"valid\"))\n",
    "     model.add(MaxPooling1D(8))\n",
    "     model.add(Activation('relu'))\n",
    " \n",
    "     model.add(Conv1D(48, kernel_size=(1), padding=\"valid\"))\n",
    "     model.add(Activation('relu'))\n",
    "\n",
    "     model.add(\n",
    "        LSTM(units = 100, return_sequences=True)\n",
    "        ) \n",
    "   \n",
    "     model.add(LSTM(32))\n",
    "     model.add(Dense(10))\n",
    "     model.add(Activation('softmax'))\n",
    " \n",
    "     model.compile(\n",
    " \t    optimizer=\"Adam\",\n",
    " \t    loss=\"categorical_crossentropy\",\n",
    " \t    metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "\n",
    "     model.fit(\n",
    " \t    x=X_train, \n",
    " \t    y=y_train,\n",
    "        epochs=24,\n",
    "        batch_size=128,\n",
    "        validation_data = (X_test, y_test),\n",
    " \t      callbacks=[tensorboard]\n",
    " \t    )\n",
    " \n",
    "     score = model.evaluate(\n",
    " \t    x=X_test,\n",
    " \t    y=y_test\n",
    "        )\n",
    " \n",
    "     print('Test loss:', score[0])\n",
    "     print('Test accuracy:', score[1])\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: SoundClassification1D.model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('SoundClassification1D.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"SoundClassification1DCNNLSTM.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopExecution",
     "evalue": "",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "class StopExecution(Exception):\n",
    "    def _render_traceback_(self):\n",
    "        pass\n",
    "\n",
    "raise StopExecution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
